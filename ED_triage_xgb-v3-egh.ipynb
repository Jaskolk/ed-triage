{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gonna use XGB now to combine the categorical, continuous and pre-embedded free text stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Online, we import the usual packages. **xgboost** needs to be installed (with conda install xgboost or pip install -U xgboost)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  the usual imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import sklearn.metrics\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import random as rn\n",
    "from IPython.display import clear_output\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def thresholding_analysis(preds, targets, admission_thresholds = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]):\n",
    "\n",
    "    i = 0\n",
    "    for thresh in admission_thresholds:\n",
    "        thresholded_predictions = [0 if prob[0] >= thresh else 1 for prob in preds]\n",
    "        \n",
    "        f1_w, f1, acc, prec, rec, auroc = get_metrics(targets,thresholded_predictions, print_output = False)\n",
    "\n",
    "        if i == 0:\n",
    "            output_df = pd.DataFrame([thresh, f1_w, f1, acc, prec, rec, rec[0], rec[1]]).T\n",
    "            output_df.columns = ['admission_threshold', 'AUROC', 'f1', 'accuracy', 'precision', 'recall', 'admission sensitivity', 'admission specificity']\n",
    "        else:\n",
    "            output_df.loc[len(output_df)] = [thresh, auroc, f1, acc, prec, rec, rec[0], rec[1]]\n",
    "        i+=1\n",
    "    \n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def show_confusion_matrix2(confusion_matrix, labels):\n",
    "    LABELS = labels\n",
    "\n",
    "    plt.figure(figsize=(3, 3))\n",
    "    sns.heatmap(confusion_matrix, cmap = 'Blues', xticklabels=LABELS, yticklabels=LABELS, annot=True, fmt=\"d\", annot_kws={\"size\": 15});\n",
    "    plt.title(\"Confusion matrix\", fontsize=10)\n",
    "    plt.ylabel('True label', fontsize=10)\n",
    "    plt.xlabel('Predicted label', fontsize=10)\n",
    "    plt.show()\n",
    "    \n",
    "def get_metrics(model, y_test, X_test, show_confusion = True, print_output = True, return_values = False):\n",
    "    preds = model.predict_proba(X_test)\n",
    "    predictions = model.predict(X_test)\n",
    "    \n",
    "    f1_w = sklearn.metrics.f1_score(y_test, predictions, average='weighted')\n",
    "    f1 = sklearn.metrics.f1_score(y_test, predictions, average=None)\n",
    "    acc = sklearn.metrics.accuracy_score(y_test, predictions)\n",
    "    prec = sklearn.metrics.precision_score(y_test,predictions, average=None) \n",
    "    rec = sklearn.metrics.recall_score(y_test,predictions, average=None)\n",
    "    auroc = sklearn.metrics.roc_auc_score(y_test,preds[:,1], average=None)\n",
    "    confusion = sklearn.metrics.confusion_matrix(y_test, predictions)\n",
    "    \n",
    "    tp, fn, fp, tn = confusion[0,0], confusion[0,1], confusion[1,0], confusion[1,1]\n",
    "    \n",
    "    sens = tp/(tp + fn)\n",
    "    spec = tn/(tn + fp)\n",
    "    ppv = tp/(tp + fp)\n",
    "    npv = tn/(tn + fn)\n",
    "    \n",
    "    \n",
    "    if print_output:\n",
    "        print ('Metrics Report:')\n",
    "        print ('---------------')\n",
    "        print ('weighted f1: ', f1_w)\n",
    "        print ('AUROC:       ',auroc)\n",
    "        print ('accuracy:    ', acc)\n",
    "        print ('precision:   ', prec)\n",
    "        print ('recall:      ', rec)\n",
    "        #print ('admission sens: ', rec[0])\n",
    "        #print ('admission spec: ', rec[1])\n",
    "        print ('sensitivity: ', sens)\n",
    "        print ('specificity: ', spec)\n",
    "        print ('PPV:         ', ppv)\n",
    "        print ('NPV:         ', npv)\n",
    "        \n",
    "    if show_confusion:\n",
    "        show_confusion_matrix2(confusion, labels = ['admit', 'd/c'])\n",
    "     \n",
    "    if return_values == True:\n",
    "        return f1_w, auroc, acc, sens, ppv\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def JJ_gridsearch(weights, print_output = False):\n",
    "    epoch = 0\n",
    "    for weight in weights:\n",
    "        \n",
    "        xgc = xgb.XGBClassifier(scale_pos_weight=weight)\n",
    "        xgc.fit(X_train, y_train)\n",
    "        preds = xgc.predict(X_test)\n",
    "        probas = xgc.predict_proba(X_test)\n",
    "        f1_w, f1, acc, prec, rec = get_metrics(y_test, preds, print_output)\n",
    "        \n",
    "        if epoch == 0:\n",
    "            results_df = pd.DataFrame([epoch+1, 1/weight, f1_w, f1, acc, prec, rec, rec[0], rec[1]]).T\n",
    "            results_df.columns = ['trial number', 'class penalty', 'weighted f1', 'f1', 'accuracy', 'precision', 'recall', 'admission sensitivity', 'admission specificity']\n",
    "        else:\n",
    "            results_df.loc[len(results_df)] = [epoch+1, 1/weight, f1_w, f1, acc, prec, rec, rec[0], rec[1]]\n",
    "        \n",
    "        epoch +=1\n",
    "        \n",
    "    return xgc, results_df, preds, probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use this cell when working from home\n",
    "path = '/Users/jjaskolkambp/Desktop/machine learning/my_projects/ed-triage'\n",
    "data_path = '/Users/jjaskolkambp/Desktop/machine learning/my_projects/data/ED triage project/combo'\n",
    "model_path = '/Users/jjaskolkambp/Desktop/machine learning/my_projects/ed-triage/models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "clin = pd.read_csv(data_path + '/complete_clean_combo_data.csv', index_col = 0,low_memory = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dx_code_dict = {code:i for i,code in enumerate(set(clin['MainDiagnosisCode']))}\n",
    "\n",
    "def convert_dxcode(s):\n",
    "    code = dx_code_dict[s]\n",
    "    return (code)\n",
    "\n",
    "clin['recoded_diagnosis'] = clin['MainDiagnosisCode'].map(convert_dxcode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "medhx = np.load(data_path + '/medhx_embeds.npy')\n",
    "\n",
    "#this is the admit vs d/c target\n",
    "target = np.load(data_path + '/admit_dc_target.npy')\n",
    "\n",
    "subjnotes = np.load(data_path + '/subj_emeds.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "egh_data = clin[clin['site']== 'EGH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63305"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "egh_idxs = np.array(list(egh_data.index)); len(egh_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "medhx = medhx[egh_idxs]\n",
    "subjnotes = subjnotes[egh_idxs]\n",
    "target = target[egh_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "clin = egh_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this cell will define the various groupings of variables from the dataframe\n",
    "dx_vars = ['recoded_diagnosis', 'PresentingComplaint']\n",
    "\n",
    "cont_vars = [ 'Triage Date & TimeYear', 'Triage Date & TimeMonth', 'Triage Date & TimeWeek', 'Triage Date & TimeDay',\n",
    " 'Triage Date & TimeDayofweek', 'Triage Date & TimeDayofyear', 'Triage Date & TimeHour', 'Triage Date & TimeMinute',\n",
    " 'Triage Date & TimeSecond', 'Triage Date & TimeElapsed',\n",
    " 'num_comorbids','systolic', 'diastolic', 'o2sat', 'pulse', 'temp', 'AgeInYrs']\n",
    "\n",
    "\n",
    "cos_date_vars = ['Triage Date & Timeweekday_cos',\n",
    "       'Triage Date & Timeweekday_sin', 'Triage Date & Timeday_month_cos',\n",
    "       'Triage Date & Timeday_month_sin', 'Triage Date & Timemonth_year_cos',\n",
    "       'Triage Date & Timemonth_year_sin', 'Triage Date & Timeday_year_cos',\n",
    "       'Triage Date & Timeday_year_sin', 'Triage Date & Timehour_cos',\n",
    "       'Triage Date & Timehour_sin', 'Triage Date & Timeclock_cos',\n",
    "       'Triage Date & Timeclock_sin', 'Triage Date & Timemin_cos',\n",
    "       'Triage Date & Timemin_sin', 'Triage Date & Timesec_cos']\n",
    "\n",
    "cat_vars = ['Triage Date & TimeIs_month_end',\n",
    " 'Triage Date & TimeIs_month_start',\n",
    " 'Triage Date & TimeIs_quarter_end',\n",
    " 'Triage Date & TimeIs_quarter_start',\n",
    " 'Triage Date & TimeIs_year_end',\n",
    " 'Triage Date & TimeIs_year_start',\n",
    " 'GenderDesc', 'TriageLevel', 'site']\n",
    "\n",
    "inf_control_vars = ['Are you feeling feverish or have had shakes or chills in the last 24 hours?',\n",
    " 'Have you ever been isolated/required isolation for an infectious disease when receiving care in a healthcare setting?',\n",
    " 'Do you have a new Rash?',\n",
    " 'Do you have a new onset of Vomiting/Diarrhea in the last 24 hours?',\n",
    " 'Have you travelled outside of Canada/USA in the last 3 weeks?',\n",
    " 'Have you had contact with a sick person who has travelled outside of Canada/USA in the last 3 weeks?',\n",
    " 'Have you received Health Care in another country in the last 2 years?',\n",
    " 'Do you have a new/worse cough or shortness of breath?',\n",
    " 'If so, select all countries that apply',\n",
    " 'If so, select all infectious diseases that apply']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preprocessing variables to use in XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to preprocess cat vars for xgb\n",
    "X = clin[cat_vars + inf_control_vars].values.astype(str)\n",
    "\n",
    "features = []\n",
    "for i in range(0, X.shape[1]):\n",
    "    label_encoder = LabelEncoder()\n",
    "    feature = label_encoder.fit_transform(X[:,i])\n",
    "    features.append(feature)\n",
    "encoded_x = np.array(features)\n",
    "encoded_x = encoded_x.reshape(X.shape[0], X.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63305, 19)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: :  (63305, 2528)\n"
     ]
    }
   ],
   "source": [
    "X2 = clin[dx_vars].values.astype(str)\n",
    "encoded_x2 = None\n",
    "for i in range(0, X2.shape[1]):\n",
    "\tlabel_encoder = LabelEncoder()\n",
    "\tfeature = label_encoder.fit_transform(X2[:,i])\n",
    "\tfeature = feature.reshape(X2.shape[0], 1)\n",
    "\tonehot_encoder = OneHotEncoder(sparse=False)\n",
    "\tfeature = onehot_encoder.fit_transform(feature)\n",
    "\tif encoded_x2 is None:\n",
    "\t\tencoded_x2 = feature\n",
    "\telse:\n",
    "\t\tencoded_x2 = np.concatenate((encoded_x2, feature), axis=1)\n",
    "print(\"X shape: : \", encoded_x2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting this one hot encoded matrix into one for the presenting complaint and one for the medical history\n",
    "X_pres = encoded_x2[:,:169]\n",
    "\n",
    "X_dx = encoded_x2[:,169:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63305, 4100)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = np.concatenate((encoded_x,X_pres, X_dx, clin[cont_vars].values), axis =1)\n",
    "\n",
    "all_features = np.concatenate((features,subjnotes,medhx), axis = 1)\n",
    "all_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataset size analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with 10000 examples\n",
      "\n",
      "CPU times: user 1min 21s, sys: 819 ms, total: 1min 22s\n",
      "Wall time: 1min 24s\n",
      "\n",
      "Training Set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jjaskolkambp/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics Report:\n",
      "---------------\n",
      "weighted f1:  0.8855704265402845\n",
      "AUROC:        0.9550917037255835\n",
      "accuracy:     0.8648\n",
      "precision:    [0.41154562 0.98879266]\n",
      "recall:       [0.90946502 0.85999114]\n",
      "sensitivity:  0.9094650205761317\n",
      "specificity:  0.8599911386796633\n",
      "PPV:          0.41154562383612664\n",
      "NPV:          0.9887926642893531\n",
      "\n",
      "Validation Set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jjaskolkambp/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics Report:\n",
      "---------------\n",
      "weighted f1:  0.8512040110990043\n",
      "AUROC:        0.8404877526426451\n",
      "accuracy:     0.8288\n",
      "precision:    [0.33855186 0.95475113]\n",
      "recall:       [0.65779468 0.84890478]\n",
      "sensitivity:  0.6577946768060836\n",
      "specificity:  0.8489047831917746\n",
      "PPV:          0.3385518590998043\n",
      "NPV:          0.9547511312217195\n",
      "\n",
      "Training with 30000 examples\n",
      "\n"
     ]
    }
   ],
   "source": [
    "       \n",
    "dataset_sizes = [10000, 30000, len(clin)]    \n",
    "\n",
    "#initialize dataframe for results\n",
    "col_names = ['num_examples','train_f1', 'test_f1', 'train_acc', 'test_acc', 'train_auroc', 'test_auroc', 'train_ppv', 'test_ppv', 'train_sens', 'test_sens']\n",
    "output_df = pd.DataFrame(columns = col_names)\n",
    "\n",
    "for size in dataset_sizes:\n",
    "    print ()\n",
    "    print ('Training with {} examples'.format(size))\n",
    "    print ()\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(all_features[:size], target[:size], random_state=1)\n",
    "    \n",
    "    xgc = xgb.XGBClassifier(scale_pos_weight = 1/9, gamma = 0.5, reg_alpha = 0.5)\n",
    "    %time xgc.fit(X_train, y_train)\n",
    "    \n",
    "    #random train subset for metrics\n",
    "    random_indices = np.random.choice(X_test.shape[0], len(X_test), replace=False)\n",
    "    \n",
    "    print ('\\nTraining Set')\n",
    "    train_f1, train_auroc, train_acc, train_sens, train_ppv = get_metrics(xgc, y_train[random_indices], X_train[random_indices],\n",
    "                                                                          show_confusion = False, return_values = True)\n",
    "    print ('\\nValidation Set')\n",
    "    test_f1, test_auroc, test_acc, test_sens, test_ppv = get_metrics(xgc, y_test, X_test,\n",
    "                                                                     show_confusion = False, return_values = True)\n",
    "    \n",
    "    output_df.loc[len(output_df)] = [size,train_f1, test_f1, train_acc, test_acc, train_auroc, test_auroc, train_ppv, test_ppv, train_sens, test_sens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
