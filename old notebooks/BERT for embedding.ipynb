{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RX_ZDhicpHkV"
   },
   "source": [
    "## Install and Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3527,
     "status": "ok",
     "timestamp": 1571579166766,
     "user": {
      "displayName": "Jeff Jaskolka",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAxPoaD5czR7gp1OnGR14wAKPoLvTCIdkN9Bp5MTg=s64",
      "userId": "18090659719286838097"
     },
     "user_tz": 240
    },
    "id": "DEfSbAA4QHas",
    "outputId": "e704a3da-cbd3-4b4f-8c3e-26e1362e4d45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6934,
     "status": "ok",
     "timestamp": 1571579173304,
     "user": {
      "displayName": "Jeff Jaskolka",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAxPoaD5czR7gp1OnGR14wAKPoLvTCIdkN9Bp5MTg=s64",
      "userId": "18090659719286838097"
     },
     "user_tz": 240
    },
    "id": "0NmMdkZO8R6q",
    "outputId": "e21a1118-169b-4e87-fe9c-428b8e41391b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytorch-pretrained-bert in /usr/local/lib/python3.6/site-packages (0.6.2)\n",
      "Requirement already satisfied: pytorch-nlp in /usr/local/lib/python3.6/site-packages (0.4.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/site-packages (from pytorch-pretrained-bert) (2.21.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/site-packages (from pytorch-pretrained-bert) (4.31.1)\n",
      "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/site-packages (from pytorch-pretrained-bert) (1.0.1.post2)\n",
      "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/site-packages (from pytorch-pretrained-bert) (1.9.253)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/site-packages (from pytorch-pretrained-bert) (1.15.4)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.6/site-packages (from pytorch-pretrained-bert) (2019.8.19)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.6/site-packages (from pytorch-nlp) (0.23.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/site-packages (from requests->pytorch-pretrained-bert) (2019.3.9)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/site-packages (from requests->pytorch-pretrained-bert) (2.8)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/site-packages (from requests->pytorch-pretrained-bert) (1.24.2)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/site-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n",
      "Requirement already satisfied: botocore<1.13.0,>=1.12.253 in /usr/local/lib/python3.6/site-packages (from boto3->pytorch-pretrained-bert) (1.12.253)\n",
      "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/site-packages (from boto3->pytorch-pretrained-bert) (0.2.1)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/site-packages (from boto3->pytorch-pretrained-bert) (0.9.4)\n",
      "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/site-packages (from pandas->pytorch-nlp) (2018.7)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/site-packages (from pandas->pytorch-nlp) (2.7.5)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/site-packages (from botocore<1.13.0,>=1.12.253->boto3->pytorch-pretrained-bert) (0.15.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/site-packages (from python-dateutil>=2.5.0->pandas->pytorch-nlp) (1.12.0)\n",
      "\u001b[31mmenpo 0.8.1 has requirement matplotlib<2.0,>=1.4, but you'll have matplotlib 3.0.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mmenpo 0.8.1 has requirement pillow<5.0,>=3.0, but you'll have pillow 5.4.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mmenpo 0.8.1 has requirement scipy<1.0,>=0.16, but you'll have scipy 1.2.0 which is incompatible.\u001b[0m\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch-pretrained-bert pytorch-nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2500,
     "status": "ok",
     "timestamp": 1571579181811,
     "user": {
      "displayName": "Jeff Jaskolka",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAxPoaD5czR7gp1OnGR14wAKPoLvTCIdkN9Bp5MTg=s64",
      "userId": "18090659719286838097"
     },
     "user_tz": 240
    },
    "id": "Ok002ceNB8E7",
    "outputId": "eb4ff100-bad7-44bd-ff2d-2afd408fde39"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertConfig\n",
    "from pytorch_pretrained_bert import BertAdam, BertForSequenceClassification\n",
    "from tqdm import tqdm, trange\n",
    "import pandas as pd\n",
    "import io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#% matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cqG7FzRVFEIv"
   },
   "source": [
    "In order for torch to use the GPU, we need to identify and specify the GPU as the device. Later, in our training loop, we will load data onto the device. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1012,
     "status": "ok",
     "timestamp": 1571579184010,
     "user": {
      "displayName": "Jeff Jaskolka",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAxPoaD5czR7gp1OnGR14wAKPoLvTCIdkN9Bp5MTg=s64",
      "userId": "18090659719286838097"
     },
     "user_tz": 240
    },
    "id": "oYsV4H8fCpZ-",
    "outputId": "ce1d5ac4-bac5-4223-f31b-aa9b21bc07b9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tesla K80'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use this cell when working online\n",
    "path = '/floyd/home/ed-triage'\n",
    "data_path = '/floyd/home/data/egh'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b0HXL90y47tD"
   },
   "source": [
    "## second pass\n",
    "now going to figure out how to run this on the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-b_nZYT05Ae3"
   },
   "outputs": [],
   "source": [
    "def create_dummy_column(s):\n",
    "  if str(s) == 'nan':\n",
    "    return 'empty cell'\n",
    "  else:\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1276,
     "status": "ok",
     "timestamp": 1571579219303,
     "user": {
      "displayName": "Jeff Jaskolka",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAxPoaD5czR7gp1OnGR14wAKPoLvTCIdkN9Bp5MTg=s64",
      "userId": "18090659719286838097"
     },
     "user_tz": 240
    },
    "id": "Bqs-jcTP5Ius",
    "outputId": "fa40609b-c590-4557-cec7-14d466fc769a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63474, 2)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(data_path + '/subj_data.csv', index_col = 0)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CleanSubjectiveNotes</th>\n",
       "      <th>pmhx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>complains of central chest tightness since yes...</td>\n",
       "      <td>childhood heart murmur, drug abuse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>pt says noted blood in stool yesterday and mor...</td>\n",
       "      <td>seizure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>rt flank pain since morning,on her periods now.</td>\n",
       "      <td>no significant medical history, ovarian cyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>abdo pain  onset monday,not seen by fd.</td>\n",
       "      <td>no significant medical history</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>fell last monday landed on ground, \" dizzy\" at...</td>\n",
       "      <td>high cholesterol, 2 stents 2014, low bp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  CleanSubjectiveNotes  \\\n",
       "511  complains of central chest tightness since yes...   \n",
       "754  pt says noted blood in stool yesterday and mor...   \n",
       "755    rt flank pain since morning,on her periods now.   \n",
       "757            abdo pain  onset monday,not seen by fd.   \n",
       "758  fell last monday landed on ground, \" dizzy\" at...   \n",
       "\n",
       "                                             pmhx  \n",
       "511            childhood heart murmur, drug abuse  \n",
       "754                                       seizure  \n",
       "755  no significant medical history, ovarian cyst  \n",
       "757                no significant medical history  \n",
       "758       high cholesterol, 2 stents 2014, low bp  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZZB-FL7K5LBe"
   },
   "outputs": [],
   "source": [
    "data['for embedding'] = data.CleanSubjectiveNotes.map(create_dummy_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HGUlz_bo595x"
   },
   "outputs": [],
   "source": [
    "sentences = data['for embedding'].values\n",
    "\n",
    "# We need to add special tokens at the beginning and end of each sentence for BERT to work properly\n",
    "sentences = [\"[CLS] \" + sentence + \" [SEP]\" for sentence in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 37782,
     "status": "ok",
     "timestamp": 1571579393262,
     "user": {
      "displayName": "Jeff Jaskolka",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAxPoaD5czR7gp1OnGR14wAKPoLvTCIdkN9Bp5MTg=s64",
      "userId": "18090659719286838097"
     },
     "user_tz": 240
    },
    "id": "hCAcGIEr63hQ",
    "outputId": "e1881cda-55ba-43d9-96f4-05721bf21f35"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenize the first sentence:\n",
      "['[CLS]', 'complain', '##s', 'of', 'central', 'chest', 'tight', '##ness', 'since', 'yesterday', 'morning', '.', 'worse', 'with', 'pal', '##pati', '##on', '.', 'relieved', 'with', 'movement', 'and', 'deep', 'breathing', '.', 'denies', 'nausea', 'and', '/', 'or', 'vomiting', '.', 'complain', '##s', 'of', 'feeling', 'cold', 'and', '\"', 'tired', '\"', '.', 'says', 'took', 'nearly', 'mel', '##aton', '##in', '100', '##mg', ',', 'cocaine', ',', 'and', 'et', '##oh', 'on', 'sunday', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "\n",
    "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
    "print (\"Tokenize the first sentence:\")\n",
    "print (tokenized_texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 35298,
     "status": "ok",
     "timestamp": 1571579393263,
     "user": {
      "displayName": "Jeff Jaskolka",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAxPoaD5czR7gp1OnGR14wAKPoLvTCIdkN9Bp5MTg=s64",
      "userId": "18090659719286838097"
     },
     "user_tz": 240
    },
    "id": "21dBlHkebaac",
    "outputId": "e6ae4500-fbdc-46f8-c9ab-350477c5b1ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "show a few other tokenized sentences\n",
      "['[CLS]', 'presently', 'feels', 'like', 'heart', 'is', 'going', 'fast', '.', 'intermittent', 'lt', 'sided', ',', 'non', '-', 'radiating', '.', 'no', 'cp', 'now', '.', 'says', 'he', 'has', 'thoughts', 'of', 'harm', '##ing', 'self', 'and', 'others', 'at', 'tri', '##age', 'but', 'says', 'plan', 'is', '\"', 'to', 'get', 'help', '\"', '.', 'says', 'takes', 'hiv', '/', 'aids', 'med', '##s', 'when', 'he', 'remembers', '.', 'cannot', 'remember', 'the', 'names', 'of', 'med', '##s', '.', '[SEP]']\n",
      "['[CLS]', 'vomit', '##ed', 'x', '5', ',', 'headache', ',', 'di', '##zziness', ',', 'not', 'able', 'to', 'tolerate', 'food', 'or', 'fluids', 'since', '113', '##0', 'hours', '[SEP]']\n",
      "['[CLS]', 'pt', 'complain', '##s', 'of', 'short', '##ness', 'of', 'breath', 'that', 'started', '1', 'week', 'ago', ',', 'denies', 'cp', '.', 'pt', 'has', 'swelling', 'to', 'feet', '.', 'report', 'feeling', 'weak', '.', 'wife', 'stated', 'pt', 'has', 'blood', 'in', 'stool', '.', '[SEP]']\n",
      "['[CLS]', 'pt', 'reported', 'that', 'he', 'needs', 'help', 'for', 'alcohol', 'withdrawal', '.', 'having', 'pal', '##pit', '##ations', ',', 'anxiety', 'attacks', 'and', 'tremor', '##s', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "print ('show a few other tokenized sentences')\n",
    "print (tokenized_texts[10])\n",
    "print (tokenized_texts[100])\n",
    "print (tokenized_texts[1000])\n",
    "print (tokenized_texts[10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5EvIzO21KuOQ"
   },
   "outputs": [],
   "source": [
    "data['tokenized_subj_notes'] = sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1291,
     "status": "ok",
     "timestamp": 1571579435728,
     "user": {
      "displayName": "Jeff Jaskolka",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAxPoaD5czR7gp1OnGR14wAKPoLvTCIdkN9Bp5MTg=s64",
      "userId": "18090659719286838097"
     },
     "user_tz": 240
    },
    "id": "9rhnM8oz63hV",
    "outputId": "93b8e93c-67df-4843-af02-f581c8c67c9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean sentence length 40.27126067366166\n",
      "max sentence length 216\n"
     ]
    }
   ],
   "source": [
    "sent_lens = [len(x) for x in tokenized_texts]\n",
    "print ('mean sentence length', np.mean(sent_lens))\n",
    "print ('max sentence length', np.max(sent_lens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LD756WGw63hX"
   },
   "outputs": [],
   "source": [
    "# Set the maximum sequence length. The longest sequence in our training set is 47, but we'll leave room on the end anyway. \n",
    "# In the original paper, the authors used a length of 512.\n",
    "MAX_LEN = np.max(sent_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b55KVcvi63hb"
   },
   "outputs": [],
   "source": [
    "# Use the BERT tokenizer to convert the tokens to their index numbers in the BERT vocabulary\n",
    "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LBYrmzqi63hd"
   },
   "outputs": [],
   "source": [
    "# Pad our input tokens\n",
    "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EXVmnYSc63hf"
   },
   "outputs": [],
   "source": [
    "# Create attention masks\n",
    "attention_masks = []\n",
    "\n",
    "# Create a mask of 1s for each token followed by 0s for padding\n",
    "for seq in input_ids:\n",
    "  seq_mask = [float(i>0) for i in seq]\n",
    "  attention_masks.append(seq_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IXy57DA063hg"
   },
   "outputs": [],
   "source": [
    "# Convert all of our data into torch tensors, the required datatype for our model\n",
    "\n",
    "train_inputs = torch.tensor(input_ids)\n",
    "train_masks = torch.tensor(attention_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b18X9iAT63hh"
   },
   "outputs": [],
   "source": [
    "# Select a batch size for training. For fine-tuning BERT on a specific task, the authors recommend a batch size of 16 or 32\n",
    "batch_size = 16\n",
    "\n",
    "# Create an iterator of our data with torch DataLoader. This helps save on memory during training because, unlike a for loop, \n",
    "# with an iterator the entire dataset does not need to be loaded into memory\n",
    "\n",
    "train_data = TensorDataset(train_inputs, train_masks)\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 29010,
     "status": "ok",
     "timestamp": 1571579502159,
     "user": {
      "displayName": "Jeff Jaskolka",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAxPoaD5czR7gp1OnGR14wAKPoLvTCIdkN9Bp5MTg=s64",
      "userId": "18090659719286838097"
     },
     "user_tz": 240
    },
    "id": "4iLZ41QQ63hk",
    "outputId": "00ec8ddf-cc3f-4ee9-ffce-23d60f0741ba"
   },
   "outputs": [],
   "source": [
    "#we are going to download the model and transfer it to cuda\n",
    "from pytorch_pretrained_bert import BertModel\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "model.cuda();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QVYAX-Rszk3N"
   },
   "source": [
    "## sentence embedding below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "ZSKQNxulb07u",
    "outputId": "6a3010de-7f6e-4d0c-8b24-abdb2ed78db4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch #: 1\n",
      "results stored...\n",
      "batch #: 501\n",
      "results stored...\n",
      "batch #: 1001\n",
      "results stored...\n",
      "batch #: 1501\n",
      "results stored...\n",
      "batch #: 2001\n",
      "results stored...\n",
      "batch #: 2501\n",
      "results stored...\n",
      "batch #: 3001\n",
      "results stored...\n",
      "batch #: 3501\n",
      "results stored...\n"
     ]
    }
   ],
   "source": [
    "#gonna redo, but this time only keep the sentences\n",
    "model.eval()\n",
    "embedded_notes = []\n",
    "for i, x in enumerate(train_dataloader):\n",
    "  \n",
    "    inpseq = x[0].to(device)\n",
    "    inpmask = x[1].to(device)\n",
    "    embeds,_ = model(inpseq, attention_mask = inpmask)\n",
    "    sentence_vec = torch.mean(embeds[11],1)  #this is supposedly where the sentences are\n",
    "    embedded_notes.append(sentence_vec.cpu().detach().numpy())\n",
    "    if i%500 == 0:\n",
    "        print ('batch #:', i+1)\n",
    "        print ('results stored...')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1048,
     "status": "ok",
     "timestamp": 1571518359821,
     "user": {
      "displayName": "Jeff Jaskolka",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAxPoaD5czR7gp1OnGR14wAKPoLvTCIdkN9Bp5MTg=s64",
      "userId": "18090659719286838097"
     },
     "user_tz": 240
    },
    "id": "i3u7sMImcsRg",
    "outputId": "78103e7a-81d3-4122-89f3-556449a90c64"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3968"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embedded_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KxLojYYzdosp"
   },
   "outputs": [],
   "source": [
    "flat_sentences = [item for sublist in embedded_notes for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d-sis2hQz2Xw"
   },
   "outputs": [],
   "source": [
    "data['embedded_subjnotes'] = flat_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 840,
     "status": "ok",
     "timestamp": 1571518968809,
     "user": {
      "displayName": "Jeff Jaskolka",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAxPoaD5czR7gp1OnGR14wAKPoLvTCIdkN9Bp5MTg=s64",
      "userId": "18090659719286838097"
     },
     "user_tz": 240
    },
    "id": "WihDHnpG1FF8",
    "outputId": "683b43fc-1f61-4054-bb45-ab3e2f56a9a2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CleanSubjectiveNotes</th>\n",
       "      <th>pmhx</th>\n",
       "      <th>for embedding</th>\n",
       "      <th>tokenized_subj_notes</th>\n",
       "      <th>embedded_subjnotes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>complains of central chest tightness since yes...</td>\n",
       "      <td>childhood heart murmur, drug abuse</td>\n",
       "      <td>complains of central chest tightness since yes...</td>\n",
       "      <td>[CLS] complains of central chest tightness sin...</td>\n",
       "      <td>[-0.2552049, 0.060189128, 0.2712358, -0.307374...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>pt says noted blood in stool yesterday and mor...</td>\n",
       "      <td>seizure</td>\n",
       "      <td>pt says noted blood in stool yesterday and mor...</td>\n",
       "      <td>[CLS] pt says noted blood in stool yesterday a...</td>\n",
       "      <td>[0.23464553, -0.18784478, 0.47729325, -0.02351...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>rt flank pain since morning,on her periods now.</td>\n",
       "      <td>no significant medical history, ovarian cyst</td>\n",
       "      <td>rt flank pain since morning,on her periods now.</td>\n",
       "      <td>[CLS] rt flank pain since morning,on her perio...</td>\n",
       "      <td>[-0.26586953, -0.1800395, 0.37560245, -0.34440...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>abdo pain  onset monday,not seen by fd.</td>\n",
       "      <td>no significant medical history</td>\n",
       "      <td>abdo pain  onset monday,not seen by fd.</td>\n",
       "      <td>[CLS] abdo pain  onset monday,not seen by fd. ...</td>\n",
       "      <td>[-0.20064865, -0.20033248, 0.32697883, -0.2581...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>fell last monday landed on ground, \" dizzy\" at...</td>\n",
       "      <td>high cholesterol, 2 stents 2014, low bp</td>\n",
       "      <td>fell last monday landed on ground, \" dizzy\" at...</td>\n",
       "      <td>[CLS] fell last monday landed on ground, \" diz...</td>\n",
       "      <td>[-0.09094222, -0.15834723, 0.48943293, 0.03535...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  CleanSubjectiveNotes  \\\n",
       "511  complains of central chest tightness since yes...   \n",
       "754  pt says noted blood in stool yesterday and mor...   \n",
       "755    rt flank pain since morning,on her periods now.   \n",
       "757            abdo pain  onset monday,not seen by fd.   \n",
       "758  fell last monday landed on ground, \" dizzy\" at...   \n",
       "\n",
       "                                             pmhx  \\\n",
       "511            childhood heart murmur, drug abuse   \n",
       "754                                       seizure   \n",
       "755  no significant medical history, ovarian cyst   \n",
       "757                no significant medical history   \n",
       "758       high cholesterol, 2 stents 2014, low bp   \n",
       "\n",
       "                                         for embedding  \\\n",
       "511  complains of central chest tightness since yes...   \n",
       "754  pt says noted blood in stool yesterday and mor...   \n",
       "755    rt flank pain since morning,on her periods now.   \n",
       "757            abdo pain  onset monday,not seen by fd.   \n",
       "758  fell last monday landed on ground, \" dizzy\" at...   \n",
       "\n",
       "                                  tokenized_subj_notes  \\\n",
       "511  [CLS] complains of central chest tightness sin...   \n",
       "754  [CLS] pt says noted blood in stool yesterday a...   \n",
       "755  [CLS] rt flank pain since morning,on her perio...   \n",
       "757  [CLS] abdo pain  onset monday,not seen by fd. ...   \n",
       "758  [CLS] fell last monday landed on ground, \" diz...   \n",
       "\n",
       "                                    embedded_subjnotes  \n",
       "511  [-0.2552049, 0.060189128, 0.2712358, -0.307374...  \n",
       "754  [0.23464553, -0.18784478, 0.47729325, -0.02351...  \n",
       "755  [-0.26586953, -0.1800395, 0.37560245, -0.34440...  \n",
       "757  [-0.20064865, -0.20033248, 0.32697883, -0.2581...  \n",
       "758  [-0.09094222, -0.15834723, 0.48943293, 0.03535...  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 534895,
     "status": "ok",
     "timestamp": 1571519625421,
     "user": {
      "displayName": "Jeff Jaskolka",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAxPoaD5czR7gp1OnGR14wAKPoLvTCIdkN9Bp5MTg=s64",
      "userId": "18090659719286838097"
     },
     "user_tz": 240
    },
    "id": "9zVd1f7H1MbA",
    "outputId": "8c800d7b-a9ee-4159-d006-59c677825827"
   },
   "outputs": [],
   "source": [
    "data['embedded_subjnotes'].to_csv(data_path + '/subjnote_embeds.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RmqSACnc2Vlm"
   },
   "source": [
    "## now gonna sentence embed medical history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BOzGihsu2p8n"
   },
   "outputs": [],
   "source": [
    "#need an way to handle empty cells so i can still embed the whole dataset and plug it back into the dataframe\n",
    "data['for embedding'] = data['pmhx'].map(create_dummy_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-Mk50kP32p8q"
   },
   "outputs": [],
   "source": [
    "sentences = data['for embedding'].values\n",
    "\n",
    "# We need to add special tokens at the beginning and end of each sentence for BERT to work properly\n",
    "sentences = [\"[CLS] \" + sentence + \" [SEP]\" for sentence in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10905,
     "status": "ok",
     "timestamp": 1571519816776,
     "user": {
      "displayName": "Jeff Jaskolka",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAxPoaD5czR7gp1OnGR14wAKPoLvTCIdkN9Bp5MTg=s64",
      "userId": "18090659719286838097"
     },
     "user_tz": 240
    },
    "id": "udl407md2p8s",
    "outputId": "51d206c3-dffa-479e-bbbc-bbc1bde98e59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenize the first sentence:\n",
      "['[CLS]', 'childhood', 'heart', 'murmur', ',', 'drug', 'abuse', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "\n",
    "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
    "print (\"Tokenize the first sentence:\")\n",
    "print (tokenized_texts[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9353,
     "status": "ok",
     "timestamp": 1571519816778,
     "user": {
      "displayName": "Jeff Jaskolka",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAxPoaD5czR7gp1OnGR14wAKPoLvTCIdkN9Bp5MTg=s64",
      "userId": "18090659719286838097"
     },
     "user_tz": 240
    },
    "id": "olUheiYj4NlB",
    "outputId": "7e12748d-d23d-41cf-d3c6-1150015391fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "show a few other tokenized sentences\n",
      "['[CLS]', 'hiv', '[SEP]']\n",
      "['[CLS]', 'no', 'significant', 'medical', 'history', '[SEP]']\n",
      "['[CLS]', 'hyper', '##tension', ',', 'high', 'cho', '##les', '##terol', '[SEP]']\n",
      "['[CLS]', 'ge', '##rd', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "print ('show a few other tokenized sentences')\n",
    "print (tokenized_texts[10])\n",
    "print (tokenized_texts[100])\n",
    "print (tokenized_texts[1000])\n",
    "print (tokenized_texts[10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VI5yqO0B2p8u"
   },
   "outputs": [],
   "source": [
    "data['tokenized_medhx'] = sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 852,
     "status": "ok",
     "timestamp": 1571519827354,
     "user": {
      "displayName": "Jeff Jaskolka",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAxPoaD5czR7gp1OnGR14wAKPoLvTCIdkN9Bp5MTg=s64",
      "userId": "18090659719286838097"
     },
     "user_tz": 240
    },
    "id": "KdSlUgJz2p8z",
    "outputId": "f05b6b3b-876a-4e33-95f8-a2ad89734dbd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean sentence length: 7.990295238995494\n",
      "max sentence length: 101\n"
     ]
    }
   ],
   "source": [
    "sent_lens = [len(x) for x in tokenized_texts]\n",
    "print ('mean sentence length:', np.mean(sent_lens))\n",
    "print ('max sentence length:', np.max(sent_lens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C50RE0Dm2p81"
   },
   "outputs": [],
   "source": [
    "# Set the maximum sequence length. The longest sequence in our training set is 47, but we'll leave room on the end anyway. \n",
    "# In the original paper, the authors used a length of 512.\n",
    "MAX_LEN = np.max(sent_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QkCSa_Bc2p84"
   },
   "outputs": [],
   "source": [
    "# Use the BERT tokenizer to convert the tokens to their index numbers in the BERT vocabulary\n",
    "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OQaMAuia2p86"
   },
   "outputs": [],
   "source": [
    "# Pad our input tokens\n",
    "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DMjxtTBA2p87"
   },
   "source": [
    "Create the attention masks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0oM9YlQH2p88"
   },
   "outputs": [],
   "source": [
    "# Create attention masks\n",
    "attention_masks = []\n",
    "\n",
    "# Create a mask of 1s for each token followed by 0s for padding\n",
    "for seq in input_ids:\n",
    "  seq_mask = [float(i>0) for i in seq]\n",
    "  attention_masks.append(seq_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ryorOZKh2p89"
   },
   "outputs": [],
   "source": [
    "# Convert all of our data into torch tensors, the required datatype for our model\n",
    "\n",
    "train_inputs = torch.tensor(input_ids)\n",
    "train_masks = torch.tensor(attention_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ff4rOgd22p8_"
   },
   "outputs": [],
   "source": [
    "# Select a batch size for training. For fine-tuning BERT on a specific task, the authors recommend a batch size of 16 or 32\n",
    "batch_size = 16\n",
    "\n",
    "# Create an iterator of our data with torch DataLoader. This helps save on memory during training because, unlike a for loop, \n",
    "# with an iterator the entire dataset does not need to be loaded into memory\n",
    "\n",
    "train_data = TensorDataset(train_inputs, train_masks)\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vUwMVWFk2p9B"
   },
   "outputs": [],
   "source": [
    "#we are going to download the model and transfer it to cuda\n",
    "from pytorch_pretrained_bert import BertModel\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "model.cuda();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1093853,
     "status": "ok",
     "timestamp": 1571520969916,
     "user": {
      "displayName": "Jeff Jaskolka",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAxPoaD5czR7gp1OnGR14wAKPoLvTCIdkN9Bp5MTg=s64",
      "userId": "18090659719286838097"
     },
     "user_tz": 240
    },
    "id": "2lOAiTVR3Lli",
    "outputId": "49aaa2ba-791a-40b6-9215-ec7ef1e101f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch #: 1\n",
      "results stored...\n",
      "batch #: 501\n",
      "results stored...\n",
      "batch #: 1001\n",
      "results stored...\n",
      "batch #: 1501\n",
      "results stored...\n",
      "batch #: 2001\n",
      "results stored...\n",
      "batch #: 2501\n",
      "results stored...\n",
      "batch #: 3001\n",
      "results stored...\n",
      "batch #: 3501\n",
      "results stored...\n"
     ]
    }
   ],
   "source": [
    "#gonna redo, but this time only keep the sentences\n",
    "model.eval()\n",
    "embedded_notes = []\n",
    "for i, x in enumerate(train_dataloader):\n",
    "  \n",
    "    inpseq = x[0].to(device)\n",
    "    inpmask = x[1].to(device)\n",
    "    embeds,_ = model(inpseq, attention_mask = inpmask)\n",
    "    sentence_vec = torch.mean(embeds[11],1)  #this is supposedly where the sentences are\n",
    "    embedded_notes.append(sentence_vec.cpu().detach().numpy())\n",
    "    if i%500 == 0:\n",
    "        print ('batch #:', i+1)\n",
    "        print ('results stored...')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1048,
     "status": "ok",
     "timestamp": 1571518359821,
     "user": {
      "displayName": "Jeff Jaskolka",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAxPoaD5czR7gp1OnGR14wAKPoLvTCIdkN9Bp5MTg=s64",
      "userId": "18090659719286838097"
     },
     "user_tz": 240
    },
    "id": "i3u7sMImcsRg",
    "outputId": "78103e7a-81d3-4122-89f3-556449a90c64"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3968"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embedded_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KxLojYYzdosp"
   },
   "outputs": [],
   "source": [
    "flat_sentences = [item for sublist in embedded_notes for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d-sis2hQz2Xw"
   },
   "outputs": [],
   "source": [
    "data['embedded_pmhx'] = flat_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3b60bU073chl"
   },
   "outputs": [],
   "source": [
    "data['embedded_pmhx'].to_csv(data_path + 'pmhx_embeds.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## below here, I'm just learning to import the data and merge it.  works well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "BERT for embedding.ipynb",
   "provenance": [
    {
     "file_id": "10SI-59huCzMvDOlVJZZRNZ0trAZeIj9g",
     "timestamp": 1571430967692
    },
    {
     "file_id": "1ywsvwO6thOVOrfagjjfuxEf6xVRxbUNO",
     "timestamp": 1570654919298
    },
    {
     "file_id": "1f_snPs--PVYgZJwT3GwjxqVALFJ0T2-y",
     "timestamp": 1556493831452
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
