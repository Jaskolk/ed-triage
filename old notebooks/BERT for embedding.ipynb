{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RX_ZDhicpHkV"
   },
   "source": [
    "## Install and Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3527,
     "status": "ok",
     "timestamp": 1571579166766,
     "user": {
      "displayName": "Jeff Jaskolka",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAxPoaD5czR7gp1OnGR14wAKPoLvTCIdkN9Bp5MTg=s64",
      "userId": "18090659719286838097"
     },
     "user_tz": 240
    },
    "id": "DEfSbAA4QHas",
    "outputId": "e704a3da-cbd3-4b4f-8c3e-26e1362e4d45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6934,
     "status": "ok",
     "timestamp": 1571579173304,
     "user": {
      "displayName": "Jeff Jaskolka",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAxPoaD5czR7gp1OnGR14wAKPoLvTCIdkN9Bp5MTg=s64",
      "userId": "18090659719286838097"
     },
     "user_tz": 240
    },
    "id": "0NmMdkZO8R6q",
    "outputId": "e21a1118-169b-4e87-fe9c-428b8e41391b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch-pretrained-bert\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
      "\u001b[K    100% |████████████████████████████████| 133kB 7.4MB/s \n",
      "\u001b[?25hCollecting pytorch-nlp\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4f/51/f0ee1efb75f7cc2e3065c5da1363d6be2eec79691b2821594f3f2329528c/pytorch_nlp-0.5.0-py3-none-any.whl (90kB)\n",
      "\u001b[K    100% |████████████████████████████████| 92kB 17.3MB/s \n",
      "\u001b[?25hCollecting regex (from pytorch-pretrained-bert)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1d/c1/c90beb2dbbfbf19f3634e16a441d5f11fa787bdf0748a35b8b88452c0e78/regex-2020.4.4-cp36-cp36m-manylinux1_x86_64.whl (679kB)\n",
      "\u001b[K    100% |████████████████████████████████| 686kB 15.3MB/s \n",
      "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/site-packages (from pytorch-pretrained-bert) (4.31.1)\n",
      "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/site-packages (from pytorch-pretrained-bert) (1.0.1.post2)\n",
      "Collecting boto3 (from pytorch-pretrained-bert)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/87/de75e5a24584d82cca60b86f95d06e56412ed9e23807dcf23896f206f58e/boto3-1.12.39-py2.py3-none-any.whl (128kB)\n",
      "\u001b[K    100% |████████████████████████████████| 133kB 25.9MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/site-packages (from pytorch-pretrained-bert) (1.15.4)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/site-packages (from pytorch-pretrained-bert) (2.21.0)\n",
      "Collecting s3transfer<0.4.0,>=0.3.0 (from boto3->pytorch-pretrained-bert)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/79/e6afb3d8b0b4e96cefbdc690f741d7dd24547ff1f94240c997a26fa908d3/s3transfer-0.3.3-py2.py3-none-any.whl (69kB)\n",
      "\u001b[K    100% |████████████████████████████████| 71kB 21.4MB/s \n",
      "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1 (from boto3->pytorch-pretrained-bert)\n",
      "  Downloading https://files.pythonhosted.org/packages/a3/43/1e939e1fcd87b827fe192d0c9fc25b48c5b3368902bfb913de7754b0dc03/jmespath-0.9.5-py2.py3-none-any.whl\n",
      "Collecting botocore<1.16.0,>=1.15.39 (from boto3->pytorch-pretrained-bert)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dc/fb/f78a0e09965c156fea9160713705af688ec4f18af4249b3095949c930f77/botocore-1.15.39-py2.py3-none-any.whl (6.1MB)\n",
      "\u001b[K    100% |████████████████████████████████| 6.1MB 7.6MB/s \n",
      "\u001b[?25hRequirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/site-packages (from requests->pytorch-pretrained-bert) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/site-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/site-packages (from requests->pytorch-pretrained-bert) (2019.3.9)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/site-packages (from requests->pytorch-pretrained-bert) (1.24.2)\n",
      "Collecting docutils<0.16,>=0.10 (from botocore<1.16.0,>=1.15.39->boto3->pytorch-pretrained-bert)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/cd/a6aa959dca619918ccb55023b4cb151949c64d4d5d55b3f4ffd7eee0c6e8/docutils-0.15.2-py3-none-any.whl (547kB)\n",
      "\u001b[K    100% |████████████████████████████████| 552kB 30.6MB/s \n",
      "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/site-packages (from botocore<1.16.0,>=1.15.39->boto3->pytorch-pretrained-bert) (2.7.5)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.16.0,>=1.15.39->boto3->pytorch-pretrained-bert) (1.12.0)\n",
      "\u001b[31mmenpo 0.8.1 has requirement matplotlib<2.0,>=1.4, but you'll have matplotlib 3.0.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mmenpo 0.8.1 has requirement pillow<5.0,>=3.0, but you'll have pillow 5.4.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mmenpo 0.8.1 has requirement scipy<1.0,>=0.16, but you'll have scipy 1.2.0 which is incompatible.\u001b[0m\n",
      "Installing collected packages: regex, docutils, jmespath, botocore, s3transfer, boto3, pytorch-pretrained-bert, pytorch-nlp\n",
      "Successfully installed boto3-1.12.39 botocore-1.15.39 docutils-0.15.2 jmespath-0.9.5 pytorch-nlp-0.5.0 pytorch-pretrained-bert-0.6.2 regex-2020.4.4 s3transfer-0.3.3\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch-pretrained-bert pytorch-nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2500,
     "status": "ok",
     "timestamp": 1571579181811,
     "user": {
      "displayName": "Jeff Jaskolka",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAxPoaD5czR7gp1OnGR14wAKPoLvTCIdkN9Bp5MTg=s64",
      "userId": "18090659719286838097"
     },
     "user_tz": 240
    },
    "id": "Ok002ceNB8E7",
    "outputId": "eb4ff100-bad7-44bd-ff2d-2afd408fde39"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertConfig\n",
    "from pytorch_pretrained_bert import BertAdam, BertForSequenceClassification\n",
    "from tqdm import tqdm, trange\n",
    "import pandas as pd\n",
    "import io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#% matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cqG7FzRVFEIv"
   },
   "source": [
    "In order for torch to use the GPU, we need to identify and specify the GPU as the device. Later, in our training loop, we will load data onto the device. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1012,
     "status": "ok",
     "timestamp": 1571579184010,
     "user": {
      "displayName": "Jeff Jaskolka",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAxPoaD5czR7gp1OnGR14wAKPoLvTCIdkN9Bp5MTg=s64",
      "userId": "18090659719286838097"
     },
     "user_tz": 240
    },
    "id": "oYsV4H8fCpZ-",
    "outputId": "ce1d5ac4-bac5-4223-f31b-aa9b21bc07b9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tesla V100-SXM2-16GB'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use this cell when working online\n",
    "path = '/floyd/home/ed-triage'\n",
    "data_path = '/floyd/home/data/combined'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b0HXL90y47tD"
   },
   "source": [
    "## second pass\n",
    "now going to figure out how to run this on the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-b_nZYT05Ae3"
   },
   "outputs": [],
   "source": [
    "def create_dummy_column(s):\n",
    "  if str(s) == 'nan':\n",
    "    return 'empty cell'\n",
    "  else:\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1276,
     "status": "ok",
     "timestamp": 1571579219303,
     "user": {
      "displayName": "Jeff Jaskolka",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAxPoaD5czR7gp1OnGR14wAKPoLvTCIdkN9Bp5MTg=s64",
      "userId": "18090659719286838097"
     },
     "user_tz": 240
    },
    "id": "Bqs-jcTP5Ius",
    "outputId": "fa40609b-c590-4557-cec7-14d466fc769a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(165433, 121)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(data_path + '/complete_clean_combo_data.csv', index_col = 0, low_memory = False)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>ChartNumber</th>\n",
       "      <th>EncounterNumber</th>\n",
       "      <th>TriageLevel</th>\n",
       "      <th>AgeNumber</th>\n",
       "      <th>AgeInYrs</th>\n",
       "      <th>GenderDesc</th>\n",
       "      <th>PIA Date &amp; Time</th>\n",
       "      <th>Disposition Date &amp; Time</th>\n",
       "      <th>DischargeDisposition</th>\n",
       "      <th>...</th>\n",
       "      <th>Reg Date &amp; Timeday_year_cos</th>\n",
       "      <th>Reg Date &amp; Timeday_year_sin</th>\n",
       "      <th>Reg Date &amp; Timehour_cos</th>\n",
       "      <th>Reg Date &amp; Timehour_sin</th>\n",
       "      <th>Reg Date &amp; Timeclock_cos</th>\n",
       "      <th>Reg Date &amp; Timeclock_sin</th>\n",
       "      <th>Reg Date &amp; Timemin_cos</th>\n",
       "      <th>Reg Date &amp; Timemin_sin</th>\n",
       "      <th>Reg Date &amp; Timesec_cos</th>\n",
       "      <th>Reg Date &amp; Timesec_sin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>149.0</td>\n",
       "      <td>N179474</td>\n",
       "      <td>NE000150/18</td>\n",
       "      <td>2.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>01/04/2018  12:25:00PM</td>\n",
       "      <td>01/04/2018   2:30:00PM</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998667</td>\n",
       "      <td>0.05162</td>\n",
       "      <td>-0.965926</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>8.660254e-01</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.809017</td>\n",
       "      <td>-0.587785</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>198.0</td>\n",
       "      <td>N798201</td>\n",
       "      <td>NE000199/18</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>01/04/2018   3:23:00PM</td>\n",
       "      <td>01/04/2018   4:13:00PM</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998667</td>\n",
       "      <td>0.05162</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.994522</td>\n",
       "      <td>0.104528</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>218.0</td>\n",
       "      <td>N798204</td>\n",
       "      <td>NE000225/18</td>\n",
       "      <td>2.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>01/04/2018   3:00:00PM</td>\n",
       "      <td>01/04/2018   5:05:00PM</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998667</td>\n",
       "      <td>0.05162</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>6.123234e-17</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.406737</td>\n",
       "      <td>0.913545</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>219.0</td>\n",
       "      <td>N110229</td>\n",
       "      <td>NE000226/18</td>\n",
       "      <td>2.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>01/04/2018   4:36:00PM</td>\n",
       "      <td>01/04/2018  11:00:00PM</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998667</td>\n",
       "      <td>0.05162</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>6.123234e-17</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.104528</td>\n",
       "      <td>0.994522</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>227.0</td>\n",
       "      <td>N739034</td>\n",
       "      <td>NE000222/18</td>\n",
       "      <td>4.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01/04/2018   3:30:00PM</td>\n",
       "      <td>63.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998667</td>\n",
       "      <td>0.05162</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>6.123234e-17</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 121 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID ChartNumber EncounterNumber  TriageLevel  AgeNumber  AgeInYrs  \\\n",
       "0  149.0     N179474     NE000150/18          2.0       43.0      43.0   \n",
       "1  198.0     N798201     NE000199/18          3.0       13.0      13.0   \n",
       "2  218.0     N798204     NE000225/18          2.0       23.0      23.0   \n",
       "3  219.0     N110229     NE000226/18          2.0       30.0      30.0   \n",
       "4  227.0     N739034     NE000222/18          4.0       36.0      36.0   \n",
       "\n",
       "  GenderDesc         PIA Date & Time Disposition Date & Time  \\\n",
       "0     Female  01/04/2018  12:25:00PM  01/04/2018   2:30:00PM   \n",
       "1     Female  01/04/2018   3:23:00PM  01/04/2018   4:13:00PM   \n",
       "2     Female  01/04/2018   3:00:00PM  01/04/2018   5:05:00PM   \n",
       "3     Female  01/04/2018   4:36:00PM  01/04/2018  11:00:00PM   \n",
       "4     Female                     NaN  01/04/2018   3:30:00PM   \n",
       "\n",
       "   DischargeDisposition          ...           Reg Date & Timeday_year_cos  \\\n",
       "0                  17.0          ...                              0.998667   \n",
       "1                  17.0          ...                              0.998667   \n",
       "2                  17.0          ...                              0.998667   \n",
       "3                  17.0          ...                              0.998667   \n",
       "4                  63.0          ...                              0.998667   \n",
       "\n",
       "  Reg Date & Timeday_year_sin  Reg Date & Timehour_cos  \\\n",
       "0                     0.05162                -0.965926   \n",
       "1                     0.05162                -0.866025   \n",
       "2                     0.05162                -0.707107   \n",
       "3                     0.05162                -0.707107   \n",
       "4                     0.05162                -0.707107   \n",
       "\n",
       "  Reg Date & Timehour_sin Reg Date & Timeclock_cos Reg Date & Timeclock_sin  \\\n",
       "0                0.258819             8.660254e-01                -0.500000   \n",
       "1               -0.500000             5.000000e-01                 0.866025   \n",
       "2               -0.707107             6.123234e-17                 1.000000   \n",
       "3               -0.707107             6.123234e-17                 1.000000   \n",
       "4               -0.707107             6.123234e-17                 1.000000   \n",
       "\n",
       "  Reg Date & Timemin_cos Reg Date & Timemin_sin Reg Date & Timesec_cos  \\\n",
       "0               0.809017              -0.587785                    1.0   \n",
       "1               0.994522               0.104528                    1.0   \n",
       "2               0.406737               0.913545                    1.0   \n",
       "3               0.104528               0.994522                    1.0   \n",
       "4               0.866025               0.500000                    1.0   \n",
       "\n",
       "  Reg Date & Timesec_sin  \n",
       "0                    0.0  \n",
       "1                    0.0  \n",
       "2                    0.0  \n",
       "3                    0.0  \n",
       "4                    0.0  \n",
       "\n",
       "[5 rows x 121 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZZB-FL7K5LBe"
   },
   "outputs": [],
   "source": [
    "data['for embedding'] = data.CleanSubjectiveNotes.map(create_dummy_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HGUlz_bo595x"
   },
   "outputs": [],
   "source": [
    "sentences = data['for embedding'].values\n",
    "\n",
    "# We need to add special tokens at the beginning and end of each sentence for BERT to work properly\n",
    "sentences = [\"[CLS] \" + sentence + \" [SEP]\" for sentence in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 37782,
     "status": "ok",
     "timestamp": 1571579393262,
     "user": {
      "displayName": "Jeff Jaskolka",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAxPoaD5czR7gp1OnGR14wAKPoLvTCIdkN9Bp5MTg=s64",
      "userId": "18090659719286838097"
     },
     "user_tz": 240
    },
    "id": "hCAcGIEr63hQ",
    "outputId": "e1881cda-55ba-43d9-96f4-05721bf21f35"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 231508/231508 [00:00<00:00, 1021109.54B/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenize the first sentence:\n",
      "['[CLS]', 'patient', 'states', 'that', 'she', 'feels', 'shaky', '.', 'patient', 'denies', 'any', 'pain', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "\n",
    "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
    "print (\"Tokenize the first sentence:\")\n",
    "print (tokenized_texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 35298,
     "status": "ok",
     "timestamp": 1571579393263,
     "user": {
      "displayName": "Jeff Jaskolka",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAxPoaD5czR7gp1OnGR14wAKPoLvTCIdkN9Bp5MTg=s64",
      "userId": "18090659719286838097"
     },
     "user_tz": 240
    },
    "id": "21dBlHkebaac",
    "outputId": "e6ae4500-fbdc-46f8-c9ab-350477c5b1ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "show a few other tokenized sentences\n",
      "['[CLS]', 'patient', 'states', 'everything', 'is', 'ok', '.', 'denies', 'any', 'head', 'pain', '.', '[SEP]']\n",
      "['[CLS]', 'patient', 'had', 'an', 'renal', 'ultrasound', 'today', 'and', 'coming', 'back', 'for', 'the', 'result', 'her', 'cr', '##ea', '##tin', '##ine', 'was', 'elevated', ',', 'also', 'complain', '##s', 'of', 'head', '##ca', '##he', 'for', 'over', 'a', 'week', 'no', 'blur', '##ry', 'vision', 'nausea', '##ted', 'no', 'vomiting', '.', '[SEP]']\n",
      "['[CLS]', 'patient', 'slipped', 'and', 'fell', 'at', '22', '00', ',', 'head', 'hit', 'to', 'concrete', 'and', 'had', 'small', 'hem', '##ato', '##ma', 'x', '2', 'on', 'the', 'back', 'of', 'the', 'head', ',', 'lost', 'lo', '##c', 'x', '1', 'mt', '.', '[SEP]']\n",
      "['[CLS]', 'sts', 'playing', 'basketball', ',', 'twisted', 'left', 'ankle', ',', 'with', 'swelling', ',', 'pain', 'with', 'movement', ',', 'with', 'ice', 'packed', 'on', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "print ('show a few other tokenized sentences')\n",
    "print (tokenized_texts[10])\n",
    "print (tokenized_texts[100])\n",
    "print (tokenized_texts[1000])\n",
    "print (tokenized_texts[10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5EvIzO21KuOQ"
   },
   "outputs": [],
   "source": [
    "data['tokenized_subj_notes'] = sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['tokenized_subj_notes'].to_csv(data_path + '/tokenized_subj_notes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1291,
     "status": "ok",
     "timestamp": 1571579435728,
     "user": {
      "displayName": "Jeff Jaskolka",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAxPoaD5czR7gp1OnGR14wAKPoLvTCIdkN9Bp5MTg=s64",
      "userId": "18090659719286838097"
     },
     "user_tz": 240
    },
    "id": "9rhnM8oz63hV",
    "outputId": "93b8e93c-67df-4843-af02-f581c8c67c9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean sentence length 47.59394437627317\n",
      "max sentence length 268\n"
     ]
    }
   ],
   "source": [
    "sent_lens = [len(x) for x in tokenized_texts]\n",
    "print ('mean sentence length', np.mean(sent_lens))\n",
    "print ('max sentence length', np.max(sent_lens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LD756WGw63hX"
   },
   "outputs": [],
   "source": [
    "# Set the maximum sequence length. The longest sequence in our training set is 47, but we'll leave room on the end anyway. \n",
    "# In the original paper, the authors used a length of 512.\n",
    "MAX_LEN = np.max(sent_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b55KVcvi63hb"
   },
   "outputs": [],
   "source": [
    "# Use the BERT tokenizer to convert the tokens to their index numbers in the BERT vocabulary\n",
    "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LBYrmzqi63hd"
   },
   "outputs": [],
   "source": [
    "# Pad our input tokens\n",
    "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EXVmnYSc63hf"
   },
   "outputs": [],
   "source": [
    "# Create attention masks\n",
    "attention_masks = []\n",
    "\n",
    "# Create a mask of 1s for each token followed by 0s for padding\n",
    "for seq in input_ids:\n",
    "  seq_mask = [float(i>0) for i in seq]\n",
    "  attention_masks.append(seq_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IXy57DA063hg"
   },
   "outputs": [],
   "source": [
    "# Convert all of our data into torch tensors, the required datatype for our model\n",
    "\n",
    "train_inputs = torch.tensor(input_ids)\n",
    "train_masks = torch.tensor(attention_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b18X9iAT63hh"
   },
   "outputs": [],
   "source": [
    "# Select a batch size for training. For fine-tuning BERT on a specific task, the authors recommend a batch size of 16 or 32\n",
    "batch_size = 16\n",
    "\n",
    "# Create an iterator of our data with torch DataLoader. This helps save on memory during training because, unlike a for loop, \n",
    "# with an iterator the entire dataset does not need to be loaded into memory\n",
    "\n",
    "train_data = TensorDataset(train_inputs, train_masks)\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 29010,
     "status": "ok",
     "timestamp": 1571579502159,
     "user": {
      "displayName": "Jeff Jaskolka",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAxPoaD5czR7gp1OnGR14wAKPoLvTCIdkN9Bp5MTg=s64",
      "userId": "18090659719286838097"
     },
     "user_tz": 240
    },
    "id": "4iLZ41QQ63hk",
    "outputId": "00ec8ddf-cc3f-4ee9-ffce-23d60f0741ba"
   },
   "outputs": [],
   "source": [
    "#we are going to download the model and transfer it to cuda\n",
    "from pytorch_pretrained_bert import BertModel\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "model.cuda();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QVYAX-Rszk3N"
   },
   "source": [
    "## sentence embedding below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "ZSKQNxulb07u",
    "outputId": "6a3010de-7f6e-4d0c-8b24-abdb2ed78db4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch #: 1\n",
      "results stored...\n",
      "batch #: 501\n",
      "results stored...\n",
      "batch #: 1001\n",
      "results stored...\n",
      "batch #: 1501\n",
      "results stored...\n",
      "batch #: 2001\n",
      "results stored...\n",
      "batch #: 2501\n",
      "results stored...\n",
      "batch #: 3001\n",
      "results stored...\n",
      "batch #: 3501\n",
      "results stored...\n",
      "batch #: 4001\n",
      "results stored...\n",
      "batch #: 4501\n",
      "results stored...\n",
      "batch #: 5001\n",
      "results stored...\n",
      "batch #: 5501\n",
      "results stored...\n",
      "batch #: 6001\n",
      "results stored...\n",
      "batch #: 6501\n",
      "results stored...\n",
      "batch #: 7001\n",
      "results stored...\n",
      "batch #: 7501\n",
      "results stored...\n",
      "batch #: 8001\n",
      "results stored...\n",
      "batch #: 8501\n",
      "results stored...\n",
      "batch #: 9001\n",
      "results stored...\n",
      "batch #: 9501\n",
      "results stored...\n",
      "batch #: 10001\n",
      "results stored...\n"
     ]
    }
   ],
   "source": [
    "#gonna redo, but this time only keep the sentences\n",
    "model.eval()\n",
    "embedded_notes = []\n",
    "for i, x in enumerate(train_dataloader):\n",
    "  \n",
    "    inpseq = x[0].to(device)\n",
    "    inpmask = x[1].to(device)\n",
    "    embeds,_ = model(inpseq, attention_mask = inpmask)\n",
    "    sentence_vec = torch.mean(embeds[11],1)  #this is supposedly where the sentences are\n",
    "    embedded_notes.append(sentence_vec.cpu().detach().numpy())\n",
    "    if i%500 == 0:\n",
    "        print ('batch #:', i+1)\n",
    "        print ('results stored...')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1048,
     "status": "ok",
     "timestamp": 1571518359821,
     "user": {
      "displayName": "Jeff Jaskolka",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAxPoaD5czR7gp1OnGR14wAKPoLvTCIdkN9Bp5MTg=s64",
      "userId": "18090659719286838097"
     },
     "user_tz": 240
    },
    "id": "i3u7sMImcsRg",
    "outputId": "78103e7a-81d3-4122-89f3-556449a90c64"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10340"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embedded_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KxLojYYzdosp"
   },
   "outputs": [],
   "source": [
    "flat_sentences = [item for sublist in embedded_notes for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d-sis2hQz2Xw"
   },
   "outputs": [],
   "source": [
    "data['embedded_subjnotes'] = flat_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 840,
     "status": "ok",
     "timestamp": 1571518968809,
     "user": {
      "displayName": "Jeff Jaskolka",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAxPoaD5czR7gp1OnGR14wAKPoLvTCIdkN9Bp5MTg=s64",
      "userId": "18090659719286838097"
     },
     "user_tz": 240
    },
    "id": "WihDHnpG1FF8",
    "outputId": "683b43fc-1f61-4054-bb45-ab3e2f56a9a2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [-0.15257795, -0.26369357, 0.53711694, 0.09271...\n",
       "1    [-0.089328445, -0.10715083, 0.27685848, -0.280...\n",
       "2    [-0.24219792, 0.25459412, 0.08023955, 0.024560...\n",
       "3    [-0.007053161, -0.15278126, 0.15155132, -0.132...\n",
       "4    [-0.22487935, 0.059827298, 0.26115206, -0.2373...\n",
       "Name: embedded_subjnotes, dtype: object"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['embedded_subjnotes'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_embed_df = pd.DataFrame(flat_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 534895,
     "status": "ok",
     "timestamp": 1571519625421,
     "user": {
      "displayName": "Jeff Jaskolka",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAxPoaD5czR7gp1OnGR14wAKPoLvTCIdkN9Bp5MTg=s64",
      "userId": "18090659719286838097"
     },
     "user_tz": 240
    },
    "id": "9zVd1f7H1MbA",
    "outputId": "8c800d7b-a9ee-4159-d006-59c677825827"
   },
   "outputs": [],
   "source": [
    "subj_embed_df.to_csv(data_path + '/subjnote_embeds.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RmqSACnc2Vlm"
   },
   "source": [
    "## now gonna sentence embed medical history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BOzGihsu2p8n"
   },
   "outputs": [],
   "source": [
    "#need an way to handle empty cells so i can still embed the whole dataset and plug it back into the dataframe\n",
    "data['for embedding'] = data['CleanMedicalHistory'].map(create_dummy_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-Mk50kP32p8q"
   },
   "outputs": [],
   "source": [
    "sentences = data['for embedding'].values\n",
    "\n",
    "# We need to add special tokens at the beginning and end of each sentence for BERT to work properly\n",
    "sentences = [\"[CLS] \" + sentence + \" [SEP]\" for sentence in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10905,
     "status": "ok",
     "timestamp": 1571519816776,
     "user": {
      "displayName": "Jeff Jaskolka",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAxPoaD5czR7gp1OnGR14wAKPoLvTCIdkN9Bp5MTg=s64",
      "userId": "18090659719286838097"
     },
     "user_tz": 240
    },
    "id": "udl407md2p8s",
    "outputId": "51d206c3-dffa-479e-bbbc-bbc1bde98e59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenize the first sentence:\n",
      "['[CLS]', 'no', 'significant', 'medical', 'history', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "\n",
    "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
    "print (\"Tokenize the first sentence:\")\n",
    "print (tokenized_texts[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9353,
     "status": "ok",
     "timestamp": 1571519816778,
     "user": {
      "displayName": "Jeff Jaskolka",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAxPoaD5czR7gp1OnGR14wAKPoLvTCIdkN9Bp5MTg=s64",
      "userId": "18090659719286838097"
     },
     "user_tz": 240
    },
    "id": "olUheiYj4NlB",
    "outputId": "7e12748d-d23d-41cf-d3c6-1150015391fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "show a few other tokenized sentences\n",
      "['[CLS]', 'no', 'significant', 'medical', 'history', '[SEP]']\n",
      "['[CLS]', 'h', '##yp', '##oth', '##yr', '##oid', '[SEP]']\n",
      "['[CLS]', 'no', 'significant', 'medical', 'history', '[SEP]']\n",
      "['[CLS]', 'ad', '##hd', '(', 'attention', 'deficit', 'hyper', '##act', '##ivity', 'disorder', ')', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "print ('show a few other tokenized sentences')\n",
    "print (tokenized_texts[10])\n",
    "print (tokenized_texts[100])\n",
    "print (tokenized_texts[1000])\n",
    "print (tokenized_texts[10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VI5yqO0B2p8u"
   },
   "outputs": [],
   "source": [
    "data['tokenized_medhx'] = sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 852,
     "status": "ok",
     "timestamp": 1571519827354,
     "user": {
      "displayName": "Jeff Jaskolka",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAxPoaD5czR7gp1OnGR14wAKPoLvTCIdkN9Bp5MTg=s64",
      "userId": "18090659719286838097"
     },
     "user_tz": 240
    },
    "id": "KdSlUgJz2p8z",
    "outputId": "f05b6b3b-876a-4e33-95f8-a2ad89734dbd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean sentence length: 9.551733934583789\n",
      "max sentence length: 107\n"
     ]
    }
   ],
   "source": [
    "sent_lens = [len(x) for x in tokenized_texts]\n",
    "print ('mean sentence length:', np.mean(sent_lens))\n",
    "print ('max sentence length:', np.max(sent_lens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C50RE0Dm2p81"
   },
   "outputs": [],
   "source": [
    "# Set the maximum sequence length. The longest sequence in our training set is 47, but we'll leave room on the end anyway. \n",
    "# In the original paper, the authors used a length of 512.\n",
    "MAX_LEN = np.max(sent_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QkCSa_Bc2p84"
   },
   "outputs": [],
   "source": [
    "# Use the BERT tokenizer to convert the tokens to their index numbers in the BERT vocabulary\n",
    "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OQaMAuia2p86"
   },
   "outputs": [],
   "source": [
    "# Pad our input tokens\n",
    "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DMjxtTBA2p87"
   },
   "source": [
    "Create the attention masks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0oM9YlQH2p88"
   },
   "outputs": [],
   "source": [
    "# Create attention masks\n",
    "attention_masks = []\n",
    "\n",
    "# Create a mask of 1s for each token followed by 0s for padding\n",
    "for seq in input_ids:\n",
    "    seq_mask = [float(i>0) for i in seq]\n",
    "    attention_masks.append(seq_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ryorOZKh2p89"
   },
   "outputs": [],
   "source": [
    "# Convert all of our data into torch tensors, the required datatype for our model\n",
    "\n",
    "train_inputs = torch.tensor(input_ids)\n",
    "train_masks = torch.tensor(attention_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ff4rOgd22p8_"
   },
   "outputs": [],
   "source": [
    "# Select a batch size for training. For fine-tuning BERT on a specific task, the authors recommend a batch size of 16 or 32\n",
    "batch_size = 16\n",
    "\n",
    "# Create an iterator of our data with torch DataLoader. This helps save on memory during training because, unlike a for loop, \n",
    "# with an iterator the entire dataset does not need to be loaded into memory\n",
    "\n",
    "train_data = TensorDataset(train_inputs, train_masks)\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vUwMVWFk2p9B"
   },
   "outputs": [],
   "source": [
    "#we are going to download the model and transfer it to cuda\n",
    "from pytorch_pretrained_bert import BertModel\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "model.cuda();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1093853,
     "status": "ok",
     "timestamp": 1571520969916,
     "user": {
      "displayName": "Jeff Jaskolka",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAxPoaD5czR7gp1OnGR14wAKPoLvTCIdkN9Bp5MTg=s64",
      "userId": "18090659719286838097"
     },
     "user_tz": 240
    },
    "id": "2lOAiTVR3Lli",
    "outputId": "49aaa2ba-791a-40b6-9215-ec7ef1e101f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch #: 1\n",
      "results stored...\n",
      "batch #: 501\n",
      "results stored...\n",
      "batch #: 1001\n",
      "results stored...\n",
      "batch #: 1501\n",
      "results stored...\n",
      "batch #: 2001\n",
      "results stored...\n",
      "batch #: 2501\n",
      "results stored...\n",
      "batch #: 3001\n",
      "results stored...\n",
      "batch #: 3501\n",
      "results stored...\n",
      "batch #: 4001\n",
      "results stored...\n",
      "batch #: 4501\n",
      "results stored...\n",
      "batch #: 5001\n",
      "results stored...\n",
      "batch #: 5501\n",
      "results stored...\n",
      "batch #: 6001\n",
      "results stored...\n",
      "batch #: 6501\n",
      "results stored...\n",
      "batch #: 7001\n",
      "results stored...\n",
      "batch #: 7501\n",
      "results stored...\n",
      "batch #: 8001\n",
      "results stored...\n",
      "batch #: 8501\n",
      "results stored...\n",
      "batch #: 9001\n",
      "results stored...\n",
      "batch #: 9501\n",
      "results stored...\n",
      "batch #: 10001\n",
      "results stored...\n"
     ]
    }
   ],
   "source": [
    "#gonna redo, but this time only keep the sentences\n",
    "model.eval()\n",
    "embedded_notes = []\n",
    "for i, x in enumerate(train_dataloader):\n",
    "  \n",
    "    inpseq = x[0].to(device)\n",
    "    inpmask = x[1].to(device)\n",
    "    embeds,_ = model(inpseq, attention_mask = inpmask)\n",
    "    sentence_vec = torch.mean(embeds[11],1)  #this is supposedly where the sentences are\n",
    "    embedded_notes.append(sentence_vec.cpu().detach().numpy())\n",
    "    if i%500 == 0:\n",
    "        print ('batch #:', i+1)\n",
    "        print ('results stored...')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1048,
     "status": "ok",
     "timestamp": 1571518359821,
     "user": {
      "displayName": "Jeff Jaskolka",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAxPoaD5czR7gp1OnGR14wAKPoLvTCIdkN9Bp5MTg=s64",
      "userId": "18090659719286838097"
     },
     "user_tz": 240
    },
    "id": "i3u7sMImcsRg",
    "outputId": "78103e7a-81d3-4122-89f3-556449a90c64"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10340"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embedded_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KxLojYYzdosp"
   },
   "outputs": [],
   "source": [
    "flat_sentences = [item for sublist in embedded_notes for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmhx_embed_df = pd.DataFrame(flat_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3b60bU073chl"
   },
   "outputs": [],
   "source": [
    "pmhx_embed_df.to_csv(data_path + '/pmhx_embeds.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "BERT for embedding.ipynb",
   "provenance": [
    {
     "file_id": "10SI-59huCzMvDOlVJZZRNZ0trAZeIj9g",
     "timestamp": 1571430967692
    },
    {
     "file_id": "1ywsvwO6thOVOrfagjjfuxEf6xVRxbUNO",
     "timestamp": 1570654919298
    },
    {
     "file_id": "1f_snPs--PVYgZJwT3GwjxqVALFJ0T2-y",
     "timestamp": 1556493831452
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
