{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gonna use XGB now to combine the categorical, continuous and pre-embedded free text stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Online, we import the usual packages. **xgboost** needs to be installed (with conda install xgboost or pip install -U xgboost)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Using cached https://files.pythonhosted.org/packages/96/84/4e2cae6247f397f83d8adc5c2a2a0c5d7d790a14a4c7400ff6574586f589/xgboost-0.90.tar.gz\n",
      "Requirement already satisfied: numpy in /Users/jjaskolkambp/anaconda3/lib/python3.6/site-packages (from xgboost) (1.14.3)\n",
      "Requirement already satisfied: scipy in /Users/jjaskolkambp/anaconda3/lib/python3.6/site-packages (from xgboost) (1.1.0)\n",
      "Building wheels for collected packages: xgboost\n",
      "  Running setup.py bdist_wheel for xgboost ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/jjaskolkambp/Library/Caches/pip/wheels/e9/48/4d/de4187b5270dff71d3697c5a7857a1e2d9a0c63a28b3462eeb\n",
      "Successfully built xgboost\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-0.90\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.2.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#!pip install xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  the usual imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import sklearn.metrics\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import random as rn\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def thresholding_analysis(preds, targets, admission_thresholds = [0.01, 0.05, 0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]):\n",
    "\n",
    "    i = 0\n",
    "    for thresh in admission_thresholds:\n",
    "        thresholded_predictions = [0 if prob[0] >= thresh else 1 for prob in preds]\n",
    "        \n",
    "        f1_w, f1, acc, prec, rec,= get_metrics(targets,thresholded_predictions, print_output = False)\n",
    "\n",
    "        if i == 0:\n",
    "            output_df = pd.DataFrame([thresh, f1_w, f1, acc, prec, rec, rec[0], rec[1]]).T\n",
    "            output_df.columns = ['admission_threshold', 'weighted f1', 'f1', 'accuracy', 'precision', 'recall', 'admission sensitivity', 'admission specificity']\n",
    "        else:\n",
    "            output_df.loc[len(output_df)] = [thresh, f1_w, f1, acc, prec, rec, rec[0], rec[1]]\n",
    "        i+=1\n",
    "    \n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364
    },
    "colab_type": "code",
    "id": "zoR-h8cO52Se",
    "outputId": "17db8de9-e516-4064-ec30-42bdd9542f65"
   },
   "outputs": [],
   "source": [
    "def show_confusion_matrix(targets, predictions, labels):\n",
    "    LABELS = labels\n",
    "\n",
    "    confusion_matrix = sklearn.metrics.confusion_matrix(targets, predictions)\n",
    "\n",
    "    plt.figure(figsize=(3, 3))\n",
    "    sns.heatmap(confusion_matrix, xticklabels=LABELS, yticklabels=LABELS, annot=True, fmt=\"d\", annot_kws={\"size\": 15});\n",
    "    plt.title(\"Confusion matrix\", fontsize=10)\n",
    "    plt.ylabel('True label', fontsize=10)\n",
    "    plt.xlabel('Predicted label', fontsize=10)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(y_test, preds, print_output = True):\n",
    "    f1_w = sklearn.metrics.f1_score(y_test, preds, average='weighted')\n",
    "    f1 = sklearn.metrics.f1_score(y_test, preds, average=None)\n",
    "    acc = sklearn.metrics.accuracy_score(y_test, preds)\n",
    "    prec = sklearn.metrics.precision_score(y_test,preds, average=None) \n",
    "    rec = sklearn.metrics.recall_score(y_test,preds, average=None)\n",
    "    \n",
    "    if print_output:\n",
    "        print ('weighted f1: ', f1_w)\n",
    "        print ('f1:          ', f1)\n",
    "        print ('accuracy:    ', acc)\n",
    "        print ('precision:   ', prec)\n",
    "        print ('recall:      ', rec)\n",
    "        print ('admission sens: ', rec[0])\n",
    "        print ('admission spec: ', rec[1])\n",
    "            \n",
    "    return f1_w, f1, acc, prec, rec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def JJ_gridsearch(weights, print_output = False):\n",
    "    epoch = 0\n",
    "    for weight in weights:\n",
    "        \n",
    "        xgc = xgb.XGBClassifier(scale_pos_weight=weight)\n",
    "        xgc.fit(X_train, y_train)\n",
    "        preds = xgc.predict(X_test)\n",
    "        probas = xgc.predict_proba(X_test)\n",
    "        f1_w, f1, acc, prec, rec = get_metrics(y_test, preds, print_output)\n",
    "        \n",
    "        if epoch == 0:\n",
    "            results_df = pd.DataFrame([epoch+1, 1/weight, f1_w, f1, acc, prec, rec, rec[0], rec[1]]).T\n",
    "            results_df.columns = ['trial number', 'class penalty', 'weighted f1', 'f1', 'accuracy', 'precision', 'recall', 'admission sensitivity', 'admission specificity']\n",
    "        else:\n",
    "            results_df.loc[len(results_df)] = [epoch+1, 1/weight, f1_w, f1, acc, prec, rec, rec[0], rec[1]]\n",
    "        \n",
    "        epoch +=1\n",
    "        \n",
    "    return xgc, results_df, preds, probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use this cell when working from home\n",
    "path = '/Users/jjaskolkambp/Desktop/machine learning/my_projects/ed-triage'\n",
    "data_path = '/Users/jjaskolkambp/Desktop/machine learning/my_projects/data/ED triage project/combo'\n",
    "model_path = '/Users/jjaskolkambp/Desktop/machine learning/my_projects/ed-triage/models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "clin = pd.read_csv(data_path + '/complete_clean_combo_data.csv', index_col = 0,low_memory = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dx_code_dict = {code:i for i,code in enumerate(set(clin['MainDiagnosisCode']))}\n",
    "\n",
    "def convert_dxcode(s):\n",
    "    code = dx_code_dict[s]\n",
    "    return (code)\n",
    "\n",
    "clin['recoded_diagnosis'] = clin['MainDiagnosisCode'].map(convert_dxcode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "medhx = np.load(data_path + '/medhx_embeds.npy')\n",
    "\n",
    "#this is the admit vs d/c target\n",
    "target = np.load(data_path + '/admit_dc_target.npy')\n",
    "\n",
    "subjnotes = np.load(data_path + '/subj_emeds.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this cell will define the various groupings of variables from the dataframe\n",
    "dx_vars = ['recoded_diagnosis', 'PresentingComplaint']\n",
    "\n",
    "cont_vars = [ 'Triage Date & TimeYear', 'Triage Date & TimeMonth', 'Triage Date & TimeWeek', 'Triage Date & TimeDay',\n",
    " 'Triage Date & TimeDayofweek', 'Triage Date & TimeDayofyear', 'Triage Date & TimeHour', 'Triage Date & TimeMinute',\n",
    " 'Triage Date & TimeSecond', 'Triage Date & TimeElapsed',\n",
    " 'num_comorbids','systolic', 'diastolic', 'o2sat', 'pulse', 'temp', 'AgeInYrs']\n",
    "\n",
    "\n",
    "cos_date_vars = ['Triage Date & Timeweekday_cos',\n",
    "       'Triage Date & Timeweekday_sin', 'Triage Date & Timeday_month_cos',\n",
    "       'Triage Date & Timeday_month_sin', 'Triage Date & Timemonth_year_cos',\n",
    "       'Triage Date & Timemonth_year_sin', 'Triage Date & Timeday_year_cos',\n",
    "       'Triage Date & Timeday_year_sin', 'Triage Date & Timehour_cos',\n",
    "       'Triage Date & Timehour_sin', 'Triage Date & Timeclock_cos',\n",
    "       'Triage Date & Timeclock_sin', 'Triage Date & Timemin_cos',\n",
    "       'Triage Date & Timemin_sin', 'Triage Date & Timesec_cos']\n",
    "\n",
    "cat_vars = ['Triage Date & TimeIs_month_end',\n",
    " 'Triage Date & TimeIs_month_start',\n",
    " 'Triage Date & TimeIs_quarter_end',\n",
    " 'Triage Date & TimeIs_quarter_start',\n",
    " 'Triage Date & TimeIs_year_end',\n",
    " 'Triage Date & TimeIs_year_start',\n",
    " 'GenderDesc']\n",
    "\n",
    "inf_control_vars = ['Are you feeling feverish or have had shakes or chills in the last 24 hours?',\n",
    " 'Have you ever been isolated/required isolation for an infectious disease when receiving care in a healthcare setting?',\n",
    " 'Do you have a new Rash?',\n",
    " 'Do you have a new onset of Vomiting/Diarrhea in the last 24 hours?',\n",
    " 'Have you travelled outside of Canada/USA in the last 3 weeks?',\n",
    " 'Have you had contact with a sick person who has travelled outside of Canada/USA in the last 3 weeks?',\n",
    " 'Have you received Health Care in another country in the last 2 years?',\n",
    " 'Do you have a new/worse cough or shortness of breath?',\n",
    " 'If so, select all countries that apply',\n",
    " 'If so, select all infectious diseases that apply']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1.0: 149218, 0.0: 16215})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sanity checking output variables\n",
    "Counter(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### preprocessing variables to use in XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#need to preprocess cat vars for xgb\n",
    "X = clin[cat_vars + inf_control_vars].values.astype(str)\n",
    "\n",
    "features = []\n",
    "for i in range(0, X.shape[1]):\n",
    "    label_encoder = LabelEncoder()\n",
    "    feature = label_encoder.fit_transform(X[:,i])\n",
    "    features.append(feature)\n",
    "encoded_x = np.array(features)\n",
    "encoded_x = encoded_x.reshape(X.shape[0], X.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(165433, 17)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: :  (165433, 3702)\n"
     ]
    }
   ],
   "source": [
    "X2 = clin[dx_vars].values.astype(str)\n",
    "encoded_x2 = None\n",
    "for i in range(0, X2.shape[1]):\n",
    "\tlabel_encoder = LabelEncoder()\n",
    "\tfeature = label_encoder.fit_transform(X2[:,i])\n",
    "\tfeature = feature.reshape(X2.shape[0], 1)\n",
    "\tonehot_encoder = OneHotEncoder(sparse=False)\n",
    "\tfeature = onehot_encoder.fit_transform(feature)\n",
    "\tif encoded_x2 is None:\n",
    "\t\tencoded_x2 = feature\n",
    "\telse:\n",
    "\t\tencoded_x2 = np.concatenate((encoded_x2, feature), axis=1)\n",
    "print(\"X shape: : \", encoded_x2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#splitting this one hot encoded matrix into one for the presenting complaint and one for the medical history\n",
    "X_pres = encoded_x2[:,:169]\n",
    "\n",
    "X_dx = encoded_x2[:,169:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gonna do this first pass with just tabular type variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11min 7s, sys: 10.7 s, total: 11min 17s\n",
      "Wall time: 11min 23s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jjaskolkambp/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weighted f1:  0.825825525531334\n",
      "f1:           [0.40011    0.87200023]\n",
      "accuracy:     0.7890181097221887\n",
      "precision:    [0.27716925 0.96315619]\n",
      "recall:       [0.71905115 0.79660699]\n",
      "admission sens:  0.7190511489992587\n",
      "admission spec:  0.7966069897084048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jjaskolkambp/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/jjaskolkambp/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/jjaskolkambp/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/jjaskolkambp/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/jjaskolkambp/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/jjaskolkambp/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admission_threshold</th>\n",
       "      <th>weighted f1</th>\n",
       "      <th>f1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>admission sensitivity</th>\n",
       "      <th>admission specificity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0174427</td>\n",
       "      <td>[0.17825837994978638, 0.0]</td>\n",
       "      <td>0.0978505</td>\n",
       "      <td>[0.09785052830097439, 0.0]</td>\n",
       "      <td>[1.0, 0.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0174427</td>\n",
       "      <td>[0.17825837994978638, 0.0]</td>\n",
       "      <td>0.0978505</td>\n",
       "      <td>[0.09785052830097439, 0.0]</td>\n",
       "      <td>[1.0, 0.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0355414</td>\n",
       "      <td>[0.1797428438187027, 0.019900761535808102]</td>\n",
       "      <td>0.106917</td>\n",
       "      <td>[0.09874585203982042, 1.0]</td>\n",
       "      <td>[1.0, 0.010050385934819897]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0100504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.239234</td>\n",
       "      <td>[0.20033322557381944, 0.243453711328079]</td>\n",
       "      <td>0.222491</td>\n",
       "      <td>[0.11137532489078139, 0.9963412285769305]</td>\n",
       "      <td>[0.9953051643192489, 0.13866852487135506]</td>\n",
       "      <td>0.995305</td>\n",
       "      <td>0.138669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.550023</td>\n",
       "      <td>[0.2571572411478436, 0.5817886363206923]</td>\n",
       "      <td>0.464857</td>\n",
       "      <td>[0.14878825539847756, 0.9861636025879188]</td>\n",
       "      <td>[0.9466271312083024, 0.4126018439108062]</td>\n",
       "      <td>0.946627</td>\n",
       "      <td>0.412602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.732108</td>\n",
       "      <td>[0.3310391298069981, 0.7756090473192231]</td>\n",
       "      <td>0.663943</td>\n",
       "      <td>[0.20555887627017333, 0.9753136546347801]</td>\n",
       "      <td>[0.8497652582159625, 0.6437875214408233]</td>\n",
       "      <td>0.849765</td>\n",
       "      <td>0.643788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.825826</td>\n",
       "      <td>[0.40010999587515467, 0.8720002347004635]</td>\n",
       "      <td>0.789018</td>\n",
       "      <td>[0.27716925421468713, 0.9631561892417368]</td>\n",
       "      <td>[0.7190511489992587, 0.7966069897084048]</td>\n",
       "      <td>0.719051</td>\n",
       "      <td>0.796607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.876093</td>\n",
       "      <td>[0.45319910947633335, 0.9219611256164781]</td>\n",
       "      <td>0.863415</td>\n",
       "      <td>[0.372533418204965, 0.9513613684960799]</td>\n",
       "      <td>[0.5784531751914999, 0.8943235420240138]</td>\n",
       "      <td>0.578453</td>\n",
       "      <td>0.894324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.899054</td>\n",
       "      <td>[0.4527260179434093, 0.94746465623468]</td>\n",
       "      <td>0.904132</td>\n",
       "      <td>[0.5128205128205128, 0.9369251329891775]</td>\n",
       "      <td>[0.4052384482332592, 0.9582439965694682]</td>\n",
       "      <td>0.405238</td>\n",
       "      <td>0.958244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.893984</td>\n",
       "      <td>[0.3373358348968105, 0.9543598490722076]</td>\n",
       "      <td>0.914601</td>\n",
       "      <td>[0.700701480904131, 0.9214492464317796]</td>\n",
       "      <td>[0.22213985668396344, 0.9897084048027445]</td>\n",
       "      <td>0.22214</td>\n",
       "      <td>0.989708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.869336</td>\n",
       "      <td>[0.114735137635901, 0.9511831111678041]</td>\n",
       "      <td>0.907469</td>\n",
       "      <td>[0.8985507246376812, 0.9075286614901541]</td>\n",
       "      <td>[0.061279960464541636, 0.9992495711835334]</td>\n",
       "      <td>0.06128</td>\n",
       "      <td>0.99925</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   admission_threshold weighted f1  \\\n",
       "0                 0.01   0.0174427   \n",
       "1                 0.05   0.0174427   \n",
       "2                  0.1   0.0355414   \n",
       "3                  0.2    0.239234   \n",
       "4                  0.3    0.550023   \n",
       "5                  0.4    0.732108   \n",
       "6                  0.5    0.825826   \n",
       "7                  0.6    0.876093   \n",
       "8                  0.7    0.899054   \n",
       "9                  0.8    0.893984   \n",
       "10                 0.9    0.869336   \n",
       "\n",
       "                                            f1   accuracy  \\\n",
       "0                   [0.17825837994978638, 0.0]  0.0978505   \n",
       "1                   [0.17825837994978638, 0.0]  0.0978505   \n",
       "2   [0.1797428438187027, 0.019900761535808102]   0.106917   \n",
       "3     [0.20033322557381944, 0.243453711328079]   0.222491   \n",
       "4     [0.2571572411478436, 0.5817886363206923]   0.464857   \n",
       "5     [0.3310391298069981, 0.7756090473192231]   0.663943   \n",
       "6    [0.40010999587515467, 0.8720002347004635]   0.789018   \n",
       "7    [0.45319910947633335, 0.9219611256164781]   0.863415   \n",
       "8       [0.4527260179434093, 0.94746465623468]   0.904132   \n",
       "9     [0.3373358348968105, 0.9543598490722076]   0.914601   \n",
       "10     [0.114735137635901, 0.9511831111678041]   0.907469   \n",
       "\n",
       "                                    precision  \\\n",
       "0                  [0.09785052830097439, 0.0]   \n",
       "1                  [0.09785052830097439, 0.0]   \n",
       "2                  [0.09874585203982042, 1.0]   \n",
       "3   [0.11137532489078139, 0.9963412285769305]   \n",
       "4   [0.14878825539847756, 0.9861636025879188]   \n",
       "5   [0.20555887627017333, 0.9753136546347801]   \n",
       "6   [0.27716925421468713, 0.9631561892417368]   \n",
       "7     [0.372533418204965, 0.9513613684960799]   \n",
       "8    [0.5128205128205128, 0.9369251329891775]   \n",
       "9     [0.700701480904131, 0.9214492464317796]   \n",
       "10   [0.8985507246376812, 0.9075286614901541]   \n",
       "\n",
       "                                        recall admission sensitivity  \\\n",
       "0                                   [1.0, 0.0]                     1   \n",
       "1                                   [1.0, 0.0]                     1   \n",
       "2                  [1.0, 0.010050385934819897]                     1   \n",
       "3    [0.9953051643192489, 0.13866852487135506]              0.995305   \n",
       "4     [0.9466271312083024, 0.4126018439108062]              0.946627   \n",
       "5     [0.8497652582159625, 0.6437875214408233]              0.849765   \n",
       "6     [0.7190511489992587, 0.7966069897084048]              0.719051   \n",
       "7     [0.5784531751914999, 0.8943235420240138]              0.578453   \n",
       "8     [0.4052384482332592, 0.9582439965694682]              0.405238   \n",
       "9    [0.22213985668396344, 0.9897084048027445]               0.22214   \n",
       "10  [0.061279960464541636, 0.9992495711835334]               0.06128   \n",
       "\n",
       "   admission specificity  \n",
       "0                      0  \n",
       "1                      0  \n",
       "2              0.0100504  \n",
       "3               0.138669  \n",
       "4               0.412602  \n",
       "5               0.643788  \n",
       "6               0.796607  \n",
       "7               0.894324  \n",
       "8               0.958244  \n",
       "9               0.989708  \n",
       "10               0.99925  "
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = np.concatenate((encoded_x,X_pres, X_dx, clin[cont_vars].values), axis =1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, random_state=1)\n",
    "\n",
    "xgc = xgb.XGBClassifier(scale_pos_weight = 1/9)\n",
    "%time xgc.fit(X_train, y_train)\n",
    "\n",
    "preds = xgc.predict(X_test)\n",
    "predictions = xgc.predict_proba(X_test)\n",
    "\n",
    "f1_w, f1, acc, prec, rec = get_metrics(y_test, preds, print_output=True)\n",
    "\n",
    "thresholding_analysis(predictions, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### now gonna repeat the process with the embedded subjective notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10min 2s, sys: 1.93 s, total: 10min 4s\n",
      "Wall time: 10min 7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jjaskolkambp/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weighted f1:  0.7358339767372062\n",
      "f1:           [0.28169458 0.78509165]\n",
      "accuracy:     0.669165115210716\n",
      "precision:    [0.17884282 0.94824904]\n",
      "recall:       [0.66296022 0.66983812]\n",
      "admission sens:  0.662960217445021\n",
      "admission spec:  0.6698381217838765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jjaskolkambp/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/jjaskolkambp/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/jjaskolkambp/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admission_threshold</th>\n",
       "      <th>weighted f1</th>\n",
       "      <th>f1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>admission sensitivity</th>\n",
       "      <th>admission specificity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0174427</td>\n",
       "      <td>[0.17825837994978638, 0.0]</td>\n",
       "      <td>0.0978505</td>\n",
       "      <td>[0.09785052830097439, 0.0]</td>\n",
       "      <td>[1.0, 0.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0187091</td>\n",
       "      <td>[0.17836051123843102, 0.0013926830574749584]</td>\n",
       "      <td>0.0984792</td>\n",
       "      <td>[0.09791207993612852, 1.0]</td>\n",
       "      <td>[1.0, 0.0006968267581475129]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000696827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0499213</td>\n",
       "      <td>[0.18067978533094814, 0.035738723090688984]</td>\n",
       "      <td>0.114099</td>\n",
       "      <td>[0.09932879305681902, 0.9897959183673469]</td>\n",
       "      <td>[0.9982703236965653, 0.018197898799313893]</td>\n",
       "      <td>0.99827</td>\n",
       "      <td>0.0181979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.200174</td>\n",
       "      <td>[0.1940120923682102, 0.2008426628144938]</td>\n",
       "      <td>0.197442</td>\n",
       "      <td>[0.10757755277897459, 0.9876864788065356]</td>\n",
       "      <td>[0.9871509760316284, 0.11178709262435678]</td>\n",
       "      <td>0.987151</td>\n",
       "      <td>0.111787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.370156</td>\n",
       "      <td>[0.21283177286160135, 0.3872202274730709]</td>\n",
       "      <td>0.310888</td>\n",
       "      <td>[0.11980721393034825, 0.9789107511686053]</td>\n",
       "      <td>[0.9520632567333828, 0.24134326758147512]</td>\n",
       "      <td>0.952063</td>\n",
       "      <td>0.241343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.559031</td>\n",
       "      <td>[0.2428121648271806, 0.5933289974914058]</td>\n",
       "      <td>0.470853</td>\n",
       "      <td>[0.1411731573865465, 0.9673998666909047]</td>\n",
       "      <td>[0.8670620212503088, 0.4278784305317324]</td>\n",
       "      <td>0.867062</td>\n",
       "      <td>0.427878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.735834</td>\n",
       "      <td>[0.2816945771431571, 0.7850916458559111]</td>\n",
       "      <td>0.669165</td>\n",
       "      <td>[0.17884282095720572, 0.9482490420002276]</td>\n",
       "      <td>[0.662960217445021, 0.6698381217838765]</td>\n",
       "      <td>0.66296</td>\n",
       "      <td>0.669838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.836772</td>\n",
       "      <td>[0.2957351290684624, 0.8954544192374976]</td>\n",
       "      <td>0.817936</td>\n",
       "      <td>[0.23792325056433408, 0.9289623782911793]</td>\n",
       "      <td>[0.3906597479614529, 0.8642795883361921]</td>\n",
       "      <td>0.39066</td>\n",
       "      <td>0.86428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.864684</td>\n",
       "      <td>[0.21349029589564109, 0.9353150512874189]</td>\n",
       "      <td>0.880461</td>\n",
       "      <td>[0.2996873604287628, 0.9137014314928426]</td>\n",
       "      <td>[0.16580182851494935, 0.9579759862778731]</td>\n",
       "      <td>0.165802</td>\n",
       "      <td>0.957976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.860009</td>\n",
       "      <td>[0.05535224153705398, 0.9472851198529599]</td>\n",
       "      <td>0.900143</td>\n",
       "      <td>[0.3723076923076923, 0.9043232441390067]</td>\n",
       "      <td>[0.029898690387941684, 0.994532590051458]</td>\n",
       "      <td>0.0298987</td>\n",
       "      <td>0.994533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.855717</td>\n",
       "      <td>[0.0, 0.948531187634265]</td>\n",
       "      <td>0.902101</td>\n",
       "      <td>[0.0, 0.9021447397054912]</td>\n",
       "      <td>[0.0, 0.9999463979416809]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999946</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   admission_threshold weighted f1  \\\n",
       "0                 0.01   0.0174427   \n",
       "1                 0.05   0.0187091   \n",
       "2                  0.1   0.0499213   \n",
       "3                  0.2    0.200174   \n",
       "4                  0.3    0.370156   \n",
       "5                  0.4    0.559031   \n",
       "6                  0.5    0.735834   \n",
       "7                  0.6    0.836772   \n",
       "8                  0.7    0.864684   \n",
       "9                  0.8    0.860009   \n",
       "10                 0.9    0.855717   \n",
       "\n",
       "                                              f1   accuracy  \\\n",
       "0                     [0.17825837994978638, 0.0]  0.0978505   \n",
       "1   [0.17836051123843102, 0.0013926830574749584]  0.0984792   \n",
       "2    [0.18067978533094814, 0.035738723090688984]   0.114099   \n",
       "3       [0.1940120923682102, 0.2008426628144938]   0.197442   \n",
       "4      [0.21283177286160135, 0.3872202274730709]   0.310888   \n",
       "5       [0.2428121648271806, 0.5933289974914058]   0.470853   \n",
       "6       [0.2816945771431571, 0.7850916458559111]   0.669165   \n",
       "7       [0.2957351290684624, 0.8954544192374976]   0.817936   \n",
       "8      [0.21349029589564109, 0.9353150512874189]   0.880461   \n",
       "9      [0.05535224153705398, 0.9472851198529599]   0.900143   \n",
       "10                      [0.0, 0.948531187634265]   0.902101   \n",
       "\n",
       "                                    precision  \\\n",
       "0                  [0.09785052830097439, 0.0]   \n",
       "1                  [0.09791207993612852, 1.0]   \n",
       "2   [0.09932879305681902, 0.9897959183673469]   \n",
       "3   [0.10757755277897459, 0.9876864788065356]   \n",
       "4   [0.11980721393034825, 0.9789107511686053]   \n",
       "5    [0.1411731573865465, 0.9673998666909047]   \n",
       "6   [0.17884282095720572, 0.9482490420002276]   \n",
       "7   [0.23792325056433408, 0.9289623782911793]   \n",
       "8    [0.2996873604287628, 0.9137014314928426]   \n",
       "9    [0.3723076923076923, 0.9043232441390067]   \n",
       "10                  [0.0, 0.9021447397054912]   \n",
       "\n",
       "                                        recall admission sensitivity  \\\n",
       "0                                   [1.0, 0.0]                     1   \n",
       "1                 [1.0, 0.0006968267581475129]                     1   \n",
       "2   [0.9982703236965653, 0.018197898799313893]               0.99827   \n",
       "3    [0.9871509760316284, 0.11178709262435678]              0.987151   \n",
       "4    [0.9520632567333828, 0.24134326758147512]              0.952063   \n",
       "5     [0.8670620212503088, 0.4278784305317324]              0.867062   \n",
       "6      [0.662960217445021, 0.6698381217838765]               0.66296   \n",
       "7     [0.3906597479614529, 0.8642795883361921]               0.39066   \n",
       "8    [0.16580182851494935, 0.9579759862778731]              0.165802   \n",
       "9    [0.029898690387941684, 0.994532590051458]             0.0298987   \n",
       "10                   [0.0, 0.9999463979416809]                     0   \n",
       "\n",
       "   admission specificity  \n",
       "0                      0  \n",
       "1            0.000696827  \n",
       "2              0.0181979  \n",
       "3               0.111787  \n",
       "4               0.241343  \n",
       "5               0.427878  \n",
       "6               0.669838  \n",
       "7                0.86428  \n",
       "8               0.957976  \n",
       "9               0.994533  \n",
       "10              0.999946  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(features, target, random_state=1)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(subjnotes, target, random_state=1)\n",
    "\n",
    "xgc2 = xgb.XGBClassifier(scale_pos_weight = 1/9)\n",
    "%time xgc2.fit(X_train2, y_train2)\n",
    "\n",
    "preds2 = xgc2.predict(X_test2)\n",
    "predictions2 = xgc2.predict_proba(X_test2)\n",
    "\n",
    "f1_w, f1, acc, prec, rec = get_metrics(y_test2, preds2, print_output=True)\n",
    "\n",
    "thresholding_analysis(predictions2, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  now gonna do this with just the embedded medical history column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 7s, sys: 1.45 s, total: 5min 9s\n",
      "Wall time: 5min 10s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jjaskolkambp/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weighted f1:  0.7382562301967925\n",
      "f1:           [0.2735758  0.78865722]\n",
      "accuracy:     0.6725742885466283\n",
      "precision:    [0.17471737 0.94406666]\n",
      "recall:       [0.63009637 0.6771816 ]\n",
      "admission sens:  0.6300963676797627\n",
      "admission spec:  0.6771816037735849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jjaskolkambp/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/jjaskolkambp/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/jjaskolkambp/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/jjaskolkambp/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/jjaskolkambp/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/jjaskolkambp/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/jjaskolkambp/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/jjaskolkambp/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/jjaskolkambp/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/jjaskolkambp/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/jjaskolkambp/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/jjaskolkambp/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admission_threshold</th>\n",
       "      <th>weighted f1</th>\n",
       "      <th>f1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>admission sensitivity</th>\n",
       "      <th>admission specificity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0174427</td>\n",
       "      <td>[0.17825837994978638, 0.0]</td>\n",
       "      <td>0.0978505</td>\n",
       "      <td>[0.09785052830097439, 0.0]</td>\n",
       "      <td>[1.0, 0.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0174427</td>\n",
       "      <td>[0.17825837994978638, 0.0]</td>\n",
       "      <td>0.0978505</td>\n",
       "      <td>[0.09785052830097439, 0.0]</td>\n",
       "      <td>[1.0, 0.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0174427</td>\n",
       "      <td>[0.17825837994978638, 0.0]</td>\n",
       "      <td>0.0978505</td>\n",
       "      <td>[0.09785052830097439, 0.0]</td>\n",
       "      <td>[1.0, 0.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.01793</td>\n",
       "      <td>[0.17829764736981232, 0.0005358769626493757]</td>\n",
       "      <td>0.0980923</td>\n",
       "      <td>[0.09787419284625988, 1.0]</td>\n",
       "      <td>[1.0, 0.00026801029159519727]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00026801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.586613</td>\n",
       "      <td>[0.23719123359964817, 0.6245129167268004]</td>\n",
       "      <td>0.496748</td>\n",
       "      <td>[0.13924867679332156, 0.955242825607064]</td>\n",
       "      <td>[0.7996046454163578, 0.46389901372212694]</td>\n",
       "      <td>0.799605</td>\n",
       "      <td>0.463899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.646507</td>\n",
       "      <td>[0.2509383378016086, 0.6894122073435603]</td>\n",
       "      <td>0.560894</td>\n",
       "      <td>[0.15060897118526587, 0.9525069703700203]</td>\n",
       "      <td>[0.7516679021497406, 0.5402015437392796]</td>\n",
       "      <td>0.751668</td>\n",
       "      <td>0.540202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.738256</td>\n",
       "      <td>[0.27357579658834885, 0.7886572195517821]</td>\n",
       "      <td>0.672574</td>\n",
       "      <td>[0.1747173689619733, 0.9440666567030339]</td>\n",
       "      <td>[0.6300963676797627, 0.6771816037735849]</td>\n",
       "      <td>0.630096</td>\n",
       "      <td>0.677182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.817183</td>\n",
       "      <td>[0.28613091380427735, 0.8747833006508086]</td>\n",
       "      <td>0.786939</td>\n",
       "      <td>[0.21284801735567072, 0.9310084084447402]</td>\n",
       "      <td>[0.4363726216950828, 0.8249624785591767]</td>\n",
       "      <td>0.436373</td>\n",
       "      <td>0.824962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.860283</td>\n",
       "      <td>[0.2519536513069253, 0.9262643433914153]</td>\n",
       "      <td>0.865761</td>\n",
       "      <td>[0.277037037037037, 0.9180707666385847]</td>\n",
       "      <td>[0.231035334815913, 0.9346054888507719]</td>\n",
       "      <td>0.231035</td>\n",
       "      <td>0.934605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.861893</td>\n",
       "      <td>[0.08625921109666233, 0.9460206903615692]</td>\n",
       "      <td>0.898063</td>\n",
       "      <td>[0.3509700176366843, 0.9056677779956854]</td>\n",
       "      <td>[0.049172226340499135, 0.9901372212692967]</td>\n",
       "      <td>0.0491722</td>\n",
       "      <td>0.990137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.855741</td>\n",
       "      <td>[0.0, 0.948557918419748]</td>\n",
       "      <td>0.902149</td>\n",
       "      <td>[0.0, 0.9021494716990256]</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   admission_threshold weighted f1  \\\n",
       "0                 0.01   0.0174427   \n",
       "1                 0.05   0.0174427   \n",
       "2                  0.1   0.0174427   \n",
       "3                  0.2     0.01793   \n",
       "4                  0.3    0.586613   \n",
       "5                  0.4    0.646507   \n",
       "6                  0.5    0.738256   \n",
       "7                  0.6    0.817183   \n",
       "8                  0.7    0.860283   \n",
       "9                  0.8    0.861893   \n",
       "10                 0.9    0.855741   \n",
       "\n",
       "                                              f1   accuracy  \\\n",
       "0                     [0.17825837994978638, 0.0]  0.0978505   \n",
       "1                     [0.17825837994978638, 0.0]  0.0978505   \n",
       "2                     [0.17825837994978638, 0.0]  0.0978505   \n",
       "3   [0.17829764736981232, 0.0005358769626493757]  0.0980923   \n",
       "4      [0.23719123359964817, 0.6245129167268004]   0.496748   \n",
       "5       [0.2509383378016086, 0.6894122073435603]   0.560894   \n",
       "6      [0.27357579658834885, 0.7886572195517821]   0.672574   \n",
       "7      [0.28613091380427735, 0.8747833006508086]   0.786939   \n",
       "8       [0.2519536513069253, 0.9262643433914153]   0.865761   \n",
       "9      [0.08625921109666233, 0.9460206903615692]   0.898063   \n",
       "10                      [0.0, 0.948557918419748]   0.902149   \n",
       "\n",
       "                                    precision  \\\n",
       "0                  [0.09785052830097439, 0.0]   \n",
       "1                  [0.09785052830097439, 0.0]   \n",
       "2                  [0.09785052830097439, 0.0]   \n",
       "3                  [0.09787419284625988, 1.0]   \n",
       "4    [0.13924867679332156, 0.955242825607064]   \n",
       "5   [0.15060897118526587, 0.9525069703700203]   \n",
       "6    [0.1747173689619733, 0.9440666567030339]   \n",
       "7   [0.21284801735567072, 0.9310084084447402]   \n",
       "8     [0.277037037037037, 0.9180707666385847]   \n",
       "9    [0.3509700176366843, 0.9056677779956854]   \n",
       "10                  [0.0, 0.9021494716990256]   \n",
       "\n",
       "                                        recall admission sensitivity  \\\n",
       "0                                   [1.0, 0.0]                     1   \n",
       "1                                   [1.0, 0.0]                     1   \n",
       "2                                   [1.0, 0.0]                     1   \n",
       "3                [1.0, 0.00026801029159519727]                     1   \n",
       "4    [0.7996046454163578, 0.46389901372212694]              0.799605   \n",
       "5     [0.7516679021497406, 0.5402015437392796]              0.751668   \n",
       "6     [0.6300963676797627, 0.6771816037735849]              0.630096   \n",
       "7     [0.4363726216950828, 0.8249624785591767]              0.436373   \n",
       "8      [0.231035334815913, 0.9346054888507719]              0.231035   \n",
       "9   [0.049172226340499135, 0.9901372212692967]             0.0491722   \n",
       "10                                  [0.0, 1.0]                     0   \n",
       "\n",
       "   admission specificity  \n",
       "0                      0  \n",
       "1                      0  \n",
       "2                      0  \n",
       "3             0.00026801  \n",
       "4               0.463899  \n",
       "5               0.540202  \n",
       "6               0.677182  \n",
       "7               0.824962  \n",
       "8               0.934605  \n",
       "9               0.990137  \n",
       "10                     1  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train3, X_test3, y_train3, y_test3 = train_test_split(medhx, target, random_state=1)\n",
    "\n",
    "xgc3 = xgb.XGBClassifier(scale_pos_weight = 1/9)\n",
    "%time xgc3.fit(X_train3, y_train3)\n",
    "\n",
    "preds3 = xgc3.predict(X_test3)\n",
    "predictions3 = xgc3.predict_proba(X_test3)\n",
    "\n",
    "f1_w, f1, acc, prec, rec = get_metrics(y_test3, preds3, print_output=True)\n",
    "\n",
    "thresholding_analysis(predictions3, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### this now the entire dataset combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(165433, 5272)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_features = np.concatenate((features,subjnotes,medhx), axis = 1)\n",
    "all_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26min 20s, sys: 44.8 s, total: 27min 4s\n",
      "Wall time: 27min 35s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jjaskolkambp/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weighted f1:  0.8218600615566528\n",
      "f1:           [0.40026738 0.86758759]\n",
      "accuracy:     0.783070190285065\n",
      "precision:    [0.27435169 0.96541418]\n",
      "recall:       [0.73980726 0.78776265]\n",
      "admission sens:  0.7398072646404744\n",
      "admission spec:  0.7877626500857633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jjaskolkambp/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/jjaskolkambp/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/jjaskolkambp/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admission_threshold</th>\n",
       "      <th>weighted f1</th>\n",
       "      <th>f1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>admission sensitivity</th>\n",
       "      <th>admission specificity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0174427</td>\n",
       "      <td>[0.17825837994978638, 0.0]</td>\n",
       "      <td>0.0978505</td>\n",
       "      <td>[0.09785052830097439, 0.0]</td>\n",
       "      <td>[1.0, 0.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0181735</td>\n",
       "      <td>[0.1783172875680201, 0.0008037077718541539]</td>\n",
       "      <td>0.0982132</td>\n",
       "      <td>[0.0978860294117647, 1.0]</td>\n",
       "      <td>[1.0, 0.0004020154373927959]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000402015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0724242</td>\n",
       "      <td>[0.18282097649186257, 0.060450127345496124]</td>\n",
       "      <td>0.125898</td>\n",
       "      <td>[0.10061453486925584, 0.9974271012006861]</td>\n",
       "      <td>[0.9992587101556709, 0.03116959691252144]</td>\n",
       "      <td>0.999259</td>\n",
       "      <td>0.0311696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.360148</td>\n",
       "      <td>[0.21757960395500234, 0.3756113465927617]</td>\n",
       "      <td>0.305472</td>\n",
       "      <td>[0.1222678013837017, 0.9939031404578397]</td>\n",
       "      <td>[0.986903879416852, 0.23156089193825044]</td>\n",
       "      <td>0.986904</td>\n",
       "      <td>0.231561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.591511</td>\n",
       "      <td>[0.27239377426363215, 0.626123240789883]</td>\n",
       "      <td>0.506057</td>\n",
       "      <td>[0.1591344153141906, 0.987131398234174]</td>\n",
       "      <td>[0.9448974549048678, 0.4584584048027444]</td>\n",
       "      <td>0.944897</td>\n",
       "      <td>0.458458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.734796</td>\n",
       "      <td>[0.3346871675853399, 0.7781933071119994]</td>\n",
       "      <td>0.667303</td>\n",
       "      <td>[0.20805530507965134, 0.9762983336029769]</td>\n",
       "      <td>[0.8552013837410427, 0.6469232418524872]</td>\n",
       "      <td>0.855201</td>\n",
       "      <td>0.646923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.82186</td>\n",
       "      <td>[0.40026737967914433, 0.8675875911331503]</td>\n",
       "      <td>0.78307</td>\n",
       "      <td>[0.27435169064418585, 0.9654141759180188]</td>\n",
       "      <td>[0.7398072646404744, 0.7877626500857633]</td>\n",
       "      <td>0.739807</td>\n",
       "      <td>0.787763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.873085</td>\n",
       "      <td>[0.4515282205137821, 0.9188086382057403]</td>\n",
       "      <td>0.858556</td>\n",
       "      <td>[0.36380117842574405, 0.9528209556706966]</td>\n",
       "      <td>[0.5950086483815171, 0.8871408662092625]</td>\n",
       "      <td>0.595009</td>\n",
       "      <td>0.887141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.897826</td>\n",
       "      <td>[0.45442359249329756, 0.9459193706981318]</td>\n",
       "      <td>0.901593</td>\n",
       "      <td>[0.4966305303252271, 0.938017182311706]</td>\n",
       "      <td>[0.41882876204596, 0.9539558319039451]</td>\n",
       "      <td>0.418829</td>\n",
       "      <td>0.953956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.895266</td>\n",
       "      <td>[0.35051546391752575, 0.9543513702352302]</td>\n",
       "      <td>0.914698</td>\n",
       "      <td>[0.6873646209386282, 0.9225746735377995]</td>\n",
       "      <td>[0.23523597726711143, 0.988395154373928]</td>\n",
       "      <td>0.235236</td>\n",
       "      <td>0.988395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.871195</td>\n",
       "      <td>[0.13083257090576395, 0.9514972047073238]</td>\n",
       "      <td>0.908122</td>\n",
       "      <td>[0.88, 0.9083442998489057]</td>\n",
       "      <td>[0.07066963182604398, 0.9989547598627787]</td>\n",
       "      <td>0.0706696</td>\n",
       "      <td>0.998955</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   admission_threshold weighted f1  \\\n",
       "0                 0.01   0.0174427   \n",
       "1                 0.05   0.0181735   \n",
       "2                  0.1   0.0724242   \n",
       "3                  0.2    0.360148   \n",
       "4                  0.3    0.591511   \n",
       "5                  0.4    0.734796   \n",
       "6                  0.5     0.82186   \n",
       "7                  0.6    0.873085   \n",
       "8                  0.7    0.897826   \n",
       "9                  0.8    0.895266   \n",
       "10                 0.9    0.871195   \n",
       "\n",
       "                                             f1   accuracy  \\\n",
       "0                    [0.17825837994978638, 0.0]  0.0978505   \n",
       "1   [0.1783172875680201, 0.0008037077718541539]  0.0982132   \n",
       "2   [0.18282097649186257, 0.060450127345496124]   0.125898   \n",
       "3     [0.21757960395500234, 0.3756113465927617]   0.305472   \n",
       "4      [0.27239377426363215, 0.626123240789883]   0.506057   \n",
       "5      [0.3346871675853399, 0.7781933071119994]   0.667303   \n",
       "6     [0.40026737967914433, 0.8675875911331503]    0.78307   \n",
       "7      [0.4515282205137821, 0.9188086382057403]   0.858556   \n",
       "8     [0.45442359249329756, 0.9459193706981318]   0.901593   \n",
       "9     [0.35051546391752575, 0.9543513702352302]   0.914698   \n",
       "10    [0.13083257090576395, 0.9514972047073238]   0.908122   \n",
       "\n",
       "                                    precision  \\\n",
       "0                  [0.09785052830097439, 0.0]   \n",
       "1                   [0.0978860294117647, 1.0]   \n",
       "2   [0.10061453486925584, 0.9974271012006861]   \n",
       "3    [0.1222678013837017, 0.9939031404578397]   \n",
       "4     [0.1591344153141906, 0.987131398234174]   \n",
       "5   [0.20805530507965134, 0.9762983336029769]   \n",
       "6   [0.27435169064418585, 0.9654141759180188]   \n",
       "7   [0.36380117842574405, 0.9528209556706966]   \n",
       "8     [0.4966305303252271, 0.938017182311706]   \n",
       "9    [0.6873646209386282, 0.9225746735377995]   \n",
       "10                 [0.88, 0.9083442998489057]   \n",
       "\n",
       "                                       recall admission sensitivity  \\\n",
       "0                                  [1.0, 0.0]                     1   \n",
       "1                [1.0, 0.0004020154373927959]                     1   \n",
       "2   [0.9992587101556709, 0.03116959691252144]              0.999259   \n",
       "3    [0.986903879416852, 0.23156089193825044]              0.986904   \n",
       "4    [0.9448974549048678, 0.4584584048027444]              0.944897   \n",
       "5    [0.8552013837410427, 0.6469232418524872]              0.855201   \n",
       "6    [0.7398072646404744, 0.7877626500857633]              0.739807   \n",
       "7    [0.5950086483815171, 0.8871408662092625]              0.595009   \n",
       "8      [0.41882876204596, 0.9539558319039451]              0.418829   \n",
       "9    [0.23523597726711143, 0.988395154373928]              0.235236   \n",
       "10  [0.07066963182604398, 0.9989547598627787]             0.0706696   \n",
       "\n",
       "   admission specificity  \n",
       "0                      0  \n",
       "1            0.000402015  \n",
       "2              0.0311696  \n",
       "3               0.231561  \n",
       "4               0.458458  \n",
       "5               0.646923  \n",
       "6               0.787763  \n",
       "7               0.887141  \n",
       "8               0.953956  \n",
       "9               0.988395  \n",
       "10              0.998955  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train4, X_test4, y_train4, y_test4 = train_test_split(all_features, target, random_state=1)\n",
    "\n",
    "xgc4 = xgb.XGBClassifier(scale_pos_weight = 1/9)\n",
    "%time xgc4.fit(X_train4, y_train4)\n",
    "\n",
    "preds4 = xgc4.predict(X_test4)\n",
    "predictions4 = xgc4.predict_proba(X_test4)\n",
    "\n",
    "f1_w, f1, acc, prec, rec = get_metrics(y_test4, preds4, print_output=True)\n",
    "\n",
    "thresholding_analysis(predictions4, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### manual ensembling\n",
    "\n",
    "remember that admit is class 0 and discharge is class 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_predictions = (predictions + predictions2 + predictions3)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jjaskolkambp/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/jjaskolkambp/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/jjaskolkambp/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/jjaskolkambp/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/jjaskolkambp/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/jjaskolkambp/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/jjaskolkambp/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/jjaskolkambp/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/jjaskolkambp/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/jjaskolkambp/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/jjaskolkambp/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/jjaskolkambp/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admission_threshold</th>\n",
       "      <th>weighted f1</th>\n",
       "      <th>f1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>admission sensitivity</th>\n",
       "      <th>admission specificity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0174427</td>\n",
       "      <td>[0.17825837994978638, 0.0]</td>\n",
       "      <td>0.0978505</td>\n",
       "      <td>[0.09785052830097439, 0.0]</td>\n",
       "      <td>[1.0, 0.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0174427</td>\n",
       "      <td>[0.17825837994978638, 0.0]</td>\n",
       "      <td>0.0978505</td>\n",
       "      <td>[0.09785052830097439, 0.0]</td>\n",
       "      <td>[1.0, 0.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0174427</td>\n",
       "      <td>[0.17825837994978638, 0.0]</td>\n",
       "      <td>0.0978505</td>\n",
       "      <td>[0.09785052830097439, 0.0]</td>\n",
       "      <td>[1.0, 0.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0632888</td>\n",
       "      <td>[0.18196547921776898, 0.050416655782241845]</td>\n",
       "      <td>0.121086</td>\n",
       "      <td>[0.10009903441445903, 0.9958720330237358]</td>\n",
       "      <td>[0.9990116135408945, 0.025862993138936537]</td>\n",
       "      <td>0.999012</td>\n",
       "      <td>0.025863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.343016</td>\n",
       "      <td>[0.21498563719831404, 0.356902505003409]</td>\n",
       "      <td>0.292995</td>\n",
       "      <td>[0.12059514487079091, 0.994728454088513]</td>\n",
       "      <td>[0.9893748455646157, 0.21746355060034306]</td>\n",
       "      <td>0.989375</td>\n",
       "      <td>0.217464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.651932</td>\n",
       "      <td>[0.29079172809499143, 0.6911022023220702]</td>\n",
       "      <td>0.569646</td>\n",
       "      <td>[0.17334916864608077, 0.9804027770938992]</td>\n",
       "      <td>[0.9016555473190018, 0.5336352915951973]</td>\n",
       "      <td>0.901656</td>\n",
       "      <td>0.533635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.81228</td>\n",
       "      <td>[0.38223436077513334, 0.8589248589248589]</td>\n",
       "      <td>0.770304</td>\n",
       "      <td>[0.2593769305445239, 0.9631011056347409]</td>\n",
       "      <td>[0.7262169508277737, 0.7750857632933105]</td>\n",
       "      <td>0.726217</td>\n",
       "      <td>0.775086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.88188</td>\n",
       "      <td>[0.42543064369900274, 0.9313882047256882]</td>\n",
       "      <td>0.877415</td>\n",
       "      <td>[0.3929244295583002, 0.9406812093379258]</td>\n",
       "      <td>[0.4638003459352607, 0.9222770154373928]</td>\n",
       "      <td>0.4638</td>\n",
       "      <td>0.922277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.884325</td>\n",
       "      <td>[0.27220739611132294, 0.9507176786451881]</td>\n",
       "      <td>0.907686</td>\n",
       "      <td>[0.5954962468723937, 0.9170069721115538]</td>\n",
       "      <td>[0.17642698295033357, 0.9870015008576329]</td>\n",
       "      <td>0.176427</td>\n",
       "      <td>0.987002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.85986</td>\n",
       "      <td>[0.036214389183969097, 0.9491956831602525]</td>\n",
       "      <td>0.903479</td>\n",
       "      <td>[0.7894736842105263, 0.9037417603722373]</td>\n",
       "      <td>[0.018532246108228317, 0.9994639794168096]</td>\n",
       "      <td>0.0185322</td>\n",
       "      <td>0.999464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.855741</td>\n",
       "      <td>[0.0, 0.948557918419748]</td>\n",
       "      <td>0.902149</td>\n",
       "      <td>[0.0, 0.9021494716990256]</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   admission_threshold weighted f1  \\\n",
       "0                 0.01   0.0174427   \n",
       "1                 0.05   0.0174427   \n",
       "2                  0.1   0.0174427   \n",
       "3                  0.2   0.0632888   \n",
       "4                  0.3    0.343016   \n",
       "5                  0.4    0.651932   \n",
       "6                  0.5     0.81228   \n",
       "7                  0.6     0.88188   \n",
       "8                  0.7    0.884325   \n",
       "9                  0.8     0.85986   \n",
       "10                 0.9    0.855741   \n",
       "\n",
       "                                             f1   accuracy  \\\n",
       "0                    [0.17825837994978638, 0.0]  0.0978505   \n",
       "1                    [0.17825837994978638, 0.0]  0.0978505   \n",
       "2                    [0.17825837994978638, 0.0]  0.0978505   \n",
       "3   [0.18196547921776898, 0.050416655782241845]   0.121086   \n",
       "4      [0.21498563719831404, 0.356902505003409]   0.292995   \n",
       "5     [0.29079172809499143, 0.6911022023220702]   0.569646   \n",
       "6     [0.38223436077513334, 0.8589248589248589]   0.770304   \n",
       "7     [0.42543064369900274, 0.9313882047256882]   0.877415   \n",
       "8     [0.27220739611132294, 0.9507176786451881]   0.907686   \n",
       "9    [0.036214389183969097, 0.9491956831602525]   0.903479   \n",
       "10                     [0.0, 0.948557918419748]   0.902149   \n",
       "\n",
       "                                    precision  \\\n",
       "0                  [0.09785052830097439, 0.0]   \n",
       "1                  [0.09785052830097439, 0.0]   \n",
       "2                  [0.09785052830097439, 0.0]   \n",
       "3   [0.10009903441445903, 0.9958720330237358]   \n",
       "4    [0.12059514487079091, 0.994728454088513]   \n",
       "5   [0.17334916864608077, 0.9804027770938992]   \n",
       "6    [0.2593769305445239, 0.9631011056347409]   \n",
       "7    [0.3929244295583002, 0.9406812093379258]   \n",
       "8    [0.5954962468723937, 0.9170069721115538]   \n",
       "9    [0.7894736842105263, 0.9037417603722373]   \n",
       "10                  [0.0, 0.9021494716990256]   \n",
       "\n",
       "                                        recall admission sensitivity  \\\n",
       "0                                   [1.0, 0.0]                     1   \n",
       "1                                   [1.0, 0.0]                     1   \n",
       "2                                   [1.0, 0.0]                     1   \n",
       "3   [0.9990116135408945, 0.025862993138936537]              0.999012   \n",
       "4    [0.9893748455646157, 0.21746355060034306]              0.989375   \n",
       "5     [0.9016555473190018, 0.5336352915951973]              0.901656   \n",
       "6     [0.7262169508277737, 0.7750857632933105]              0.726217   \n",
       "7     [0.4638003459352607, 0.9222770154373928]                0.4638   \n",
       "8    [0.17642698295033357, 0.9870015008576329]              0.176427   \n",
       "9   [0.018532246108228317, 0.9994639794168096]             0.0185322   \n",
       "10                                  [0.0, 1.0]                     0   \n",
       "\n",
       "   admission specificity  \n",
       "0                      0  \n",
       "1                      0  \n",
       "2                      0  \n",
       "3               0.025863  \n",
       "4               0.217464  \n",
       "5               0.533635  \n",
       "6               0.775086  \n",
       "7               0.922277  \n",
       "8               0.987002  \n",
       "9               0.999464  \n",
       "10                     1  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresholding_analysis(combined_predictions, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### now gonna try to save these models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(xgc, open(data_path + \"/tabular_xgb_model.pkl\", \"wb\"))\n",
    "pickle.dump(xgc2, open(data_path + \"/subjnotes_xgb_model.pkl\", \"wb\"))\n",
    "pickle.dump(xgc3, open(data_path + \"/med_hx_xgb_model.pkl\", \"wb\"))\n",
    "pickle.dump(xgc4, open(data_path + \"/combined_xgb_model.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for reloading later\n",
    "with open(data_path + \"/tabular_xgb.pkl\", mode = 'rb') as pkl:\n",
    "    xgc3 = pickle.load(pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
