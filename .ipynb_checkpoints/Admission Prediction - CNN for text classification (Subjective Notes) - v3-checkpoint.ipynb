{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\goond\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\goond\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\goond\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\goond\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\goond\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\goond\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\goond\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Activation, Conv2D, Input, Embedding, Reshape, MaxPool2D, Concatenate, Flatten, Dropout, Dense, Conv1D\n",
    "from keras.layers import MaxPool1D\n",
    "from keras.models import Model\n",
    "from keras.layers import Embedding\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\goond\\Anaconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3058: DtypeWarning: Columns (26,27,28,38) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DischargeDispositionDesc</th>\n",
       "      <th>SubjectiveNotes</th>\n",
       "      <th>Disposition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>83758</td>\n",
       "      <td>Discharge to private home, condo, apt without ...</td>\n",
       "      <td>^c^^^^ctasSUN=Pt has in the Er this morning fo...</td>\n",
       "      <td>Discharge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16100</td>\n",
       "      <td>Discharge to private home, condo, apt without ...</td>\n",
       "      <td>^c^^^^ctasSUN=As per mom pt has abcess to uppe...</td>\n",
       "      <td>Discharge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8952</td>\n",
       "      <td>Discharge to private home, condo, apt without ...</td>\n",
       "      <td>^c^^^^ctasSUN=pt feel last week Wednesday on f...</td>\n",
       "      <td>Discharge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39841</td>\n",
       "      <td>Discharge to private home, condo, apt without ...</td>\n",
       "      <td>^c^^^^ctasSUN=As per parent, fever since yeste...</td>\n",
       "      <td>Discharge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15010</td>\n",
       "      <td>Discharge to private home, condo, apt without ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Discharge</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                DischargeDispositionDesc  \\\n",
       "83758  Discharge to private home, condo, apt without ...   \n",
       "16100  Discharge to private home, condo, apt without ...   \n",
       "8952   Discharge to private home, condo, apt without ...   \n",
       "39841  Discharge to private home, condo, apt without ...   \n",
       "15010  Discharge to private home, condo, apt without ...   \n",
       "\n",
       "                                         SubjectiveNotes Disposition  \n",
       "83758  ^c^^^^ctasSUN=Pt has in the Er this morning fo...   Discharge  \n",
       "16100  ^c^^^^ctasSUN=As per mom pt has abcess to uppe...   Discharge  \n",
       "8952   ^c^^^^ctasSUN=pt feel last week Wednesday on f...   Discharge  \n",
       "39841  ^c^^^^ctasSUN=As per parent, fever since yeste...   Discharge  \n",
       "15010                                                NaN   Discharge  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import the dataset - This notebook only tests a Convolutional Neural Network on the Subjective Notes column\n",
    "#Subsequent tests will include the Medical History column\n",
    "df = pd.read_csv('BCH_Test3.csv', error_bad_lines=False)\n",
    "df = df.reindex(np.random.permutation(df.index))  \n",
    "df = df[['DischargeDispositionDesc', 'SubjectiveNotes']]\n",
    "\n",
    "#Create a separate column called Disposition as a binary outcome of the patient's stay in the hospital\n",
    "df['Disposition'] = np.where(df['DischargeDispositionDesc'].str[:5]==\"Admit\", 'Admit', 'Discharge')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discharge    120080\n",
       "Admit         16913\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Count the total number of records of each major outcome type\n",
    "pd.value_counts(df['Disposition'].values, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discharge    100170\n",
       "Admit         10704\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove any Subjective Notes with empty values and count the number of records\n",
    "filtered_df = df[df['SubjectiveNotes'].notnull()]\n",
    "filtered_df.dropna(subset=['SubjectiveNotes'])\n",
    "pd.value_counts(filtered_df['Disposition'].values, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10704\n"
     ]
    }
   ],
   "source": [
    "#Create a temporary subset of only the admitted patients\n",
    "admit_df = filtered_df.loc[filtered_df.Disposition == \"Admit\"]\n",
    "num_admits = len(admit_df)\n",
    "#admit_df.head()\n",
    "print(num_admits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a subset of discharged patients of length equal to the number of admits and save as a temporary subset\n",
    "discharge_df = filtered_df.loc[filtered_df.Disposition == \"Discharge\"]\n",
    "#discharge_df.head()\n",
    "balanced_discharge_df = discharge_df.sample(n = num_admits) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DischargeDispositionDesc</th>\n",
       "      <th>SubjectiveNotes</th>\n",
       "      <th>Disposition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1638</td>\n",
       "      <td>Admit to reporting facility as inpatient to an...</td>\n",
       "      <td>^c^^^^ctasSUN=Pt is 16 weeks pregnant c/o naus...</td>\n",
       "      <td>Admit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39669</td>\n",
       "      <td>Admit to reporting facility as inpatient to an...</td>\n",
       "      <td>^c^^^^ctasSUN=Pt 8 weeks pregnant. Pt in ER c/...</td>\n",
       "      <td>Admit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128761</td>\n",
       "      <td>Admit to reporting facility as inpatient to an...</td>\n",
       "      <td>^c^^^^ctasSUN=Pt c/o shortness of breath since...</td>\n",
       "      <td>Admit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39866</td>\n",
       "      <td>Admit to reporting facility as inpatient to an...</td>\n",
       "      <td>^c^^^^ctasSUN=c/o intermittent generalized abd...</td>\n",
       "      <td>Admit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120489</td>\n",
       "      <td>Admit to reporting facility as inpatient to SC...</td>\n",
       "      <td>^c^^^^ctasSUN=alert , lethargic, 8 mg lorazepa...</td>\n",
       "      <td>Admit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 DischargeDispositionDesc  \\\n",
       "1638    Admit to reporting facility as inpatient to an...   \n",
       "39669   Admit to reporting facility as inpatient to an...   \n",
       "128761  Admit to reporting facility as inpatient to an...   \n",
       "39866   Admit to reporting facility as inpatient to an...   \n",
       "120489  Admit to reporting facility as inpatient to SC...   \n",
       "\n",
       "                                          SubjectiveNotes Disposition  \n",
       "1638    ^c^^^^ctasSUN=Pt is 16 weeks pregnant c/o naus...       Admit  \n",
       "39669   ^c^^^^ctasSUN=Pt 8 weeks pregnant. Pt in ER c/...       Admit  \n",
       "128761  ^c^^^^ctasSUN=Pt c/o shortness of breath since...       Admit  \n",
       "39866   ^c^^^^ctasSUN=c/o intermittent generalized abd...       Admit  \n",
       "120489  ^c^^^^ctasSUN=alert , lethargic, 8 mg lorazepa...       Admit  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Combine the subset of admitted patients and the random discharged patients back into a single dataframe\n",
    "balanced_set = admit_df.append(balanced_discharge_df)\n",
    "balanced_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changing the text to lowercase:\n",
    "balanced_set['SubjectiveNotes'] = balanced_set['SubjectiveNotes'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a function to remove stopwords and apply this to the dataset.\n",
    "#A whitelist of words is created and can be expanded to include a broader set of terms\n",
    "def remove_stopwords(input_text):\n",
    "        stop_words = stopwords.words('english')\n",
    "        whitelist = [\"n't\", \"not\", \"no\"]\n",
    "        words = input_text.split() \n",
    "        clean_words = [word for word in words if (word not in stop_words or word in whitelist) and len(word) > 1] \n",
    "        return \" \".join(clean_words) \n",
    "\n",
    "balanced_set.SubjectiveNotes = balanced_set.SubjectiveNotes.apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DischargeDispositionDesc</th>\n",
       "      <th>SubjectiveNotes</th>\n",
       "      <th>Disposition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1638</td>\n",
       "      <td>Admit to reporting facility as inpatient to an...</td>\n",
       "      <td>pt 16 weeks pregnant c/o nausea vomiting since...</td>\n",
       "      <td>Admit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39669</td>\n",
       "      <td>Admit to reporting facility as inpatient to an...</td>\n",
       "      <td>pt weeks pregnant. pt er c/o worsening diarrhe...</td>\n",
       "      <td>Admit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128761</td>\n",
       "      <td>Admit to reporting facility as inpatient to an...</td>\n",
       "      <td>pt c/o shortness breath since yesterday. last ...</td>\n",
       "      <td>Admit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39866</td>\n",
       "      <td>Admit to reporting facility as inpatient to an...</td>\n",
       "      <td>/o intermittent generalized abdo pain, sharp, ...</td>\n",
       "      <td>Admit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120489</td>\n",
       "      <td>Admit to reporting facility as inpatient to SC...</td>\n",
       "      <td>lert lethargic, mg lorazepam iv given oxygen 2...</td>\n",
       "      <td>Admit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 DischargeDispositionDesc  \\\n",
       "1638    Admit to reporting facility as inpatient to an...   \n",
       "39669   Admit to reporting facility as inpatient to an...   \n",
       "128761  Admit to reporting facility as inpatient to an...   \n",
       "39866   Admit to reporting facility as inpatient to an...   \n",
       "120489  Admit to reporting facility as inpatient to SC...   \n",
       "\n",
       "                                          SubjectiveNotes Disposition  \n",
       "1638    pt 16 weeks pregnant c/o nausea vomiting since...       Admit  \n",
       "39669   pt weeks pregnant. pt er c/o worsening diarrhe...       Admit  \n",
       "128761  pt c/o shortness breath since yesterday. last ...       Admit  \n",
       "39866   /o intermittent generalized abdo pain, sharp, ...       Admit  \n",
       "120489  lert lethargic, mg lorazepam iv given oxygen 2...       Admit  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Removing the following string from the SubjectiveNotes:\n",
    "#String to be removed: ^c^^^^ctasSUN=\n",
    "substring = '^c^^^^ctassun='\n",
    "balanced_set['SubjectiveNotes'] = balanced_set['SubjectiveNotes'].str.strip(substring)\n",
    "balanced_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discharge    10704\n",
       "Admit        10704\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Verifying that the new dataset has an equal number of Admits and Discharges\n",
    "#Future iterations will include additional performance metrics, however since the current tests involve accuracy only,\n",
    "#The datasets are stricly balanced\n",
    "pd.value_counts(balanced_set['Disposition'].values, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting the parameters for the CNN\n",
    "MAX_WORDS = 5000\n",
    "MAX_SEQUENCE_LENGTH = 250\n",
    "VALIDATION_SPLIT = 0.2\n",
    "EMBEDDING_DIM = 50\n",
    "filter_sizes = [3,4,5]\n",
    "num_filters = 512\n",
    "embedding_dim = 50\n",
    "drop = 0.5\n",
    "batch_size = 50\n",
    "epochs = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting the binary outcome value to numeric values\n",
    "Y = balanced_set['Disposition']\n",
    "Y = np.where(balanced_set['Disposition'].str[:5]==\"Admit\", 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique words : 14532\n",
      "Shape of data tensor:  (21408, 250)\n",
      "Shape of label tensor:  (21408, 2)\n"
     ]
    }
   ],
   "source": [
    "#Tokenizing text\n",
    "tokenizer = Tokenizer(num_words = MAX_WORDS)\n",
    "tokenizer.fit_on_texts(balanced_set.SubjectiveNotes)\n",
    "sequences = tokenizer.texts_to_sequences(balanced_set.SubjectiveNotes)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print(\"unique words : {}\".format(len(word_index)))\n",
    "\n",
    "#Padding records with shorter notes up to the max sequence length (of ~250 words)\n",
    "data = pad_sequences(sequences, maxlen = MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "Y = to_categorical(np.asarray(Y))\n",
    "print('Shape of data tensor: ', data.shape)\n",
    "print('Shape of label tensor: ', Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the data randomly into training and validation sets\n",
    "indices = np.arange(data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data = data[indices]\n",
    "Y = Y[indices]\n",
    "nb_validation_samples = int(VALIDATION_SPLIT * data.shape[0])\n",
    "\n",
    "x_train = data[:-nb_validation_samples]\n",
    "y_train = Y[:-nb_validation_samples]\n",
    "x_val = data[-nb_validation_samples:]\n",
    "y_val = Y[-nb_validation_samples:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "#Creating a matrix of word embeddings using Glove - the 50 dimensional representation is used.\n",
    "#Higher dimensional representations are also available\n",
    "embeddings_index = {}\n",
    "f= open(\"glove.6B.50d.txt\", encoding=\"utf8\")\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:],dtype = 'float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a word embedding matrix of the tokenized words\n",
    "embedding_matrix = np.zeros((len(word_index)+1, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating an embedding layer to be fed into the CNN\n",
    "embedding_layer = Embedding(len(word_index)+1,\n",
    "                           EMBEDDING_DIM,\n",
    "                           weights = [embedding_matrix],\n",
    "                           input_length=MAX_SEQUENCE_LENGTH,\n",
    "                           trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\goond\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "(?, 250, 50)\n",
      "(?, 250, 50, 1)\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 250)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 250, 50)      726650      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 250, 50, 1)   0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 248, 1, 512)  77312       reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 247, 1, 512)  102912      reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 246, 1, 512)  128512      reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 1, 1, 512)    0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 1, 1, 512)    0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 1, 1, 512)    0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 3, 1, 512)    0           max_pooling2d_1[0][0]            \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 1536)         0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1536)         0           flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2)            3074        dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,038,460\n",
      "Trainable params: 311,810\n",
      "Non-trainable params: 726,650\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Setting the CNN architecture\n",
    "inputs = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "embedding = embedding_layer(inputs)\n",
    "\n",
    "print(embedding.shape)\n",
    "reshape = Reshape((MAX_SEQUENCE_LENGTH,EMBEDDING_DIM,1))(embedding)\n",
    "print(reshape.shape)\n",
    "\n",
    "conv_0 = Conv2D(num_filters, kernel_size=(filter_sizes[0], embedding_dim), padding='valid', kernel_initializer='normal', activation='relu')(reshape)\n",
    "conv_1 = Conv2D(num_filters, kernel_size=(filter_sizes[1], embedding_dim), padding='valid', kernel_initializer='normal', activation='relu')(reshape)\n",
    "conv_2 = Conv2D(num_filters, kernel_size=(filter_sizes[2], embedding_dim), padding='valid', kernel_initializer='normal', activation='relu')(reshape)\n",
    "\n",
    "maxpool_0 = MaxPool2D(pool_size=(MAX_SEQUENCE_LENGTH - filter_sizes[0] + 1, 1), strides=(1,1), padding='valid')(conv_0)\n",
    "maxpool_1 = MaxPool2D(pool_size=(MAX_SEQUENCE_LENGTH - filter_sizes[1] + 1, 1), strides=(1,1), padding='valid')(conv_1)\n",
    "maxpool_2 = MaxPool2D(pool_size=(MAX_SEQUENCE_LENGTH - filter_sizes[2] + 1, 1), strides=(1,1), padding='valid')(conv_2)\n",
    "\n",
    "concatenated_tensor = Concatenate(axis=1)([maxpool_0, maxpool_1, maxpool_2])\n",
    "flatten = Flatten()(concatenated_tensor)\n",
    "dropout = Dropout(drop)(flatten)\n",
    "output = Dense(units=2, activation='softmax')(dropout)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=output)\n",
    "\n",
    "checkpoint = ModelCheckpoint('weights_cnn_sentece.hdf5', monitor='val_acc', verbose=1, save_best_only=True, mode='auto')\n",
    "adam = Adam(lr=1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "model.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "WARNING:tensorflow:From C:\\Users\\goond\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 17127 samples, validate on 4281 samples\n",
      "Epoch 1/25\n",
      "17127/17127 [==============================] - 96s 6ms/step - loss: 0.9049 - accuracy: 0.5469 - val_loss: 0.6329 - val_accuracy: 0.6414\n",
      "Epoch 2/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\goond\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\callbacks\\callbacks.py:707: RuntimeWarning: Can save best model only with val_acc available, skipping.\n",
      "  'skipping.' % (self.monitor), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17127/17127 [==============================] - 108s 6ms/step - loss: 0.7934 - accuracy: 0.5981 - val_loss: 0.6219 - val_accuracy: 0.6534\n",
      "Epoch 3/25\n",
      "17127/17127 [==============================] - 105s 6ms/step - loss: 0.7336 - accuracy: 0.6177 - val_loss: 0.6093 - val_accuracy: 0.6692\n",
      "Epoch 4/25\n",
      "17127/17127 [==============================] - 94s 5ms/step - loss: 0.6816 - accuracy: 0.6370 - val_loss: 0.6087 - val_accuracy: 0.6674\n",
      "Epoch 5/25\n",
      "17127/17127 [==============================] - 89s 5ms/step - loss: 0.6526 - accuracy: 0.6546 - val_loss: 0.6005 - val_accuracy: 0.6739\n",
      "Epoch 6/25\n",
      "17127/17127 [==============================] - 89s 5ms/step - loss: 0.6215 - accuracy: 0.6687 - val_loss: 0.6090 - val_accuracy: 0.6664\n",
      "Epoch 7/25\n",
      "17127/17127 [==============================] - 90s 5ms/step - loss: 0.6009 - accuracy: 0.6790 - val_loss: 0.5964 - val_accuracy: 0.6856\n",
      "Epoch 8/25\n",
      "17127/17127 [==============================] - 90s 5ms/step - loss: 0.5864 - accuracy: 0.6940 - val_loss: 0.5943 - val_accuracy: 0.6837\n",
      "Epoch 9/25\n",
      "17127/17127 [==============================] - 89s 5ms/step - loss: 0.5624 - accuracy: 0.7109 - val_loss: 0.5936 - val_accuracy: 0.6765\n",
      "Epoch 10/25\n",
      "17127/17127 [==============================] - 90s 5ms/step - loss: 0.5513 - accuracy: 0.7152 - val_loss: 0.5901 - val_accuracy: 0.6811\n",
      "Epoch 11/25\n",
      "17127/17127 [==============================] - 91s 5ms/step - loss: 0.5474 - accuracy: 0.7215 - val_loss: 0.5893 - val_accuracy: 0.6856\n",
      "Epoch 12/25\n",
      "17127/17127 [==============================] - 88s 5ms/step - loss: 0.5360 - accuracy: 0.7342 - val_loss: 0.5896 - val_accuracy: 0.6809\n",
      "Epoch 13/25\n",
      "17127/17127 [==============================] - 88s 5ms/step - loss: 0.5190 - accuracy: 0.7424 - val_loss: 0.5879 - val_accuracy: 0.6816\n",
      "Epoch 14/25\n",
      "17127/17127 [==============================] - 89s 5ms/step - loss: 0.5052 - accuracy: 0.7483 - val_loss: 0.5929 - val_accuracy: 0.6772\n",
      "Epoch 15/25\n",
      "17127/17127 [==============================] - 89s 5ms/step - loss: 0.5006 - accuracy: 0.7578 - val_loss: 0.5869 - val_accuracy: 0.6837\n",
      "Epoch 16/25\n",
      "17127/17127 [==============================] - 89s 5ms/step - loss: 0.4881 - accuracy: 0.7655 - val_loss: 0.5887 - val_accuracy: 0.6795\n",
      "Epoch 17/25\n",
      "17127/17127 [==============================] - 89s 5ms/step - loss: 0.4781 - accuracy: 0.7723 - val_loss: 0.5863 - val_accuracy: 0.6891\n",
      "Epoch 18/25\n",
      "17127/17127 [==============================] - 89s 5ms/step - loss: 0.4700 - accuracy: 0.7807 - val_loss: 0.5885 - val_accuracy: 0.6851\n",
      "Epoch 19/25\n",
      "17127/17127 [==============================] - 89s 5ms/step - loss: 0.4601 - accuracy: 0.7811 - val_loss: 0.5867 - val_accuracy: 0.6896\n",
      "Epoch 20/25\n",
      "17127/17127 [==============================] - 89s 5ms/step - loss: 0.4487 - accuracy: 0.7896 - val_loss: 0.6024 - val_accuracy: 0.6753\n",
      "Epoch 21/25\n",
      "17127/17127 [==============================] - 88s 5ms/step - loss: 0.4410 - accuracy: 0.7986 - val_loss: 0.5921 - val_accuracy: 0.6826\n",
      "Epoch 22/25\n",
      "17127/17127 [==============================] - 89s 5ms/step - loss: 0.4330 - accuracy: 0.8025 - val_loss: 0.5900 - val_accuracy: 0.6828\n",
      "Epoch 23/25\n",
      " 8450/17127 [=============>................] - ETA: 42s - loss: 0.4230 - accuracy: 0.8071"
     ]
    }
   ],
   "source": [
    "#Running the model & printing testing and validation accuracies and losses\n",
    "print(\"Training model...\")\n",
    "model.fit(x_train, y_train, batch_size = batch_size, epochs = epochs, verbose = 1, callbacks = [checkpoint],\\\n",
    "         validation_data = (x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
