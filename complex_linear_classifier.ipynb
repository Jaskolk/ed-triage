{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 768,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from torch.optim import Adam\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "%matplotlib inline\n",
    "import time\n",
    "from collections import Counter\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## first pass pre made BERT embeddings with continuous variable\n",
    "- made up data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj = torch.rand(160,768).numpy()\n",
    "medhx = torch.rand(160,768).numpy()\n",
    "cont = torch.rand(160,10).numpy()\n",
    "labels = torch.randint(0,3,(160,)).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((160, 768), (160, 768), (160, 10), (160,))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subj.shape, medhx.shape, cont.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subj, validation_subj = train_test_split(subj, random_state = 42, test_size=0.1)\n",
    "train_medhx, validation_medhx = train_test_split(medhx, random_state = 42, test_size=0.1)\n",
    "train_cont, validation_cont = train_test_split(cont, random_state = 42, test_size=0.1)\n",
    "train_labels, validation_labels = train_test_split(labels, random_state = 42, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subj = torch.tensor(train_subj)\n",
    "validation_subj = torch.tensor(validation_subj)\n",
    "train_medhx = torch.tensor(train_medhx)\n",
    "validation_medhx = torch.tensor(validation_medhx)\n",
    "train_cont = torch.tensor(train_cont)\n",
    "validation_cont = torch.tensor(validation_cont)\n",
    "train_labels = torch.tensor(train_labels)\n",
    "validation_labels = torch.tensor(validation_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a batch size for training. For fine-tuning BERT on a specific task, the authors recommend a batch size of 16 or 32\n",
    "batch_size = 4\n",
    "\n",
    "# Create an iterator of our data with torch DataLoader. This helps save on memory during training because, unlike a for loop, \n",
    "# with an iterator the entire dataset does not need to be loaded into memory\n",
    "\n",
    "train_data = TensorDataset(train_subj, train_medhx, train_cont,train_labels)\n",
    "trainloader = DataLoader(train_data, batch_size=batch_size)\n",
    "\n",
    "valid_data = TensorDataset(validation_subj, validation_medhx, validation_cont, validation_labels)\n",
    "validloader = DataLoader(valid_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameters\n",
    "lr = 1\n",
    "epochs = 10\n",
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.linear_subjective = nn.Linear(768,10)  \n",
    "        self.linear_medhx = nn.Linear(768, 10)\n",
    "        self.linear_combined = nn.Linear(30, 10)\n",
    "        self.out = nn.Linear(10,4)\n",
    "\n",
    "    def forward(self, subj,medhx,cont):\n",
    "        nlp1 = F.relu(self.linear_subjective(subj))\n",
    "        nlp2 = F.relu(self.linear_medhx(medhx))\n",
    "        combined = torch.cat((nlp1,nlp2,cont), axis = 1)\n",
    "        x = F.relu(self.linear_combined(combined))\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (linear_subjective): Linear(in_features=768, out_features=10, bias=True)\n",
       "  (linear_medhx): Linear(in_features=768, out_features=10, bias=True)\n",
       "  (linear_combined): Linear(in_features=30, out_features=10, bias=True)\n",
       "  (out): Linear(in_features=10, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Net()\n",
    "net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### testing the forward method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1,x2,x3,x4 = next(iter(trainloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1384,  0.2051, -0.3294,  0.1121],\n",
       "        [-0.1240,  0.2034, -0.3558,  0.1069],\n",
       "        [-0.1337,  0.2237, -0.3588,  0.0350],\n",
       "        [-0.1064,  0.2089, -0.3560,  0.1055]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(x1,x2,x3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trying the training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model):\n",
    "    optimizer = Adam(model.parameters(), lr = lr)\n",
    "    running_loss = []\n",
    "    for epoch_num in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for step_num, batch_data in enumerate(trainloader):\n",
    "        \n",
    "            cont_var, subj_notes, medhx, labels = tuple(t.to(device) for t in batch_data)\n",
    "        \n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "            logits = model(cont_var, subj_notes, medhx)#, cat_var)\n",
    "        \n",
    "            batch_loss = loss_func(logits, labels)\n",
    "        \n",
    "            train_loss += batch_loss.item()\n",
    "        \n",
    "            batch_loss.backward()\n",
    "        \n",
    "\n",
    "            clip_grad_norm_(parameters=model.parameters(), max_norm=1.0)\n",
    "        \n",
    "            optimizer.step()\n",
    "        \n",
    "            if step_num %12 == 0:\n",
    "                print('Epoch: ', epoch_num + 1)\n",
    "                print(\"\\r\" + \"{0}/{1} loss: {2} \".format(step_num, len(train_data) / batch_size, train_loss / (step_num + 1)))\n",
    "            \n",
    "        running_loss.append(train_loss)\n",
    "\n",
    "    return running_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1\n",
      "0/36.0 loss: 1.4609160423278809 \n",
      "Epoch:  1\n",
      "12/36.0 loss: 6626.937793273192 \n",
      "Epoch:  1\n",
      "24/36.0 loss: 3446.6568507003785 \n",
      "Epoch:  2\n",
      "0/36.0 loss: 1.6175388097763062 \n",
      "Epoch:  2\n",
      "12/36.0 loss: 1.2158456215491662 \n",
      "Epoch:  2\n",
      "24/36.0 loss: 1.1831336450576782 \n",
      "Epoch:  3\n",
      "0/36.0 loss: 1.5438588857650757 \n",
      "Epoch:  3\n",
      "12/36.0 loss: 1.1842343623821552 \n",
      "Epoch:  3\n",
      "24/36.0 loss: 1.159710364341736 \n",
      "Epoch:  4\n",
      "0/36.0 loss: 1.6018681526184082 \n",
      "Epoch:  4\n",
      "12/36.0 loss: 1.1966940256265493 \n",
      "Epoch:  4\n",
      "24/36.0 loss: 1.166122121810913 \n",
      "Epoch:  5\n",
      "0/36.0 loss: 1.6093086004257202 \n",
      "Epoch:  5\n",
      "12/36.0 loss: 1.2002241978278527 \n",
      "Epoch:  5\n",
      "24/36.0 loss: 1.1681951045989991 \n",
      "Epoch:  6\n",
      "0/36.0 loss: 1.6111395359039307 \n",
      "Epoch:  6\n",
      "12/36.0 loss: 1.2017108843876765 \n",
      "Epoch:  6\n",
      "24/36.0 loss: 1.1691481161117554 \n",
      "Epoch:  7\n",
      "0/36.0 loss: 1.61270010471344 \n",
      "Epoch:  7\n",
      "12/36.0 loss: 1.2026233948194063 \n",
      "Epoch:  7\n",
      "24/36.0 loss: 1.1697545337677002 \n",
      "Epoch:  8\n",
      "0/36.0 loss: 1.6136481761932373 \n",
      "Epoch:  8\n",
      "12/36.0 loss: 1.203214663725633 \n",
      "Epoch:  8\n",
      "24/36.0 loss: 1.1701646757125854 \n",
      "Epoch:  9\n",
      "0/36.0 loss: 1.6142199039459229 \n",
      "Epoch:  9\n",
      "12/36.0 loss: 1.2036263346672058 \n",
      "Epoch:  9\n",
      "24/36.0 loss: 1.170461027622223 \n",
      "Epoch:  10\n",
      "0/36.0 loss: 1.61459481716156 \n",
      "Epoch:  10\n",
      "12/36.0 loss: 1.2039314325039203 \n",
      "Epoch:  10\n",
      "24/36.0 loss: 1.1706869173049927 \n"
     ]
    }
   ],
   "source": [
    "cum_loss = train_model(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[86183.85667216778,\n",
       " 44.014511823654175,\n",
       " 43.58671426773071,\n",
       " 43.78844529390335,\n",
       " 43.84966313838959,\n",
       " 43.878470838069916,\n",
       " 43.89542007446289,\n",
       " 43.90597438812256,\n",
       " 43.91312235593796,\n",
       " 43.91829025745392]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cum_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a20f84fd0>]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(cum_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## now we are going to make the model more complex and add embedding\n",
    "- still made up data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj = torch.rand(160,768).numpy()\n",
    "medhx = torch.rand(160,768).numpy()\n",
    "cont = torch.rand(160,10).numpy()\n",
    "labels = torch.randint(0,3,(160,)).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = np.random.randint(1, 30, size=(160))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(cats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 11)"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#not sure which the best method for embedding filters is but likley # 2\n",
    "embedding_size = min(50, (len(set(cats))// 2) +1)\n",
    "embedding_size2 = min(600, round(1.6 * len(set(cats))**0.56))\n",
    "embedding_size, embedding_size2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subj, validation_subj = train_test_split(subj, random_state = 42, test_size=0.1)\n",
    "train_medhx, validation_medhx = train_test_split(medhx, random_state = 42, test_size=0.1)\n",
    "train_cont, validation_cont = train_test_split(cont, random_state = 42, test_size=0.1)\n",
    "train_cats, validation_cats = train_test_split(cats, random_state = 42, test_size=0.1)\n",
    "train_labels, validation_labels = train_test_split(labels, random_state = 42, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subj = torch.tensor(train_subj)\n",
    "validation_subj = torch.tensor(validation_subj)\n",
    "train_medhx = torch.tensor(train_medhx)\n",
    "validation_medhx = torch.tensor(validation_medhx)\n",
    "train_cont = torch.tensor(train_cont)\n",
    "validation_cont = torch.tensor(validation_cont)\n",
    "train_cats = torch.tensor(train_cats)\n",
    "validation_cats = torch.tensor(validation_cats)\n",
    "train_labels = torch.tensor(train_labels)\n",
    "validation_labels = torch.tensor(validation_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a batch size for training. For fine-tuning BERT on a specific task, the authors recommend a batch size of 16 or 32\n",
    "batch_size = 4\n",
    "\n",
    "# Create an iterator of our data with torch DataLoader. This helps save on memory during training because, unlike a for loop, \n",
    "# with an iterator the entire dataset does not need to be loaded into memory\n",
    "\n",
    "train_data = TensorDataset(train_subj, train_medhx, train_cont,train_cats,train_labels)\n",
    "trainloader = DataLoader(train_data, batch_size=batch_size)\n",
    "\n",
    "valid_data = TensorDataset(validation_subj, validation_medhx, validation_cont, validation_cats, validation_labels)\n",
    "validloader = DataLoader(valid_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net1, self).__init__()\n",
    "        \n",
    "        self.linear_subjective = nn.Linear(768,10)  \n",
    "        self.linear_medhx = nn.Linear(768, 10)\n",
    "        self.embedding = nn.Embedding(len(set(cats))+1, 30)\n",
    "        self.linear_cat = nn.Linear(30,10)\n",
    "        self.linear_combined = nn.Linear(40, 10)\n",
    "        self.out = nn.Linear(10,4)\n",
    "\n",
    "    def forward(self, subj,medhx,cont,cat_var):\n",
    "        nlp1 = F.relu(self.linear_subjective(subj))\n",
    "        nlp2 = F.relu(self.linear_medhx(medhx))\n",
    "        embeds = self.embedding(cat_var)\n",
    "        cats = F.relu(self.linear_cat(embeds))\n",
    "        combined = torch.cat((nlp1,nlp2,cont,cats), axis = 1)\n",
    "        x = F.relu(self.linear_combined(combined))\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model2(model, lr = 1e-3, epochs = 10, loss_func = nn.CrossEntropyLoss()):\n",
    "    optimizer = Adam(model.parameters(), lr = lr)\n",
    "    running_loss = []\n",
    "    for epoch_num in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for step_num, batch_data in enumerate(trainloader):\n",
    "        \n",
    "            cont_var, subj_notes, medhx, cat_var, labels = tuple(t.to(device) for t in batch_data)\n",
    "        \n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "            logits = model(cont_var, subj_notes, medhx, cat_var)\n",
    "        \n",
    "            batch_loss = loss_func(logits, labels)\n",
    "        \n",
    "            train_loss += batch_loss.item()\n",
    "        \n",
    "            batch_loss.backward()\n",
    "        \n",
    "\n",
    "            clip_grad_norm_(parameters=model.parameters(), max_norm=1.0)\n",
    "        \n",
    "            optimizer.step()\n",
    "        \n",
    "            print('Epoch: ', epoch_num + 1)\n",
    "            print(\"\\r\" + \"{0}/{1} loss: {2} \".format(step_num, len(train_data) / batch_size, train_loss / (step_num + 1)))\n",
    "            \n",
    "        running_loss.append(train_loss)\n",
    "\n",
    "    return running_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net1(\n",
      "  (linear_subjective): Linear(in_features=768, out_features=10, bias=True)\n",
      "  (linear_medhx): Linear(in_features=768, out_features=10, bias=True)\n",
      "  (embedding): Embedding(30, 30)\n",
      "  (linear_cat): Linear(in_features=30, out_features=10, bias=True)\n",
      "  (linear_combined): Linear(in_features=40, out_features=10, bias=True)\n",
      "  (out): Linear(in_features=10, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = Net1()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x1,x2,x3,x4,x5 = next(iter(trainloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0392, -0.2653, -0.2816, -0.0602],\n",
       "        [ 0.0389, -0.3038, -0.2784, -0.0424],\n",
       "        [ 0.1807, -0.2866, -0.2834, -0.0349],\n",
       "        [ 0.0880, -0.2504, -0.2093, -0.0058]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(x1,x2,x3,x4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1\n",
      "0/36.0 loss: 1.4564157724380493 \n",
      "Epoch:  1\n",
      "12/36.0 loss: 1.3908660778632531 \n",
      "Epoch:  1\n",
      "24/36.0 loss: 1.3096880102157593 \n",
      "Epoch:  2\n",
      "0/36.0 loss: 1.1334772109985352 \n",
      "Epoch:  2\n",
      "12/36.0 loss: 1.2425980797180762 \n",
      "Epoch:  2\n",
      "24/36.0 loss: 1.1831288576126098 \n",
      "Epoch:  3\n",
      "0/36.0 loss: 1.0782979726791382 \n",
      "Epoch:  3\n",
      "12/36.0 loss: 1.1369681174938495 \n",
      "Epoch:  3\n",
      "24/36.0 loss: 1.1143255043029785 \n",
      "Epoch:  4\n",
      "0/36.0 loss: 1.0798842906951904 \n",
      "Epoch:  4\n",
      "12/36.0 loss: 1.089571659381573 \n",
      "Epoch:  4\n",
      "24/36.0 loss: 1.0901463556289672 \n",
      "Epoch:  5\n",
      "0/36.0 loss: 1.0853729248046875 \n",
      "Epoch:  5\n",
      "12/36.0 loss: 1.0698626316510713 \n",
      "Epoch:  5\n",
      "24/36.0 loss: 1.0787011671066284 \n",
      "Epoch:  6\n",
      "0/36.0 loss: 1.0809965133666992 \n",
      "Epoch:  6\n",
      "12/36.0 loss: 1.0579146788670466 \n",
      "Epoch:  6\n",
      "24/36.0 loss: 1.070279860496521 \n",
      "Epoch:  7\n",
      "0/36.0 loss: 1.0749640464782715 \n",
      "Epoch:  7\n",
      "12/36.0 loss: 1.0462983617415795 \n",
      "Epoch:  7\n",
      "24/36.0 loss: 1.0594910216331481 \n",
      "Epoch:  8\n",
      "0/36.0 loss: 1.055727481842041 \n",
      "Epoch:  8\n",
      "12/36.0 loss: 1.032783554150508 \n",
      "Epoch:  8\n",
      "24/36.0 loss: 1.0454776430130004 \n",
      "Epoch:  9\n",
      "0/36.0 loss: 1.0343444347381592 \n",
      "Epoch:  9\n",
      "12/36.0 loss: 1.014243116745582 \n",
      "Epoch:  9\n",
      "24/36.0 loss: 1.0277545475959777 \n",
      "Epoch:  10\n",
      "0/36.0 loss: 1.007015585899353 \n",
      "Epoch:  10\n",
      "12/36.0 loss: 0.9970009097686181 \n",
      "Epoch:  10\n",
      "24/36.0 loss: 1.013094482421875 \n"
     ]
    }
   ],
   "source": [
    "cum_loss = train_model2(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## next I'm going to make a pipeline for converting a list of categories into embedded classes\n",
    "### and turn those into model layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "animals = ['manatee', 'dog', 'giraffe', 'narwhal', 'cat', 'elephant', 'mouse', 'dingo', 'wombat', 'skunk']\n",
    "cat_data = [[animal]* 16 for animal in animals]\n",
    "cat_data = [item for sublist in cat_data for item in sublist]\n",
    "random.shuffle(cat_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "animal_to_num = {animal:i for i,animal in enumerate(list(set(cat_data)))}\n",
    "num_to_animal = {i:animal for animal, i in enumerate(list(set(cat_data)))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is going to be my fake categorical animal data\n",
    "numerical_cat_data = [animal_to_num[item] for item in cat_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160, {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}, 10)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(numerical_cat_data), set(numerical_cat_data), len(set(numerical_cat_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### copied tabular learner code from fast.ai\n",
    "- trying to figure out how to build the model construction pipeline that I want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class TabularModel(nn.Module):\n",
    "    \"Basic model for tabular data.\"\n",
    "    def __init__(self, emb_szs:ListSizes, n_cont:int, out_sz:int, layers:Collection[int], ps:Collection[float]=None,\n",
    "                 emb_drop:float=0., y_range:OptRange=None, use_bn:bool=True, bn_final:bool=False):\n",
    "        super().__init__()\n",
    "        ps = ifnone(ps, [0]*len(layers))\n",
    "        ps = listify(ps, layers)\n",
    "        self.embeds = nn.ModuleList([embedding(ni, nf) for ni,nf in emb_szs])\n",
    "        self.emb_drop = nn.Dropout(emb_drop)\n",
    "        self.bn_cont = nn.BatchNorm1d(n_cont)\n",
    "        n_emb = sum(e.embedding_dim for e in self.embeds)\n",
    "        self.n_emb,self.n_cont,self.y_range = n_emb,n_cont,y_range\n",
    "        sizes = self.get_sizes(layers, out_sz)\n",
    "        actns = [nn.ReLU(inplace=True) for _ in range(len(sizes)-2)] + [None]\n",
    "        layers = []\n",
    "        for i,(n_in,n_out,dp,act) in enumerate(zip(sizes[:-1],sizes[1:],[0.]+ps,actns)):\n",
    "            layers += bn_drop_lin(n_in, n_out, bn=use_bn and i!=0, p=dp, actn=act)\n",
    "        if bn_final: layers.append(nn.BatchNorm1d(sizes[-1]))\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "    def get_sizes(self, layers, out_sz):\n",
    "        return [self.n_emb + self.n_cont] + layers + [out_sz]\n",
    "\n",
    "    def forward(self, x_cat:Tensor, x_cont:Tensor) -> Tensor:\n",
    "        if self.n_emb != 0:\n",
    "            x = [e(x_cat[:,i]) for i,e in enumerate(self.embeds)]\n",
    "            x = torch.cat(x, 1)\n",
    "            x = self.emb_drop(x)\n",
    "        if self.n_cont != 0:\n",
    "            x_cont = self.bn_cont(x_cont)\n",
    "            x = torch.cat([x, x_cont], 1) if self.n_emb != 0 else x_cont\n",
    "        x = self.layers(x)\n",
    "        if self.y_range is not None:\n",
    "            x = (self.y_range[1]-self.y_range[0]) * torch.sigmoid(x) + self.y_range[0]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "emb_szs = [(30,30), (20,20), (400,50)]\n",
    "embed_layers = nn.ModuleList([nn.Embedding(ni, nf) for ni,nf in emb_szs])\n",
    "embed_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "embed_layers = [nn.Embedding(ni, nf) for ni,nf in emb_szs]\n",
    "embed_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "n_emb = sum(e.embedding_dim for e in embed_layers); n_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "layers=[200,100]\n",
    "n_cont = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_sizes(layers, out_sz):\n",
    "    return [n_emb + n_cont] + layers + [out_sz]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sizes = get_sizes(layers, 4); sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "actns = [nn.ReLU(inplace=True) for _ in range(len(sizes)-2)] + [None]; actns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def forward(self, x_cat:Tensor, x_cont:Tensor) -> Tensor:\n",
    "        if self.n_emb != 0:\n",
    "            x = [e(x_cat[:,i]) for i,e in enumerate(self.embeds)]\n",
    "            x = torch.cat(x, 1)\n",
    "            x = self.emb_drop(x)\n",
    "        if self.n_cont != 0:\n",
    "            x_cont = self.bn_cont(x_cont)\n",
    "            x = torch.cat([x, x_cont], 1) if self.n_emb != 0 else x_cont\n",
    "        x = self.layers(x)\n",
    "        if self.y_range is not None:\n",
    "            x = (self.y_range[1]-self.y_range[0]) * torch.sigmoid(x) + self.y_range[0]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cats = np.random.randint(0, 29, size=(160))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cats.shape, len(set(cats))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fast.ai code code deconstructed above\n",
    "#### using that style to create my model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj = torch.rand(160,768).numpy()\n",
    "medhx = torch.rand(160,768).numpy()\n",
    "cont = torch.rand(160,10).numpy()\n",
    "labels = torch.randint(0,3,(160,)).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dtype('float32'), dtype('float32'))"
      ]
     },
     "execution_count": 612,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subj.dtype, medhx.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = np.random.randint(0, 29, size=(160))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [],
   "source": [
    "#so lets say I have 2 columns of categorical data:\n",
    "cat1 = numerical_cat_data #from the \"animal data\" I created above\n",
    "cat2 = cats #the original random number data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 596,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_list = [cat1,cat2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10, 29]"
      ]
     },
     "execution_count": 598,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_lengths = [len(set(cat)) for cat in cat_list]\n",
    "class_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160, 2)"
      ]
     },
     "execution_count": 599,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this is an array the categorical data\n",
    "cats_array = np.vstack([np.array(cat) for cat in cat_list]).transpose(); cats_array.shape\n",
    "\n",
    "#this is a code I used during dev to go straight to a tensor\n",
    "#torch_cats = torch.tensor(np.vstack([np.array(cat) for cat in cat_list])).t(); cat3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 9, 0, 0, 5, 2, 7, 9, 9, 4, 2, 6, 5, 3, 3, 4, 5, 9, 3, 0, 7, 6,\n",
       "       9, 1, 2, 8, 6, 2, 9, 6, 1, 1, 3, 2, 3, 5, 4, 9, 2, 3, 4, 8, 6, 7,\n",
       "       7, 3, 7, 6, 7, 9, 2, 0, 5, 7, 3, 3, 0, 4, 6, 7, 1, 5, 7, 7, 5, 3,\n",
       "       1, 0, 3, 4, 9, 8, 4, 6, 4, 3, 9, 2, 9, 2, 8, 8, 5, 4, 1, 5, 3, 8,\n",
       "       8, 6, 5, 3, 1, 1, 5, 7, 8, 0, 8, 5, 0, 1, 2, 4, 2, 5, 8, 4, 0, 0,\n",
       "       0, 3, 1, 7, 8, 5, 3, 6, 4, 0, 2, 6, 1, 8, 1, 9, 2, 8, 8, 6, 4, 4,\n",
       "       0, 6, 9, 8, 2, 1, 2, 6, 1, 8, 9, 7, 9, 6, 4, 0, 7, 9, 7, 0, 1, 2,\n",
       "       6, 5, 0, 5, 7, 4])"
      ]
     },
     "execution_count": 600,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cats_array[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5,  2, 18,  5, 12, 20,  1, 14, 20, 16, 11, 24,  2,  0, 28, 10, 18,\n",
       "       16, 27,  3, 12,  0, 18, 16, 19,  6, 27,  2, 16, 28, 12, 14, 17, 13,\n",
       "        3,  8, 10,  3, 21, 21, 24, 15, 27,  6,  3,  1,  4, 11,  2, 11, 22,\n",
       "       11, 12,  2, 17,  0,  2, 14,  2,  1, 21, 28,  4, 27, 12,  3, 28, 27,\n",
       "       13, 23,  2, 21, 23,  3, 25, 21,  2, 10, 14, 13,  2, 23, 28,  2, 18,\n",
       "        2, 26,  7, 26,  9, 19,  7, 10, 21, 19, 18, 17,  7, 20,  3, 22,  5,\n",
       "       22, 24, 17,  7,  5, 11, 18, 15,  7, 13,  4,  4, 16,  3, 26, 24,  1,\n",
       "       14, 25, 19, 25, 20, 11, 19, 25,  2,  8, 21, 20,  1, 28, 18, 17, 25,\n",
       "       28,  2,  4, 20, 20, 20, 12, 10, 12,  7, 24, 10, 13, 25, 10,  8,  5,\n",
       "       12,  4, 14, 26, 23, 26, 15])"
      ]
     },
     "execution_count": 601,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cats_array[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(10, 6), (29, 11)]"
      ]
     },
     "execution_count": 602,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating a set of embedding sizes for each categorical variable\n",
    "emb_szs = [(length, min(600, round(1.6 * length **0.56))) for length in class_lengths]\n",
    "emb_szs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net2(nn.Module):\n",
    "    def __init__(self, emb_szs):\n",
    "        super(Net2, self).__init__()\n",
    "        \n",
    "        #first create the embedding layers for each of the categorical variables\n",
    "        self.embed_layers = nn.ModuleList([nn.Embedding(ni, nf) for ni,nf in emb_szs])\n",
    "        n_emb = sum(e.embedding_dim for e in self.embed_layers)\n",
    "        \n",
    "        self.linear_subjective = nn.Linear(768,10)  \n",
    "        self.linear_medhx = nn.Linear(768, 10)\n",
    "        self.linear_cat = nn.Linear(n_emb,10)\n",
    "        self.linear_combined = nn.Linear(40, 10)\n",
    "        self.out = nn.Linear(10,4)\n",
    "\n",
    "    def forward(self, subj,medhx,cont,cat_var):\n",
    "        #first we run each BERT vector through a linear layer and activation\n",
    "        nlp1 = F.relu(self.linear_subjective(subj))\n",
    "        nlp2 = F.relu(self.linear_medhx(medhx))\n",
    "        \n",
    "        #now we pass each categorical variable through an embedding layer, combine output and pass through\n",
    "        #a linear layer with activation\n",
    "        embeds = [e(cat_var[:,i]) for i,e in enumerate(self.embed_layers)]\n",
    "        embeds = torch.cat(embeds, 1)\n",
    "        embeds = F.relu(self.linear_cat(embeds))\n",
    "        \n",
    "        #now we combine all four sources of input and pass through a layer with activation\n",
    "        combined = torch.cat((nlp1,nlp2,cont,embeds), axis = 1)\n",
    "        x = F.relu(self.linear_combined(combined))\n",
    "        \n",
    "        #compute logits\n",
    "        x = self.out(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net2(\n",
       "  (embed_layers): ModuleList(\n",
       "    (0): Embedding(10, 6)\n",
       "    (1): Embedding(29, 11)\n",
       "  )\n",
       "  (linear_subjective): Linear(in_features=768, out_features=10, bias=True)\n",
       "  (linear_medhx): Linear(in_features=768, out_features=10, bias=True)\n",
       "  (linear_cat): Linear(in_features=17, out_features=10, bias=True)\n",
       "  (linear_combined): Linear(in_features=40, out_features=10, bias=True)\n",
       "  (out): Linear(in_features=10, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 604,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Net2(emb_szs)\n",
    "net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### now lets create \"datasets, loaders, etc\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subj, validation_subj = train_test_split(subj, random_state = 42, test_size=0.1)\n",
    "train_medhx, validation_medhx = train_test_split(medhx, random_state = 42, test_size=0.1)\n",
    "train_cont, validation_cont = train_test_split(cont, random_state = 42, test_size=0.1)\n",
    "train_cats, validation_cats = train_test_split(cats_array, random_state = 42, test_size=0.1)\n",
    "train_labels, validation_labels = train_test_split(labels, random_state = 42, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subj = torch.tensor(train_subj)\n",
    "validation_subj = torch.tensor(validation_subj)\n",
    "train_medhx = torch.tensor(train_medhx)\n",
    "validation_medhx = torch.tensor(validation_medhx)\n",
    "train_cont = torch.tensor(train_cont)\n",
    "validation_cont = torch.tensor(validation_cont)\n",
    "train_cats = torch.tensor(train_cats)\n",
    "validation_cats = torch.tensor(validation_cats)\n",
    "train_labels = torch.tensor(train_labels)\n",
    "validation_labels = torch.tensor(validation_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "\n",
    "train_data = TensorDataset(train_subj, train_medhx, train_cont,train_cats,train_labels)\n",
    "trainloader = DataLoader(train_data, batch_size=batch_size)\n",
    "\n",
    "valid_data = TensorDataset(validation_subj, validation_medhx, validation_cont, validation_cats, validation_labels)\n",
    "validloader = DataLoader(valid_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1,x2,x3,x4,x5 = next(iter(trainloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1552, -0.2715, -0.1548, -0.0525],\n",
       "        [-0.1519, -0.2778, -0.1637, -0.0225],\n",
       "        [-0.2310, -0.2008, -0.1826, -0.0447],\n",
       "        [-0.2008, -0.2522, -0.1842, -0.0937]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 609,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(x1,x2,x3,x4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1\n",
      "0/36.0 loss: 1.470170497894287 \n",
      "Epoch:  1\n",
      "1/36.0 loss: 1.451158046722412 \n",
      "Epoch:  1\n",
      "2/36.0 loss: 1.4386531909306843 \n",
      "Epoch:  1\n",
      "3/36.0 loss: 1.4276705384254456 \n",
      "Epoch:  1\n",
      "4/36.0 loss: 1.4242132186889649 \n",
      "Epoch:  1\n",
      "5/36.0 loss: 1.4221746921539307 \n",
      "Epoch:  1\n",
      "6/36.0 loss: 1.4176146984100342 \n",
      "Epoch:  1\n",
      "7/36.0 loss: 1.4081696271896362 \n",
      "Epoch:  1\n",
      "8/36.0 loss: 1.4001778761545818 \n",
      "Epoch:  1\n",
      "9/36.0 loss: 1.39479501247406 \n",
      "Epoch:  1\n",
      "10/36.0 loss: 1.3899159323085437 \n",
      "Epoch:  1\n",
      "11/36.0 loss: 1.3730320831139882 \n",
      "Epoch:  1\n",
      "12/36.0 loss: 1.3738352427115808 \n",
      "Epoch:  1\n",
      "13/36.0 loss: 1.3693932039397103 \n",
      "Epoch:  1\n",
      "14/36.0 loss: 1.3622467994689942 \n",
      "Epoch:  1\n",
      "15/36.0 loss: 1.3599234595894814 \n",
      "Epoch:  1\n",
      "16/36.0 loss: 1.3525224924087524 \n",
      "Epoch:  1\n",
      "17/36.0 loss: 1.3453961544566684 \n",
      "Epoch:  1\n",
      "18/36.0 loss: 1.3340327488748651 \n",
      "Epoch:  1\n",
      "19/36.0 loss: 1.327636444568634 \n",
      "Epoch:  1\n",
      "20/36.0 loss: 1.3183319171269734 \n",
      "Epoch:  1\n",
      "21/36.0 loss: 1.3074766939336604 \n",
      "Epoch:  1\n",
      "22/36.0 loss: 1.292395249657009 \n",
      "Epoch:  1\n",
      "23/36.0 loss: 1.293146143356959 \n",
      "Epoch:  1\n",
      "24/36.0 loss: 1.3043660879135133 \n",
      "Epoch:  1\n",
      "25/36.0 loss: 1.2849988226707165 \n",
      "Epoch:  1\n",
      "26/36.0 loss: 1.2976298839957625 \n",
      "Epoch:  1\n",
      "27/36.0 loss: 1.2906496205500193 \n",
      "Epoch:  1\n",
      "28/36.0 loss: 1.2757231654791996 \n",
      "Epoch:  1\n",
      "29/36.0 loss: 1.2842416842778523 \n",
      "Epoch:  1\n",
      "30/36.0 loss: 1.2825315536991242 \n",
      "Epoch:  1\n",
      "31/36.0 loss: 1.2811034992337227 \n",
      "Epoch:  1\n",
      "32/36.0 loss: 1.2766226746819236 \n",
      "Epoch:  1\n",
      "33/36.0 loss: 1.2669543343431808 \n",
      "Epoch:  1\n",
      "34/36.0 loss: 1.2675161668232509 \n",
      "Epoch:  1\n",
      "35/36.0 loss: 1.2630556060208216 \n",
      "Epoch:  2\n",
      "0/36.0 loss: 1.673790693283081 \n",
      "Epoch:  2\n",
      "1/36.0 loss: 1.371775507926941 \n",
      "Epoch:  2\n",
      "2/36.0 loss: 1.2830390135447185 \n",
      "Epoch:  2\n",
      "3/36.0 loss: 1.3093644678592682 \n",
      "Epoch:  2\n",
      "4/36.0 loss: 1.269723129272461 \n",
      "Epoch:  2\n",
      "5/36.0 loss: 1.2860300540924072 \n",
      "Epoch:  2\n",
      "6/36.0 loss: 1.2449217438697815 \n",
      "Epoch:  2\n",
      "7/36.0 loss: 1.2234599813818932 \n",
      "Epoch:  2\n",
      "8/36.0 loss: 1.2233047551578946 \n",
      "Epoch:  2\n",
      "9/36.0 loss: 1.2241163074970245 \n",
      "Epoch:  2\n",
      "10/36.0 loss: 1.2344989288936963 \n",
      "Epoch:  2\n",
      "11/36.0 loss: 1.1921704014142354 \n",
      "Epoch:  2\n",
      "12/36.0 loss: 1.2119190509502704 \n",
      "Epoch:  2\n",
      "13/36.0 loss: 1.2109425834247045 \n",
      "Epoch:  2\n",
      "14/36.0 loss: 1.2080176750818887 \n",
      "Epoch:  2\n",
      "15/36.0 loss: 1.2145828604698181 \n",
      "Epoch:  2\n",
      "16/36.0 loss: 1.2070168186636532 \n",
      "Epoch:  2\n",
      "17/36.0 loss: 1.2011000050438776 \n",
      "Epoch:  2\n",
      "18/36.0 loss: 1.1886910325602482 \n",
      "Epoch:  2\n",
      "19/36.0 loss: 1.183409422636032 \n",
      "Epoch:  2\n",
      "20/36.0 loss: 1.1747445776349021 \n",
      "Epoch:  2\n",
      "21/36.0 loss: 1.1670393618670376 \n",
      "Epoch:  2\n",
      "22/36.0 loss: 1.154682439306508 \n",
      "Epoch:  2\n",
      "23/36.0 loss: 1.1572720607121785 \n",
      "Epoch:  2\n",
      "24/36.0 loss: 1.1692757606506348 \n",
      "Epoch:  2\n",
      "25/36.0 loss: 1.1537810976688678 \n",
      "Epoch:  2\n",
      "26/36.0 loss: 1.1653058131535847 \n",
      "Epoch:  2\n",
      "27/36.0 loss: 1.1638818425791604 \n",
      "Epoch:  2\n",
      "28/36.0 loss: 1.15405194512729 \n",
      "Epoch:  2\n",
      "29/36.0 loss: 1.1599020640055338 \n",
      "Epoch:  2\n",
      "30/36.0 loss: 1.160205856446297 \n",
      "Epoch:  2\n",
      "31/36.0 loss: 1.1610863916575909 \n",
      "Epoch:  2\n",
      "32/36.0 loss: 1.1586958675673513 \n",
      "Epoch:  2\n",
      "33/36.0 loss: 1.1536853418630713 \n",
      "Epoch:  2\n",
      "34/36.0 loss: 1.1530492169516426 \n",
      "Epoch:  2\n",
      "35/36.0 loss: 1.1501580311192408 \n",
      "Epoch:  3\n",
      "0/36.0 loss: 1.405700445175171 \n",
      "Epoch:  3\n",
      "1/36.0 loss: 1.263843595981598 \n",
      "Epoch:  3\n",
      "2/36.0 loss: 1.1902267535527546 \n",
      "Epoch:  3\n",
      "3/36.0 loss: 1.1954551935195923 \n",
      "Epoch:  3\n",
      "4/36.0 loss: 1.1665799379348756 \n",
      "Epoch:  3\n",
      "5/36.0 loss: 1.1752302447954814 \n",
      "Epoch:  3\n",
      "6/36.0 loss: 1.1465892962047033 \n",
      "Epoch:  3\n",
      "7/36.0 loss: 1.1343140751123428 \n",
      "Epoch:  3\n",
      "8/36.0 loss: 1.1249785423278809 \n",
      "Epoch:  3\n",
      "9/36.0 loss: 1.118956708908081 \n",
      "Epoch:  3\n",
      "10/36.0 loss: 1.1216303218494763 \n",
      "Epoch:  3\n",
      "11/36.0 loss: 1.0989140619834263 \n",
      "Epoch:  3\n",
      "12/36.0 loss: 1.1130531888741713 \n",
      "Epoch:  3\n",
      "13/36.0 loss: 1.108104761157717 \n",
      "Epoch:  3\n",
      "14/36.0 loss: 1.0999950528144837 \n",
      "Epoch:  3\n",
      "15/36.0 loss: 1.111858930438757 \n",
      "Epoch:  3\n",
      "16/36.0 loss: 1.1084747980622685 \n",
      "Epoch:  3\n",
      "17/36.0 loss: 1.11717970834838 \n",
      "Epoch:  3\n",
      "18/36.0 loss: 1.1077889800071716 \n",
      "Epoch:  3\n",
      "19/36.0 loss: 1.1056867033243178 \n",
      "Epoch:  3\n",
      "20/36.0 loss: 1.0989271373975844 \n",
      "Epoch:  3\n",
      "21/36.0 loss: 1.1008477021347394 \n",
      "Epoch:  3\n",
      "22/36.0 loss: 1.0961838468261387 \n",
      "Epoch:  3\n",
      "23/36.0 loss: 1.0954561059673626 \n",
      "Epoch:  3\n",
      "24/36.0 loss: 1.1007089161872863 \n",
      "Epoch:  3\n",
      "25/36.0 loss: 1.0902785658836365 \n",
      "Epoch:  3\n",
      "26/36.0 loss: 1.0960100094477336 \n",
      "Epoch:  3\n",
      "27/36.0 loss: 1.1023468588079726 \n",
      "Epoch:  3\n",
      "28/36.0 loss: 1.097378251881435 \n",
      "Epoch:  3\n",
      "29/36.0 loss: 1.0984664777914683 \n",
      "Epoch:  3\n",
      "30/36.0 loss: 1.100889769292647 \n",
      "Epoch:  3\n",
      "31/36.0 loss: 1.104640418663621 \n",
      "Epoch:  3\n",
      "32/36.0 loss: 1.102879327355009 \n",
      "Epoch:  3\n",
      "33/36.0 loss: 1.1019443115767311 \n",
      "Epoch:  3\n",
      "34/36.0 loss: 1.0990563920566014 \n",
      "Epoch:  3\n",
      "35/36.0 loss: 1.0965378135442734 \n",
      "Epoch:  4\n",
      "0/36.0 loss: 1.2961704730987549 \n",
      "Epoch:  4\n",
      "1/36.0 loss: 1.2596315145492554 \n",
      "Epoch:  4\n",
      "2/36.0 loss: 1.1746367613474529 \n",
      "Epoch:  4\n",
      "3/36.0 loss: 1.1734299659729004 \n",
      "Epoch:  4\n",
      "4/36.0 loss: 1.1409778594970703 \n",
      "Epoch:  4\n",
      "5/36.0 loss: 1.1487269600232441 \n",
      "Epoch:  4\n",
      "6/36.0 loss: 1.113757508141654 \n",
      "Epoch:  4\n",
      "7/36.0 loss: 1.1007394641637802 \n",
      "Epoch:  4\n",
      "8/36.0 loss: 1.0886045098304749 \n",
      "Epoch:  4\n",
      "9/36.0 loss: 1.0809744775295258 \n",
      "Epoch:  4\n",
      "10/36.0 loss: 1.086748323657296 \n",
      "Epoch:  4\n",
      "11/36.0 loss: 1.0589126994212468 \n",
      "Epoch:  4\n",
      "12/36.0 loss: 1.0801233832652752 \n",
      "Epoch:  4\n",
      "13/36.0 loss: 1.0746558180877142 \n",
      "Epoch:  4\n",
      "14/36.0 loss: 1.0661837220191956 \n",
      "Epoch:  4\n",
      "15/36.0 loss: 1.083922367542982 \n",
      "Epoch:  4\n",
      "16/36.0 loss: 1.0798994898796082 \n",
      "Epoch:  4\n",
      "17/36.0 loss: 1.09120484524303 \n",
      "Epoch:  4\n",
      "18/36.0 loss: 1.0796034053752297 \n",
      "Epoch:  4\n",
      "19/36.0 loss: 1.0768179565668106 \n",
      "Epoch:  4\n",
      "20/36.0 loss: 1.0684776050703866 \n",
      "Epoch:  4\n",
      "21/36.0 loss: 1.070743514732881 \n",
      "Epoch:  4\n",
      "22/36.0 loss: 1.064928798571877 \n",
      "Epoch:  4\n",
      "23/36.0 loss: 1.0656967088580132 \n",
      "Epoch:  4\n",
      "24/36.0 loss: 1.0743894696235656 \n",
      "Epoch:  4\n",
      "25/36.0 loss: 1.061504134765038 \n",
      "Epoch:  4\n",
      "26/36.0 loss: 1.0704736974504259 \n",
      "Epoch:  4\n",
      "27/36.0 loss: 1.078238376549312 \n",
      "Epoch:  4\n",
      "28/36.0 loss: 1.0724126306073418 \n",
      "Epoch:  4\n",
      "29/36.0 loss: 1.0751330574353537 \n",
      "Epoch:  4\n",
      "30/36.0 loss: 1.0785022897105063 \n",
      "Epoch:  4\n",
      "31/36.0 loss: 1.0833483673632145 \n",
      "Epoch:  4\n",
      "32/36.0 loss: 1.0811605995351619 \n",
      "Epoch:  4\n",
      "33/36.0 loss: 1.0803462617537554 \n",
      "Epoch:  4\n",
      "34/36.0 loss: 1.0774838158062525 \n",
      "Epoch:  4\n",
      "35/36.0 loss: 1.0746677269538243 \n",
      "Epoch:  5\n",
      "0/36.0 loss: 1.3197273015975952 \n",
      "Epoch:  5\n",
      "1/36.0 loss: 1.2790516018867493 \n",
      "Epoch:  5\n",
      "2/36.0 loss: 1.1764999429384868 \n",
      "Epoch:  5\n",
      "3/36.0 loss: 1.1734718531370163 \n",
      "Epoch:  5\n",
      "4/36.0 loss: 1.1341811418533325 \n",
      "Epoch:  5\n",
      "5/36.0 loss: 1.1403073072433472 \n",
      "Epoch:  5\n",
      "6/36.0 loss: 1.1032679506710596 \n",
      "Epoch:  5\n",
      "7/36.0 loss: 1.0880735144019127 \n",
      "Epoch:  5\n",
      "8/36.0 loss: 1.073310587141249 \n",
      "Epoch:  5\n",
      "9/36.0 loss: 1.0637852668762207 \n",
      "Epoch:  5\n",
      "10/36.0 loss: 1.0682430375706067 \n",
      "Epoch:  5\n",
      "11/36.0 loss: 1.042437846461932 \n",
      "Epoch:  5\n",
      "12/36.0 loss: 1.0630584267469554 \n",
      "Epoch:  5\n",
      "13/36.0 loss: 1.0565636370863234 \n",
      "Epoch:  5\n",
      "14/36.0 loss: 1.04699764251709 \n",
      "Epoch:  5\n",
      "15/36.0 loss: 1.0656240954995155 \n",
      "Epoch:  5\n",
      "16/36.0 loss: 1.0612681402879602 \n",
      "Epoch:  5\n",
      "17/36.0 loss: 1.0749623245663114 \n",
      "Epoch:  5\n",
      "18/36.0 loss: 1.0640852639549656 \n",
      "Epoch:  5\n",
      "19/36.0 loss: 1.0603607445955276 \n",
      "Epoch:  5\n",
      "20/36.0 loss: 1.0528233164832705 \n",
      "Epoch:  5\n",
      "21/36.0 loss: 1.0567122372713955 \n",
      "Epoch:  5\n",
      "22/36.0 loss: 1.0522459019785342 \n",
      "Epoch:  5\n",
      "23/36.0 loss: 1.0520085394382477 \n",
      "Epoch:  5\n",
      "24/36.0 loss: 1.0598203086853026 \n",
      "Epoch:  5\n",
      "25/36.0 loss: 1.04790755877128 \n",
      "Epoch:  5\n",
      "26/36.0 loss: 1.056160781118605 \n",
      "Epoch:  5\n",
      "27/36.0 loss: 1.0646070880549294 \n",
      "Epoch:  5\n",
      "28/36.0 loss: 1.05959768541928 \n",
      "Epoch:  5\n",
      "29/36.0 loss: 1.061910899480184 \n",
      "Epoch:  5\n",
      "30/36.0 loss: 1.065135625100905 \n",
      "Epoch:  5\n",
      "31/36.0 loss: 1.0700577571988106 \n",
      "Epoch:  5\n",
      "32/36.0 loss: 1.0672234983155222 \n",
      "Epoch:  5\n",
      "33/36.0 loss: 1.0667138625593746 \n",
      "Epoch:  5\n",
      "34/36.0 loss: 1.0636039904185703 \n",
      "Epoch:  5\n",
      "35/36.0 loss: 1.0602123969131045 \n",
      "Epoch:  6\n",
      "0/36.0 loss: 1.3040086030960083 \n",
      "Epoch:  6\n",
      "1/36.0 loss: 1.2701079845428467 \n",
      "Epoch:  6\n",
      "2/36.0 loss: 1.1583516995112102 \n",
      "Epoch:  6\n",
      "3/36.0 loss: 1.1569843590259552 \n",
      "Epoch:  6\n",
      "4/36.0 loss: 1.1133107662200927 \n",
      "Epoch:  6\n",
      "5/36.0 loss: 1.120303988456726 \n",
      "Epoch:  6\n",
      "6/36.0 loss: 1.0841494032314845 \n",
      "Epoch:  6\n",
      "7/36.0 loss: 1.0672228410840034 \n",
      "Epoch:  6\n",
      "8/36.0 loss: 1.052019516626994 \n",
      "Epoch:  6\n",
      "9/36.0 loss: 1.0425729870796203 \n",
      "Epoch:  6\n",
      "10/36.0 loss: 1.0467407378283413 \n",
      "Epoch:  6\n",
      "11/36.0 loss: 1.0223686198393505 \n",
      "Epoch:  6\n",
      "12/36.0 loss: 1.0432678736173189 \n",
      "Epoch:  6\n",
      "13/36.0 loss: 1.0366726687976293 \n",
      "Epoch:  6\n",
      "14/36.0 loss: 1.026777191956838 \n",
      "Epoch:  6\n",
      "15/36.0 loss: 1.045951697975397 \n",
      "Epoch:  6\n",
      "16/36.0 loss: 1.0411015959346996 \n",
      "Epoch:  6\n",
      "17/36.0 loss: 1.0561301973130968 \n",
      "Epoch:  6\n",
      "18/36.0 loss: 1.0458721173437018 \n",
      "Epoch:  6\n",
      "19/36.0 loss: 1.0410511434078216 \n",
      "Epoch:  6\n",
      "20/36.0 loss: 1.0343019650095986 \n",
      "Epoch:  6\n",
      "21/36.0 loss: 1.0391846163706346 \n",
      "Epoch:  6\n",
      "22/36.0 loss: 1.0355080547540083 \n",
      "Epoch:  6\n",
      "23/36.0 loss: 1.0346862350900967 \n",
      "Epoch:  6\n",
      "24/36.0 loss: 1.0426738905906676 \n",
      "Epoch:  6\n",
      "25/36.0 loss: 1.0311641349242284 \n",
      "Epoch:  6\n",
      "26/36.0 loss: 1.039753258228302 \n",
      "Epoch:  6\n",
      "27/36.0 loss: 1.04848812520504 \n",
      "Epoch:  6\n",
      "28/36.0 loss: 1.0438451746414448 \n",
      "Epoch:  6\n",
      "29/36.0 loss: 1.0465332885583243 \n",
      "Epoch:  6\n",
      "30/36.0 loss: 1.049570700814647 \n",
      "Epoch:  6\n",
      "31/36.0 loss: 1.054610500112176 \n",
      "Epoch:  6\n",
      "32/36.0 loss: 1.0508658506653525 \n",
      "Epoch:  6\n",
      "33/36.0 loss: 1.0504474271746242 \n",
      "Epoch:  6\n",
      "34/36.0 loss: 1.0472106899533953 \n",
      "Epoch:  6\n",
      "35/36.0 loss: 1.043055580721961 \n",
      "Epoch:  7\n",
      "0/36.0 loss: 1.2946051359176636 \n",
      "Epoch:  7\n",
      "1/36.0 loss: 1.2630196809768677 \n",
      "Epoch:  7\n",
      "2/36.0 loss: 1.1384411454200745 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  7\n",
      "3/36.0 loss: 1.138667806982994 \n",
      "Epoch:  7\n",
      "4/36.0 loss: 1.0891778707504272 \n",
      "Epoch:  7\n",
      "5/36.0 loss: 1.096759816010793 \n",
      "Epoch:  7\n",
      "6/36.0 loss: 1.0616603663989477 \n",
      "Epoch:  7\n",
      "7/36.0 loss: 1.0424295589327812 \n",
      "Epoch:  7\n",
      "8/36.0 loss: 1.0266159971555073 \n",
      "Epoch:  7\n",
      "9/36.0 loss: 1.0167916595935822 \n",
      "Epoch:  7\n",
      "10/36.0 loss: 1.0201617641882463 \n",
      "Epoch:  7\n",
      "11/36.0 loss: 0.9980736573537191 \n",
      "Epoch:  7\n",
      "12/36.0 loss: 1.0189783573150635 \n",
      "Epoch:  7\n",
      "13/36.0 loss: 1.0119546226092748 \n",
      "Epoch:  7\n",
      "14/36.0 loss: 1.0013582269350687 \n",
      "Epoch:  7\n",
      "15/36.0 loss: 1.021242666989565 \n",
      "Epoch:  7\n",
      "16/36.0 loss: 1.0159154955078573 \n",
      "Epoch:  7\n",
      "17/36.0 loss: 1.032979240020116 \n",
      "Epoch:  7\n",
      "18/36.0 loss: 1.0235694678206193 \n",
      "Epoch:  7\n",
      "19/36.0 loss: 1.0174830704927444 \n",
      "Epoch:  7\n",
      "20/36.0 loss: 1.0117420156796773 \n",
      "Epoch:  7\n",
      "21/36.0 loss: 1.0180136046626351 \n",
      "Epoch:  7\n",
      "22/36.0 loss: 1.0153798486875452 \n",
      "Epoch:  7\n",
      "23/36.0 loss: 1.0138125518957775 \n",
      "Epoch:  7\n",
      "24/36.0 loss: 1.0220188617706298 \n",
      "Epoch:  7\n",
      "25/36.0 loss: 1.0109225878348718 \n",
      "Epoch:  7\n",
      "26/36.0 loss: 1.0199903470498544 \n",
      "Epoch:  7\n",
      "27/36.0 loss: 1.0290858106953757 \n",
      "Epoch:  7\n",
      "28/36.0 loss: 1.024796991512693 \n",
      "Epoch:  7\n",
      "29/36.0 loss: 1.028013253211975 \n",
      "Epoch:  7\n",
      "30/36.0 loss: 1.0308282336881083 \n",
      "Epoch:  7\n",
      "31/36.0 loss: 1.0360162518918514 \n",
      "Epoch:  7\n",
      "32/36.0 loss: 1.0311995148658752 \n",
      "Epoch:  7\n",
      "33/36.0 loss: 1.0308490518261404 \n",
      "Epoch:  7\n",
      "34/36.0 loss: 1.027421840599605 \n",
      "Epoch:  7\n",
      "35/36.0 loss: 1.0224589738580916 \n",
      "Epoch:  8\n",
      "0/36.0 loss: 1.272952675819397 \n",
      "Epoch:  8\n",
      "1/36.0 loss: 1.2554299235343933 \n",
      "Epoch:  8\n",
      "2/36.0 loss: 1.1159759362538655 \n",
      "Epoch:  8\n",
      "3/36.0 loss: 1.11177659034729 \n",
      "Epoch:  8\n",
      "4/36.0 loss: 1.056872510910034 \n",
      "Epoch:  8\n",
      "5/36.0 loss: 1.0612189372380574 \n",
      "Epoch:  8\n",
      "6/36.0 loss: 1.0291633776256017 \n",
      "Epoch:  8\n",
      "7/36.0 loss: 1.0081288442015648 \n",
      "Epoch:  8\n",
      "8/36.0 loss: 0.9888369176122878 \n",
      "Epoch:  8\n",
      "9/36.0 loss: 0.9773045003414154 \n",
      "Epoch:  8\n",
      "10/36.0 loss: 0.9786454926837574 \n",
      "Epoch:  8\n",
      "11/36.0 loss: 0.9626761277516683 \n",
      "Epoch:  8\n",
      "12/36.0 loss: 0.9828077371303852 \n",
      "Epoch:  8\n",
      "13/36.0 loss: 0.9747745181832995 \n",
      "Epoch:  8\n",
      "14/36.0 loss: 0.9630964080492656 \n",
      "Epoch:  8\n",
      "15/36.0 loss: 0.98462750390172 \n",
      "Epoch:  8\n",
      "16/36.0 loss: 0.9795914642951068 \n",
      "Epoch:  8\n",
      "17/36.0 loss: 1.000684337483512 \n",
      "Epoch:  8\n",
      "18/36.0 loss: 0.9926145892394217 \n",
      "Epoch:  8\n",
      "19/36.0 loss: 0.9855216145515442 \n",
      "Epoch:  8\n",
      "20/36.0 loss: 0.9811140469142369 \n",
      "Epoch:  8\n",
      "21/36.0 loss: 0.9895003383809869 \n",
      "Epoch:  8\n",
      "22/36.0 loss: 0.988239366075267 \n",
      "Epoch:  8\n",
      "23/36.0 loss: 0.9860777879754702 \n",
      "Epoch:  8\n",
      "24/36.0 loss: 0.9949235081672668 \n",
      "Epoch:  8\n",
      "25/36.0 loss: 0.9839899058525379 \n",
      "Epoch:  8\n",
      "26/36.0 loss: 0.9941687164483247 \n",
      "Epoch:  8\n",
      "27/36.0 loss: 1.0039725026914053 \n",
      "Epoch:  8\n",
      "28/36.0 loss: 0.999811604105193 \n",
      "Epoch:  8\n",
      "29/36.0 loss: 1.004059080282847 \n",
      "Epoch:  8\n",
      "30/36.0 loss: 1.0069101933510072 \n",
      "Epoch:  8\n",
      "31/36.0 loss: 1.0125240497291088 \n",
      "Epoch:  8\n",
      "32/36.0 loss: 1.0065731171405676 \n",
      "Epoch:  8\n",
      "33/36.0 loss: 1.0062819771906908 \n",
      "Epoch:  8\n",
      "34/36.0 loss: 1.0028108545712062 \n",
      "Epoch:  8\n",
      "35/36.0 loss: 0.9973575621843338 \n",
      "Epoch:  9\n",
      "0/36.0 loss: 1.2784236669540405 \n",
      "Epoch:  9\n",
      "1/36.0 loss: 1.256507933139801 \n",
      "Epoch:  9\n",
      "2/36.0 loss: 1.099102516969045 \n",
      "Epoch:  9\n",
      "3/36.0 loss: 1.0938246101140976 \n",
      "Epoch:  9\n",
      "4/36.0 loss: 1.0308780550956727 \n",
      "Epoch:  9\n",
      "5/36.0 loss: 1.0327819883823395 \n",
      "Epoch:  9\n",
      "6/36.0 loss: 1.0012884395463126 \n",
      "Epoch:  9\n",
      "7/36.0 loss: 0.9777935966849327 \n",
      "Epoch:  9\n",
      "8/36.0 loss: 0.9549242854118347 \n",
      "Epoch:  9\n",
      "9/36.0 loss: 0.9411919057369232 \n",
      "Epoch:  9\n",
      "10/36.0 loss: 0.9399889003146779 \n",
      "Epoch:  9\n",
      "11/36.0 loss: 0.9301308741172155 \n",
      "Epoch:  9\n",
      "12/36.0 loss: 0.9489837563954867 \n",
      "Epoch:  9\n",
      "13/36.0 loss: 0.9387752882071904 \n",
      "Epoch:  9\n",
      "14/36.0 loss: 0.9252910017967224 \n",
      "Epoch:  9\n",
      "15/36.0 loss: 0.9473500289022923 \n",
      "Epoch:  9\n",
      "16/36.0 loss: 0.942327667685116 \n",
      "Epoch:  9\n",
      "17/36.0 loss: 0.969216333495246 \n",
      "Epoch:  9\n",
      "18/36.0 loss: 0.9662707730343467 \n",
      "Epoch:  9\n",
      "19/36.0 loss: 0.9589273869991303 \n",
      "Epoch:  9\n",
      "20/36.0 loss: 0.9586541397230965 \n",
      "Epoch:  9\n",
      "21/36.0 loss: 0.9703530804677443 \n",
      "Epoch:  9\n",
      "22/36.0 loss: 0.9707707892293516 \n",
      "Epoch:  9\n",
      "23/36.0 loss: 0.9672535409530004 \n",
      "Epoch:  9\n",
      "24/36.0 loss: 0.9758875513076782 \n",
      "Epoch:  9\n",
      "25/36.0 loss: 0.9640422830214868 \n",
      "Epoch:  9\n",
      "26/36.0 loss: 0.9752974112828573 \n",
      "Epoch:  9\n",
      "27/36.0 loss: 0.9848729584898267 \n",
      "Epoch:  9\n",
      "28/36.0 loss: 0.9796417006130876 \n",
      "Epoch:  9\n",
      "29/36.0 loss: 0.9863532106081645 \n",
      "Epoch:  9\n",
      "30/36.0 loss: 0.988681027966161 \n",
      "Epoch:  9\n",
      "31/36.0 loss: 0.9944427944719791 \n",
      "Epoch:  9\n",
      "32/36.0 loss: 0.986900573427027 \n",
      "Epoch:  9\n",
      "33/36.0 loss: 0.9864815035287071 \n",
      "Epoch:  9\n",
      "34/36.0 loss: 0.9829088415418352 \n",
      "Epoch:  9\n",
      "35/36.0 loss: 0.976033392879698 \n",
      "Epoch:  10\n",
      "0/36.0 loss: 1.1796255111694336 \n",
      "Epoch:  10\n",
      "1/36.0 loss: 1.2170595526695251 \n",
      "Epoch:  10\n",
      "2/36.0 loss: 1.0565312306086223 \n",
      "Epoch:  10\n",
      "3/36.0 loss: 1.0378409922122955 \n",
      "Epoch:  10\n",
      "4/36.0 loss: 0.9768593192100525 \n",
      "Epoch:  10\n",
      "5/36.0 loss: 0.9700036545594534 \n",
      "Epoch:  10\n",
      "6/36.0 loss: 0.949321482862745 \n",
      "Epoch:  10\n",
      "7/36.0 loss: 0.9244602993130684 \n",
      "Epoch:  10\n",
      "8/36.0 loss: 0.8995122710863749 \n",
      "Epoch:  10\n",
      "9/36.0 loss: 0.8848424673080444 \n",
      "Epoch:  10\n",
      "10/36.0 loss: 0.8833857178688049 \n",
      "Epoch:  10\n",
      "11/36.0 loss: 0.8799368888139725 \n",
      "Epoch:  10\n",
      "12/36.0 loss: 0.8989284542890695 \n",
      "Epoch:  10\n",
      "13/36.0 loss: 0.8879137592656272 \n",
      "Epoch:  10\n",
      "14/36.0 loss: 0.8741167108217875 \n",
      "Epoch:  10\n",
      "15/36.0 loss: 0.8966489695012569 \n",
      "Epoch:  10\n",
      "16/36.0 loss: 0.8908963238491732 \n",
      "Epoch:  10\n",
      "17/36.0 loss: 0.9168566498491499 \n",
      "Epoch:  10\n",
      "18/36.0 loss: 0.9119567337789034 \n",
      "Epoch:  10\n",
      "19/36.0 loss: 0.9030905425548553 \n",
      "Epoch:  10\n",
      "20/36.0 loss: 0.9011481602986654 \n",
      "Epoch:  10\n",
      "21/36.0 loss: 0.9111169847575101 \n",
      "Epoch:  10\n",
      "22/36.0 loss: 0.9092474139255026 \n",
      "Epoch:  10\n",
      "23/36.0 loss: 0.9084542195002238 \n",
      "Epoch:  10\n",
      "24/36.0 loss: 0.9246570205688477 \n",
      "Epoch:  10\n",
      "25/36.0 loss: 0.9098405654613788 \n",
      "Epoch:  10\n",
      "26/36.0 loss: 0.9289082244590476 \n",
      "Epoch:  10\n",
      "27/36.0 loss: 0.9397705154759544 \n",
      "Epoch:  10\n",
      "28/36.0 loss: 0.933403730392456 \n",
      "Epoch:  10\n",
      "29/36.0 loss: 0.9453367511431376 \n",
      "Epoch:  10\n",
      "30/36.0 loss: 0.9489388350517519 \n",
      "Epoch:  10\n",
      "31/36.0 loss: 0.9561643600463867 \n",
      "Epoch:  10\n",
      "32/36.0 loss: 0.948219895362854 \n",
      "Epoch:  10\n",
      "33/36.0 loss: 0.9479378041099099 \n",
      "Epoch:  10\n",
      "34/36.0 loss: 0.9441144023622785 \n",
      "Epoch:  10\n",
      "35/36.0 loss: 0.9364226311445236 \n",
      "Epoch:  11\n",
      "0/36.0 loss: 1.1790072917938232 \n",
      "Epoch:  11\n",
      "1/36.0 loss: 1.2290235757827759 \n",
      "Epoch:  11\n",
      "2/36.0 loss: 1.0507216652234395 \n",
      "Epoch:  11\n",
      "3/36.0 loss: 1.016962081193924 \n",
      "Epoch:  11\n",
      "4/36.0 loss: 0.9522233009338379 \n",
      "Epoch:  11\n",
      "5/36.0 loss: 0.9351874987284342 \n",
      "Epoch:  11\n",
      "6/36.0 loss: 0.9184953059468951 \n",
      "Epoch:  11\n",
      "7/36.0 loss: 0.8947266712784767 \n",
      "Epoch:  11\n",
      "8/36.0 loss: 0.8631507754325867 \n",
      "Epoch:  11\n",
      "9/36.0 loss: 0.8443576514720916 \n",
      "Epoch:  11\n",
      "10/36.0 loss: 0.8386031931096857 \n",
      "Epoch:  11\n",
      "11/36.0 loss: 0.8435544967651367 \n",
      "Epoch:  11\n",
      "12/36.0 loss: 0.8602993855109582 \n",
      "Epoch:  11\n",
      "13/36.0 loss: 0.8463343254157475 \n",
      "Epoch:  11\n",
      "14/36.0 loss: 0.8303783456484477 \n",
      "Epoch:  11\n",
      "15/36.0 loss: 0.8544235192239285 \n",
      "Epoch:  11\n",
      "16/36.0 loss: 0.8478886450038237 \n",
      "Epoch:  11\n",
      "17/36.0 loss: 0.875377529197269 \n",
      "Epoch:  11\n",
      "18/36.0 loss: 0.8698276720548931 \n",
      "Epoch:  11\n",
      "19/36.0 loss: 0.85918188393116 \n",
      "Epoch:  11\n",
      "20/36.0 loss: 0.8568269638788133 \n",
      "Epoch:  11\n",
      "21/36.0 loss: 0.8668102025985718 \n",
      "Epoch:  11\n",
      "22/36.0 loss: 0.8648225380026776 \n",
      "Epoch:  11\n",
      "23/36.0 loss: 0.8645305261015892 \n",
      "Epoch:  11\n",
      "24/36.0 loss: 0.8835705018043518 \n",
      "Epoch:  11\n",
      "25/36.0 loss: 0.8685267281073791 \n",
      "Epoch:  11\n",
      "26/36.0 loss: 0.8913632090444918 \n",
      "Epoch:  11\n",
      "27/36.0 loss: 0.9029199853539467 \n",
      "Epoch:  11\n",
      "28/36.0 loss: 0.896210299483661 \n",
      "Epoch:  11\n",
      "29/36.0 loss: 0.9099831809600194 \n",
      "Epoch:  11\n",
      "30/36.0 loss: 0.9136082231998444 \n",
      "Epoch:  11\n",
      "31/36.0 loss: 0.921180653385818 \n",
      "Epoch:  11\n",
      "32/36.0 loss: 0.9126526343099999 \n",
      "Epoch:  11\n",
      "33/36.0 loss: 0.9125986388501 \n",
      "Epoch:  11\n",
      "34/36.0 loss: 0.9082330916609083 \n",
      "Epoch:  11\n",
      "35/36.0 loss: 0.9000474289059639 \n",
      "Epoch:  12\n",
      "0/36.0 loss: 1.1532292366027832 \n",
      "Epoch:  12\n",
      "1/36.0 loss: 1.2136173248291016 \n",
      "Epoch:  12\n",
      "2/36.0 loss: 1.028106431166331 \n",
      "Epoch:  12\n",
      "3/36.0 loss: 0.9839750379323959 \n",
      "Epoch:  12\n",
      "4/36.0 loss: 0.9182632207870484 \n",
      "Epoch:  12\n",
      "5/36.0 loss: 0.8925196429093679 \n",
      "Epoch:  12\n",
      "6/36.0 loss: 0.8799839871270316 \n",
      "Epoch:  12\n",
      "7/36.0 loss: 0.8574298322200775 \n",
      "Epoch:  12\n",
      "8/36.0 loss: 0.8215238915549384 \n",
      "Epoch:  12\n",
      "9/36.0 loss: 0.800440114736557 \n",
      "Epoch:  12\n",
      "10/36.0 loss: 0.7915100888772444 \n",
      "Epoch:  12\n",
      "11/36.0 loss: 0.8005971858898798 \n",
      "Epoch:  12\n",
      "12/36.0 loss: 0.8164081160838788 \n",
      "Epoch:  12\n",
      "13/36.0 loss: 0.8000696216310773 \n",
      "Epoch:  12\n",
      "14/36.0 loss: 0.7824883063634237 \n",
      "Epoch:  12\n",
      "15/36.0 loss: 0.8072203397750854 \n",
      "Epoch:  12\n",
      "16/36.0 loss: 0.7999077228938832 \n",
      "Epoch:  12\n",
      "17/36.0 loss: 0.8280971414513059 \n",
      "Epoch:  12\n",
      "18/36.0 loss: 0.8224500009888097 \n",
      "Epoch:  12\n",
      "19/36.0 loss: 0.8111564338207244 \n",
      "Epoch:  12\n",
      "20/36.0 loss: 0.8086640721275693 \n",
      "Epoch:  12\n",
      "21/36.0 loss: 0.8184330571781505 \n",
      "Epoch:  12\n",
      "22/36.0 loss: 0.8162921978079755 \n",
      "Epoch:  12\n",
      "23/36.0 loss: 0.8170550813277563 \n",
      "Epoch:  12\n",
      "24/36.0 loss: 0.8401227521896363 \n",
      "Epoch:  12\n",
      "25/36.0 loss: 0.8247963075454419 \n",
      "Epoch:  12\n",
      "26/36.0 loss: 0.8519972408259356 \n",
      "Epoch:  12\n",
      "27/36.0 loss: 0.8639394364186695 \n",
      "Epoch:  12\n",
      "28/36.0 loss: 0.8573407777424517 \n",
      "Epoch:  12\n",
      "29/36.0 loss: 0.8737581431865692 \n",
      "Epoch:  12\n",
      "30/36.0 loss: 0.8771955601630672 \n",
      "Epoch:  12\n",
      "31/36.0 loss: 0.8845853749662638 \n",
      "Epoch:  12\n",
      "32/36.0 loss: 0.8756271149172927 \n",
      "Epoch:  12\n",
      "33/36.0 loss: 0.8757063202998218 \n",
      "Epoch:  12\n",
      "34/36.0 loss: 0.8707022871289934 \n",
      "Epoch:  12\n",
      "35/36.0 loss: 0.8622157639927335 \n",
      "Epoch:  13\n",
      "0/36.0 loss: 1.1003414392471313 \n",
      "Epoch:  13\n",
      "1/36.0 loss: 1.1745640635490417 \n",
      "Epoch:  13\n",
      "2/36.0 loss: 0.9892061551411947 \n",
      "Epoch:  13\n",
      "3/36.0 loss: 0.9386364817619324 \n",
      "Epoch:  13\n",
      "4/36.0 loss: 0.8730070114135742 \n",
      "Epoch:  13\n",
      "5/36.0 loss: 0.8387810389200846 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  13\n",
      "6/36.0 loss: 0.8293542180742536 \n",
      "Epoch:  13\n",
      "7/36.0 loss: 0.8069928884506226 \n",
      "Epoch:  13\n",
      "8/36.0 loss: 0.7689725160598755 \n",
      "Epoch:  13\n",
      "9/36.0 loss: 0.7469903528690338 \n",
      "Epoch:  13\n",
      "10/36.0 loss: 0.7359620061787692 \n",
      "Epoch:  13\n",
      "11/36.0 loss: 0.7465358376502991 \n",
      "Epoch:  13\n",
      "12/36.0 loss: 0.7620229583520156 \n",
      "Epoch:  13\n",
      "13/36.0 loss: 0.7445019355842045 \n",
      "Epoch:  13\n",
      "14/36.0 loss: 0.7262901385625203 \n",
      "Epoch:  13\n",
      "15/36.0 loss: 0.7511710599064827 \n",
      "Epoch:  13\n",
      "16/36.0 loss: 0.7437068153830135 \n",
      "Epoch:  13\n",
      "17/36.0 loss: 0.7727319134606255 \n",
      "Epoch:  13\n",
      "18/36.0 loss: 0.7680965348293907 \n",
      "Epoch:  13\n",
      "19/36.0 loss: 0.7567884296178817 \n",
      "Epoch:  13\n",
      "20/36.0 loss: 0.7548455113456363 \n",
      "Epoch:  13\n",
      "21/36.0 loss: 0.765101053498008 \n",
      "Epoch:  13\n",
      "22/36.0 loss: 0.763705092927684 \n",
      "Epoch:  13\n",
      "23/36.0 loss: 0.7649109835426012 \n",
      "Epoch:  13\n",
      "24/36.0 loss: 0.7904721140861511 \n",
      "Epoch:  13\n",
      "25/36.0 loss: 0.7757754016381043 \n",
      "Epoch:  13\n",
      "26/36.0 loss: 0.807366919738275 \n",
      "Epoch:  13\n",
      "27/36.0 loss: 0.8200145119002887 \n",
      "Epoch:  13\n",
      "28/36.0 loss: 0.8135931296595211 \n",
      "Epoch:  13\n",
      "29/36.0 loss: 0.8325352877378464 \n",
      "Epoch:  13\n",
      "30/36.0 loss: 0.836032364637621 \n",
      "Epoch:  13\n",
      "31/36.0 loss: 0.8433887595310807 \n",
      "Epoch:  13\n",
      "32/36.0 loss: 0.834414828004259 \n",
      "Epoch:  13\n",
      "33/36.0 loss: 0.8346649802782956 \n",
      "Epoch:  13\n",
      "34/36.0 loss: 0.8291156828403473 \n",
      "Epoch:  13\n",
      "35/36.0 loss: 0.8205665573477745 \n",
      "Epoch:  14\n",
      "0/36.0 loss: 1.0487403869628906 \n",
      "Epoch:  14\n",
      "1/36.0 loss: 1.1359414458274841 \n",
      "Epoch:  14\n",
      "2/36.0 loss: 0.9536470969518026 \n",
      "Epoch:  14\n",
      "3/36.0 loss: 0.8920864313840866 \n",
      "Epoch:  14\n",
      "4/36.0 loss: 0.829186737537384 \n",
      "Epoch:  14\n",
      "5/36.0 loss: 0.7868190904458364 \n",
      "Epoch:  14\n",
      "6/36.0 loss: 0.7855932286807469 \n",
      "Epoch:  14\n",
      "7/36.0 loss: 0.7648224458098412 \n",
      "Epoch:  14\n",
      "8/36.0 loss: 0.7250544495052762 \n",
      "Epoch:  14\n",
      "9/36.0 loss: 0.7018193989992142 \n",
      "Epoch:  14\n",
      "10/36.0 loss: 0.6884922737425024 \n",
      "Epoch:  14\n",
      "11/36.0 loss: 0.7014455373088518 \n",
      "Epoch:  14\n",
      "12/36.0 loss: 0.7153715055722457 \n",
      "Epoch:  14\n",
      "13/36.0 loss: 0.6967493976865496 \n",
      "Epoch:  14\n",
      "14/36.0 loss: 0.6780164579550425 \n",
      "Epoch:  14\n",
      "15/36.0 loss: 0.7021127063781023 \n",
      "Epoch:  14\n",
      "16/36.0 loss: 0.6940227273632499 \n",
      "Epoch:  14\n",
      "17/36.0 loss: 0.7217298365301557 \n",
      "Epoch:  14\n",
      "18/36.0 loss: 0.7176515789408433 \n",
      "Epoch:  14\n",
      "19/36.0 loss: 0.7064555570483207 \n",
      "Epoch:  14\n",
      "20/36.0 loss: 0.704774043389729 \n",
      "Epoch:  14\n",
      "21/36.0 loss: 0.7148216569965536 \n",
      "Epoch:  14\n",
      "22/36.0 loss: 0.7141985647056414 \n",
      "Epoch:  14\n",
      "23/36.0 loss: 0.7151845283806324 \n",
      "Epoch:  14\n",
      "24/36.0 loss: 0.7407861316204071 \n",
      "Epoch:  14\n",
      "25/36.0 loss: 0.7278930281217282 \n",
      "Epoch:  14\n",
      "26/36.0 loss: 0.7601755426989661 \n",
      "Epoch:  14\n",
      "27/36.0 loss: 0.772595998431955 \n",
      "Epoch:  14\n",
      "28/36.0 loss: 0.7669644777117104 \n",
      "Epoch:  14\n",
      "29/36.0 loss: 0.7851076891024907 \n",
      "Epoch:  14\n",
      "30/36.0 loss: 0.7880287141569199 \n",
      "Epoch:  14\n",
      "31/36.0 loss: 0.7940794927999377 \n",
      "Epoch:  14\n",
      "32/36.0 loss: 0.7855986401890264 \n",
      "Epoch:  14\n",
      "33/36.0 loss: 0.7861781900419909 \n",
      "Epoch:  14\n",
      "34/36.0 loss: 0.780002669777189 \n",
      "Epoch:  14\n",
      "35/36.0 loss: 0.7717748218112521 \n",
      "Epoch:  15\n",
      "0/36.0 loss: 1.0086342096328735 \n",
      "Epoch:  15\n",
      "1/36.0 loss: 1.0767467617988586 \n",
      "Epoch:  15\n",
      "2/36.0 loss: 0.8960605462392172 \n",
      "Epoch:  15\n",
      "3/36.0 loss: 0.8365624397993088 \n",
      "Epoch:  15\n",
      "4/36.0 loss: 0.7734121322631836 \n",
      "Epoch:  15\n",
      "5/36.0 loss: 0.7266551355520884 \n",
      "Epoch:  15\n",
      "6/36.0 loss: 0.7213175807680402 \n",
      "Epoch:  15\n",
      "7/36.0 loss: 0.6989018842577934 \n",
      "Epoch:  15\n",
      "8/36.0 loss: 0.6600980692439609 \n",
      "Epoch:  15\n",
      "9/36.0 loss: 0.6368264406919479 \n",
      "Epoch:  15\n",
      "10/36.0 loss: 0.6249772228977897 \n",
      "Epoch:  15\n",
      "11/36.0 loss: 0.6369815692305565 \n",
      "Epoch:  15\n",
      "12/36.0 loss: 0.6524146176301516 \n",
      "Epoch:  15\n",
      "13/36.0 loss: 0.6337915595088687 \n",
      "Epoch:  15\n",
      "14/36.0 loss: 0.6155257920424143 \n",
      "Epoch:  15\n",
      "15/36.0 loss: 0.6403132509440184 \n",
      "Epoch:  15\n",
      "16/36.0 loss: 0.632950963342891 \n",
      "Epoch:  15\n",
      "17/36.0 loss: 0.663037993841701 \n",
      "Epoch:  15\n",
      "18/36.0 loss: 0.6603267334009472 \n",
      "Epoch:  15\n",
      "19/36.0 loss: 0.6500262424349785 \n",
      "Epoch:  15\n",
      "20/36.0 loss: 0.6490302100068047 \n",
      "Epoch:  15\n",
      "21/36.0 loss: 0.660226200114597 \n",
      "Epoch:  15\n",
      "22/36.0 loss: 0.6608046513536702 \n",
      "Epoch:  15\n",
      "23/36.0 loss: 0.6617555804550648 \n",
      "Epoch:  15\n",
      "24/36.0 loss: 0.6879403007030487 \n",
      "Epoch:  15\n",
      "25/36.0 loss: 0.6760213008293738 \n",
      "Epoch:  15\n",
      "26/36.0 loss: 0.7101611737851743 \n",
      "Epoch:  15\n",
      "27/36.0 loss: 0.7238840120179313 \n",
      "Epoch:  15\n",
      "28/36.0 loss: 0.7189127700082187 \n",
      "Epoch:  15\n",
      "29/36.0 loss: 0.7374107758204143 \n",
      "Epoch:  15\n",
      "30/36.0 loss: 0.7409503959840343 \n",
      "Epoch:  15\n",
      "31/36.0 loss: 0.746829042211175 \n",
      "Epoch:  15\n",
      "32/36.0 loss: 0.7386473661119287 \n",
      "Epoch:  15\n",
      "33/36.0 loss: 0.7397657589000814 \n",
      "Epoch:  15\n",
      "34/36.0 loss: 0.7326968090874808 \n",
      "Epoch:  15\n",
      "35/36.0 loss: 0.7247550595137808 \n",
      "Epoch:  16\n",
      "0/36.0 loss: 0.9347830414772034 \n",
      "Epoch:  16\n",
      "1/36.0 loss: 1.0281560719013214 \n",
      "Epoch:  16\n",
      "2/36.0 loss: 0.85594509045283 \n",
      "Epoch:  16\n",
      "3/36.0 loss: 0.7882733345031738 \n",
      "Epoch:  16\n",
      "4/36.0 loss: 0.7280573606491089 \n",
      "Epoch:  16\n",
      "5/36.0 loss: 0.6794522752364477 \n",
      "Epoch:  16\n",
      "6/36.0 loss: 0.6832198202610016 \n",
      "Epoch:  16\n",
      "7/36.0 loss: 0.6622311808168888 \n",
      "Epoch:  16\n",
      "8/36.0 loss: 0.623577763636907 \n",
      "Epoch:  16\n",
      "9/36.0 loss: 0.5998277217149734 \n",
      "Epoch:  16\n",
      "10/36.0 loss: 0.5869573761116375 \n",
      "Epoch:  16\n",
      "11/36.0 loss: 0.602973518272241 \n",
      "Epoch:  16\n",
      "12/36.0 loss: 0.6162781554919022 \n",
      "Epoch:  16\n",
      "13/36.0 loss: 0.5973422548600605 \n",
      "Epoch:  16\n",
      "14/36.0 loss: 0.5792187770207723 \n",
      "Epoch:  16\n",
      "15/36.0 loss: 0.6022487357258797 \n",
      "Epoch:  16\n",
      "16/36.0 loss: 0.5942966499749351 \n",
      "Epoch:  16\n",
      "17/36.0 loss: 0.6217821223868264 \n",
      "Epoch:  16\n",
      "18/36.0 loss: 0.6198132461623141 \n",
      "Epoch:  16\n",
      "19/36.0 loss: 0.6097486585378646 \n",
      "Epoch:  16\n",
      "20/36.0 loss: 0.6090294491677057 \n",
      "Epoch:  16\n",
      "21/36.0 loss: 0.6191452985460107 \n",
      "Epoch:  16\n",
      "22/36.0 loss: 0.6197408567304197 \n",
      "Epoch:  16\n",
      "23/36.0 loss: 0.6210533355673155 \n",
      "Epoch:  16\n",
      "24/36.0 loss: 0.6489843440055847 \n",
      "Epoch:  16\n",
      "25/36.0 loss: 0.6378839680781732 \n",
      "Epoch:  16\n",
      "26/36.0 loss: 0.67441710057082 \n",
      "Epoch:  16\n",
      "27/36.0 loss: 0.6876642044101443 \n",
      "Epoch:  16\n",
      "28/36.0 loss: 0.6827079571526626 \n",
      "Epoch:  16\n",
      "29/36.0 loss: 0.7019099613030751 \n",
      "Epoch:  16\n",
      "30/36.0 loss: 0.7054959785553717 \n",
      "Epoch:  16\n",
      "31/36.0 loss: 0.7103883717209101 \n",
      "Epoch:  16\n",
      "32/36.0 loss: 0.7020499913981466 \n",
      "Epoch:  16\n",
      "33/36.0 loss: 0.7028200179338455 \n",
      "Epoch:  16\n",
      "34/36.0 loss: 0.6954613855906895 \n",
      "Epoch:  16\n",
      "35/36.0 loss: 0.6875389499796761 \n",
      "Epoch:  17\n",
      "0/36.0 loss: 0.9250963926315308 \n",
      "Epoch:  17\n",
      "1/36.0 loss: 0.9722128510475159 \n",
      "Epoch:  17\n",
      "2/36.0 loss: 0.8014305531978607 \n",
      "Epoch:  17\n",
      "3/36.0 loss: 0.7375392988324165 \n",
      "Epoch:  17\n",
      "4/36.0 loss: 0.6788853287696839 \n",
      "Epoch:  17\n",
      "5/36.0 loss: 0.6313163240750631 \n",
      "Epoch:  17\n",
      "6/36.0 loss: 0.6359958478382656 \n",
      "Epoch:  17\n",
      "7/36.0 loss: 0.6146955564618111 \n",
      "Epoch:  17\n",
      "8/36.0 loss: 0.5773311058680216 \n",
      "Epoch:  17\n",
      "9/36.0 loss: 0.553913339972496 \n",
      "Epoch:  17\n",
      "10/36.0 loss: 0.541391982273622 \n",
      "Epoch:  17\n",
      "11/36.0 loss: 0.5636258150140444 \n",
      "Epoch:  17\n",
      "12/36.0 loss: 0.5747315264665164 \n",
      "Epoch:  17\n",
      "13/36.0 loss: 0.5552995460374015 \n",
      "Epoch:  17\n",
      "14/36.0 loss: 0.5380450248718261 \n",
      "Epoch:  17\n",
      "15/36.0 loss: 0.5595395714044571 \n",
      "Epoch:  17\n",
      "16/36.0 loss: 0.5514258759863236 \n",
      "Epoch:  17\n",
      "17/36.0 loss: 0.5793211642238829 \n",
      "Epoch:  17\n",
      "18/36.0 loss: 0.5787453918080581 \n",
      "Epoch:  17\n",
      "19/36.0 loss: 0.568580923974514 \n",
      "Epoch:  17\n",
      "20/36.0 loss: 0.5683595807779402 \n",
      "Epoch:  17\n",
      "21/36.0 loss: 0.5779799832539125 \n",
      "Epoch:  17\n",
      "22/36.0 loss: 0.5784028703751771 \n",
      "Epoch:  17\n",
      "23/36.0 loss: 0.5805725020666918 \n",
      "Epoch:  17\n",
      "24/36.0 loss: 0.6124331438541413 \n",
      "Epoch:  17\n",
      "25/36.0 loss: 0.6009300935726899 \n",
      "Epoch:  17\n",
      "26/36.0 loss: 0.6430620959511509 \n",
      "Epoch:  17\n",
      "27/36.0 loss: 0.6571878099015781 \n",
      "Epoch:  17\n",
      "28/36.0 loss: 0.6516014594456245 \n",
      "Epoch:  17\n",
      "29/36.0 loss: 0.6735896954933802 \n",
      "Epoch:  17\n",
      "30/36.0 loss: 0.6776539558364499 \n",
      "Epoch:  17\n",
      "31/36.0 loss: 0.6818156084045768 \n",
      "Epoch:  17\n",
      "32/36.0 loss: 0.6729874394156716 \n",
      "Epoch:  17\n",
      "33/36.0 loss: 0.673159823698156 \n",
      "Epoch:  17\n",
      "34/36.0 loss: 0.665232104914529 \n",
      "Epoch:  17\n",
      "35/36.0 loss: 0.657034210032887 \n",
      "Epoch:  18\n",
      "0/36.0 loss: 0.8331658244132996 \n",
      "Epoch:  18\n",
      "1/36.0 loss: 0.8951752185821533 \n",
      "Epoch:  18\n",
      "2/36.0 loss: 0.7404075960318247 \n",
      "Epoch:  18\n",
      "3/36.0 loss: 0.6784263551235199 \n",
      "Epoch:  18\n",
      "4/36.0 loss: 0.6217941880226135 \n",
      "Epoch:  18\n",
      "5/36.0 loss: 0.5767594277858734 \n",
      "Epoch:  18\n",
      "6/36.0 loss: 0.5908252937453133 \n",
      "Epoch:  18\n",
      "7/36.0 loss: 0.5698947086930275 \n",
      "Epoch:  18\n",
      "8/36.0 loss: 0.5351276728841994 \n",
      "Epoch:  18\n",
      "9/36.0 loss: 0.5132954061031342 \n",
      "Epoch:  18\n",
      "10/36.0 loss: 0.5015947981314226 \n",
      "Epoch:  18\n",
      "11/36.0 loss: 0.5250220845143 \n",
      "Epoch:  18\n",
      "12/36.0 loss: 0.5364014414640573 \n",
      "Epoch:  18\n",
      "13/36.0 loss: 0.517996317573956 \n",
      "Epoch:  18\n",
      "14/36.0 loss: 0.5016883194446564 \n",
      "Epoch:  18\n",
      "15/36.0 loss: 0.5218739416450262 \n",
      "Epoch:  18\n",
      "16/36.0 loss: 0.5130900337415583 \n",
      "Epoch:  18\n",
      "17/36.0 loss: 0.5383281624979444 \n",
      "Epoch:  18\n",
      "18/36.0 loss: 0.5389563990266699 \n",
      "Epoch:  18\n",
      "19/36.0 loss: 0.5285033896565438 \n",
      "Epoch:  18\n",
      "20/36.0 loss: 0.5291160387652261 \n",
      "Epoch:  18\n",
      "21/36.0 loss: 0.5378310504284772 \n",
      "Epoch:  18\n",
      "22/36.0 loss: 0.5383152560047482 \n",
      "Epoch:  18\n",
      "23/36.0 loss: 0.5402343533933163 \n",
      "Epoch:  18\n",
      "24/36.0 loss: 0.5712069141864776 \n",
      "Epoch:  18\n",
      "25/36.0 loss: 0.5609047630658517 \n",
      "Epoch:  18\n",
      "26/36.0 loss: 0.6020060987384231 \n",
      "Epoch:  18\n",
      "27/36.0 loss: 0.6156088592750686 \n",
      "Epoch:  18\n",
      "28/36.0 loss: 0.609825647082822 \n",
      "Epoch:  18\n",
      "29/36.0 loss: 0.6305032402276993 \n",
      "Epoch:  18\n",
      "30/36.0 loss: 0.6351613373525681 \n",
      "Epoch:  18\n",
      "31/36.0 loss: 0.6391825275495648 \n",
      "Epoch:  18\n",
      "32/36.0 loss: 0.6304182915976553 \n",
      "Epoch:  18\n",
      "33/36.0 loss: 0.6303172760150012 \n",
      "Epoch:  18\n",
      "34/36.0 loss: 0.6224567004612513 \n",
      "Epoch:  18\n",
      "35/36.0 loss: 0.6142526194453239 \n",
      "Epoch:  19\n",
      "0/36.0 loss: 0.824536919593811 \n",
      "Epoch:  19\n",
      "1/36.0 loss: 0.8533694744110107 \n",
      "Epoch:  19\n",
      "2/36.0 loss: 0.6985960006713867 \n",
      "Epoch:  19\n",
      "3/36.0 loss: 0.6357253566384315 \n",
      "Epoch:  19\n",
      "4/36.0 loss: 0.5780764162540436 \n",
      "Epoch:  19\n",
      "5/36.0 loss: 0.5341575394074122 \n",
      "Epoch:  19\n",
      "6/36.0 loss: 0.5546503109591348 \n",
      "Epoch:  19\n",
      "7/36.0 loss: 0.5330970920622349 \n",
      "Epoch:  19\n",
      "8/36.0 loss: 0.49949441684616935 \n",
      "Epoch:  19\n",
      "9/36.0 loss: 0.4784046471118927 \n",
      "Epoch:  19\n",
      "10/36.0 loss: 0.46648870273069903 \n",
      "Epoch:  19\n",
      "11/36.0 loss: 0.4937315285205841 \n",
      "Epoch:  19\n",
      "12/36.0 loss: 0.5043477874535781 \n",
      "Epoch:  19\n",
      "13/36.0 loss: 0.4862610548734665 \n",
      "Epoch:  19\n",
      "14/36.0 loss: 0.47105928460756935 \n",
      "Epoch:  19\n",
      "15/36.0 loss: 0.4891938138753176 \n",
      "Epoch:  19\n",
      "16/36.0 loss: 0.47942984454772053 \n",
      "Epoch:  19\n",
      "17/36.0 loss: 0.5022350913948483 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  19\n",
      "\r",
      "18/36.0 loss: 0.5049485093668887 \n",
      "Epoch:  19\n",
      "\r",
      "19/36.0 loss: 0.4941228464245796 \n",
      "Epoch:  19\n",
      "\r",
      "20/36.0 loss: 0.49614458566620234 \n",
      "Epoch:  19\n",
      "\r",
      "21/36.0 loss: 0.5030900686979294 \n",
      "Epoch:  19\n",
      "\r",
      "22/36.0 loss: 0.5031522292157878 \n",
      "Epoch:  19\n",
      "\r",
      "23/36.0 loss: 0.5054991828898588 \n",
      "Epoch:  19\n",
      "\r",
      "24/36.0 loss: 0.5385178411006928 \n",
      "Epoch:  19\n",
      "\r",
      "25/36.0 loss: 0.5286931475767722 \n",
      "Epoch:  19\n",
      "\r",
      "26/36.0 loss: 0.5730353891849518 \n",
      "Epoch:  19\n",
      "\r",
      "27/36.0 loss: 0.5856386667915753 \n",
      "Epoch:  19\n",
      "\r",
      "28/36.0 loss: 0.5790708095862948 \n",
      "Epoch:  19\n",
      "\r",
      "29/36.0 loss: 0.6019508709510167 \n",
      "Epoch:  19\n",
      "\r",
      "30/36.0 loss: 0.6065135511659807 \n",
      "Epoch:  19\n",
      "\r",
      "31/36.0 loss: 0.6098415786400437 \n",
      "Epoch:  19\n",
      "\r",
      "32/36.0 loss: 0.6006988061196876 \n",
      "Epoch:  19\n",
      "\r",
      "33/36.0 loss: 0.5994484275579453 \n",
      "Epoch:  19\n",
      "\r",
      "34/36.0 loss: 0.5919959000178746 \n",
      "Epoch:  19\n",
      "\r",
      "35/36.0 loss: 0.5834062952134345 \n",
      "Epoch:  20\n",
      "\r",
      "0/36.0 loss: 0.7926843166351318 \n",
      "Epoch:  20\n",
      "\r",
      "1/36.0 loss: 0.7922584414482117 \n",
      "Epoch:  20\n",
      "\r",
      "2/36.0 loss: 0.6467366913954417 \n",
      "Epoch:  20\n",
      "\r",
      "3/36.0 loss: 0.5845895260572433 \n",
      "Epoch:  20\n",
      "\r",
      "4/36.0 loss: 0.5286665678024292 \n",
      "Epoch:  20\n",
      "\r",
      "5/36.0 loss: 0.48567093908786774 \n",
      "Epoch:  20\n",
      "\r",
      "6/36.0 loss: 0.5203057995864323 \n",
      "Epoch:  20\n",
      "\r",
      "7/36.0 loss: 0.4983299598097801 \n",
      "Epoch:  20\n",
      "\r",
      "8/36.0 loss: 0.46747032966878677 \n",
      "Epoch:  20\n",
      "\r",
      "9/36.0 loss: 0.4483091667294502 \n",
      "Epoch:  20\n",
      "\r",
      "10/36.0 loss: 0.43617124584588135 \n",
      "Epoch:  20\n",
      "\r",
      "11/36.0 loss: 0.4675118488570054 \n",
      "Epoch:  20\n",
      "\r",
      "12/36.0 loss: 0.4774066358804703 \n",
      "Epoch:  20\n",
      "\r",
      "13/36.0 loss: 0.46024306437798906 \n",
      "Epoch:  20\n",
      "\r",
      "14/36.0 loss: 0.44604890048503876 \n",
      "Epoch:  20\n",
      "\r",
      "15/36.0 loss: 0.4617190221324563 \n",
      "Epoch:  20\n",
      "\r",
      "16/36.0 loss: 0.4509023419197868 \n",
      "Epoch:  20\n",
      "\r",
      "17/36.0 loss: 0.47093084040615296 \n",
      "Epoch:  20\n",
      "\r",
      "18/36.0 loss: 0.475694203847333 \n",
      "Epoch:  20\n",
      "\r",
      "19/36.0 loss: 0.4643294833600521 \n",
      "Epoch:  20\n",
      "\r",
      "20/36.0 loss: 0.4674548102276666 \n",
      "Epoch:  20\n",
      "\r",
      "21/36.0 loss: 0.47237843478267844 \n",
      "Epoch:  20\n",
      "\r",
      "22/36.0 loss: 0.47150631378526275 \n",
      "Epoch:  20\n",
      "\r",
      "23/36.0 loss: 0.4745600800961256 \n",
      "Epoch:  20\n",
      "\r",
      "24/36.0 loss: 0.5109408313035965 \n",
      "Epoch:  20\n",
      "\r",
      "25/36.0 loss: 0.500571102477037 \n",
      "Epoch:  20\n",
      "\r",
      "26/36.0 loss: 0.550382771425777 \n",
      "Epoch:  20\n",
      "\r",
      "27/36.0 loss: 0.5634626283177308 \n",
      "Epoch:  20\n",
      "\r",
      "28/36.0 loss: 0.5557404515044443 \n",
      "Epoch:  20\n",
      "\r",
      "29/36.0 loss: 0.580561205248038 \n",
      "Epoch:  20\n",
      "\r",
      "30/36.0 loss: 0.5848493888493507 \n",
      "Epoch:  20\n",
      "\r",
      "31/36.0 loss: 0.5868619312532246 \n",
      "Epoch:  20\n",
      "\r",
      "32/36.0 loss: 0.5771872794086282 \n",
      "Epoch:  20\n",
      "\r",
      "33/36.0 loss: 0.5748876258730888 \n",
      "Epoch:  20\n",
      "\r",
      "34/36.0 loss: 0.567508265376091 \n",
      "Epoch:  20\n",
      "\r",
      "35/36.0 loss: 0.5585516062047746 \n"
     ]
    }
   ],
   "source": [
    "cum_loss = train_model2(net, epochs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[46.63822090625763,\n",
       " 43.66939979791641,\n",
       " 41.07068222761154,\n",
       " 39.68642622232437,\n",
       " 38.976588785648346,\n",
       " 38.47554665803909,\n",
       " 38.01677441596985,\n",
       " 37.535325825214386,\n",
       " 36.99564707279205,\n",
       " 36.36943459510803,\n",
       " 35.62875932455063,\n",
       " 34.74488544464111,\n",
       " 33.69030314683914,\n",
       " 32.45323324203491,\n",
       " 31.01966142654419,\n",
       " 29.393729209899902,\n",
       " 27.54505866765976,\n",
       " 25.782746881246567,\n",
       " 24.037420600652695,\n",
       " 22.429779946804047]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cum_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a212ea208>]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(cum_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [],
   "source": [
    "#refactoring again to track validation loss\n",
    "\n",
    "def train_model3(model, lr = 1e-3, epochs = 10, loss_func = nn.CrossEntropyLoss(), batch_size = 4):\n",
    "    optimizer = Adam(model.parameters(), lr = lr)\n",
    "    running_train_loss = []\n",
    "    running_valid_loss = []\n",
    "    for epoch_num in range(epochs):\n",
    "        start_time = time.time()\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for step_num, batch_data in enumerate(trainloader):\n",
    "        \n",
    "            cont_var, subj_notes, medhx, cat_var, labels = tuple(t.to(device) for t in batch_data)\n",
    "        \n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "            logits = model(cont_var, subj_notes, medhx, cat_var)\n",
    "        \n",
    "            batch_loss = loss_func(logits, labels)\n",
    "        \n",
    "            train_loss += batch_loss.item()\n",
    "        \n",
    "            batch_loss.backward()\n",
    "        \n",
    "\n",
    "            clip_grad_norm_(parameters=model.parameters(), max_norm=1.0)\n",
    "        \n",
    "            optimizer.step()\n",
    "        \n",
    "        #check against validation set\n",
    "        model.eval()\n",
    "        valid_loss = 0\n",
    "        for batch_data in validloader:\n",
    "            \n",
    "            cont_var, subj_notes, medhx, cat_var, labels = tuple(t.to(device) for t in batch_data)\n",
    "            \n",
    "            logits = model(cont_var, subj_notes, medhx, cat_var)\n",
    "        \n",
    "            batch_loss = loss_func(logits, labels)\n",
    "        \n",
    "            valid_loss += batch_loss.item()\n",
    "            \n",
    "        end_time = time.time()\n",
    "        print('Epoch {}:'.format(epoch_num + 1),' {0:.3f} sec'.format(end_time - start_time))\n",
    "        #print(\"\\r\" + \"{0}/{1} loss: {2} \".format(step_num, len(train_data) / batch_size, train_loss / (step_num + 1)))\n",
    "        print ('Training loss = {0:.4f}'.format(train_loss/len(trainloader)))\n",
    "        print ('Validation loss = {0:.4f}'.format(valid_loss/len(validloader)))\n",
    "        print ()\n",
    "        \n",
    "        running_train_loss.append(train_loss/len(trainloader))\n",
    "        running_valid_loss.append(valid_loss/len(validloader))\n",
    "        \n",
    "\n",
    "    return running_train_loss, running_valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  0.107 sec\n",
      "Training loss = 1.3719\n",
      "Validation loss = 1.3315\n",
      "\n",
      "Epoch 2:  0.066 sec\n",
      "Training loss = 1.3510\n",
      "Validation loss = 1.3285\n",
      "\n",
      "Epoch 3:  0.062 sec\n",
      "Training loss = 1.3341\n",
      "Validation loss = 1.3213\n",
      "\n",
      "Epoch 4:  0.083 sec\n",
      "Training loss = 1.3198\n",
      "Validation loss = 1.3147\n",
      "\n",
      "Epoch 5:  0.100 sec\n",
      "Training loss = 1.3061\n",
      "Validation loss = 1.3076\n",
      "\n",
      "Epoch 6:  0.086 sec\n",
      "Training loss = 1.2935\n",
      "Validation loss = 1.3032\n",
      "\n",
      "Epoch 7:  0.077 sec\n",
      "Training loss = 1.2821\n",
      "Validation loss = 1.2994\n",
      "\n",
      "Epoch 8:  0.065 sec\n",
      "Training loss = 1.2709\n",
      "Validation loss = 1.2939\n",
      "\n",
      "Epoch 9:  0.074 sec\n",
      "Training loss = 1.2605\n",
      "Validation loss = 1.2914\n",
      "\n",
      "Epoch 10:  0.065 sec\n",
      "Training loss = 1.2503\n",
      "Validation loss = 1.2873\n",
      "\n",
      "Epoch 11:  0.084 sec\n",
      "Training loss = 1.2408\n",
      "Validation loss = 1.2871\n",
      "\n",
      "Epoch 12:  0.074 sec\n",
      "Training loss = 1.2318\n",
      "Validation loss = 1.2866\n",
      "\n",
      "Epoch 13:  0.096 sec\n",
      "Training loss = 1.2231\n",
      "Validation loss = 1.2836\n",
      "\n",
      "Epoch 14:  0.087 sec\n",
      "Training loss = 1.2145\n",
      "Validation loss = 1.2794\n",
      "\n",
      "Epoch 15:  0.074 sec\n",
      "Training loss = 1.2065\n",
      "Validation loss = 1.2776\n",
      "\n",
      "Epoch 16:  0.070 sec\n",
      "Training loss = 1.1988\n",
      "Validation loss = 1.2759\n",
      "\n",
      "Epoch 17:  0.074 sec\n",
      "Training loss = 1.1911\n",
      "Validation loss = 1.2719\n",
      "\n",
      "Epoch 18:  0.082 sec\n",
      "Training loss = 1.1839\n",
      "Validation loss = 1.2698\n",
      "\n",
      "Epoch 19:  0.148 sec\n",
      "Training loss = 1.1772\n",
      "Validation loss = 1.2682\n",
      "\n",
      "Epoch 20:  0.111 sec\n",
      "Training loss = 1.1702\n",
      "Validation loss = 1.2622\n",
      "\n",
      "Epoch 21:  0.135 sec\n",
      "Training loss = 1.1641\n",
      "Validation loss = 1.2637\n",
      "\n",
      "Epoch 22:  0.137 sec\n",
      "Training loss = 1.1583\n",
      "Validation loss = 1.2615\n",
      "\n",
      "Epoch 23:  0.144 sec\n",
      "Training loss = 1.1519\n",
      "Validation loss = 1.2601\n",
      "\n",
      "Epoch 24:  0.103 sec\n",
      "Training loss = 1.1462\n",
      "Validation loss = 1.2585\n",
      "\n",
      "Epoch 25:  0.114 sec\n",
      "Training loss = 1.1404\n",
      "Validation loss = 1.2546\n",
      "\n"
     ]
    }
   ],
   "source": [
    "net = Net2(emb_szs)\n",
    "tloss, vloss = train_model3(net, lr = 1e-4,epochs = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(tloss,'b', label = 'train')\n",
    "plt.plot(vloss,'g', label = 'valid')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### next step is to complete the pipeline from pandas dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### but first I have to make the dataframe I want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/jjaskolkambp/Desktop/machine learning/my_projects/ed-triage'"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_path = '/Users/jjaskolkambp/Desktop/machine learning/my_projects/data/ed triage project/egh'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(data_path + '/pmhx_embeds.csv', header = None, index_col = 0)\n",
    "df2 = pd.read_csv(data_path + '/subjnote_embeds.csv', header = None, index_col = 0)\n",
    "balanced_data = pd.read_csv(data_path + '/balanced_4cls_nlp_data.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "del df1.index.name\n",
    "del df2.index.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>[-5.62175699e-02 -1.55288264e-01 -3.55031192e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>[-2.32482120e-01 -3.98706704e-01  5.75849652e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>[ 7.09933490e-02 -1.90701023e-01 -3.40518981e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>[-6.41224608e-02  1.80907622e-02 -2.60267198e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>[-3.08350593e-01 -8.54802653e-02  3.15538704e-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     1\n",
       "511  [-5.62175699e-02 -1.55288264e-01 -3.55031192e-...\n",
       "754  [-2.32482120e-01 -3.98706704e-01  5.75849652e-...\n",
       "755  [ 7.09933490e-02 -1.90701023e-01 -3.40518981e-...\n",
       "757  [-6.41224608e-02  1.80907622e-02 -2.60267198e-...\n",
       "758  [-3.08350593e-01 -8.54802653e-02  3.15538704e-..."
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df1.columns = ['pmhx_embeds']\n",
    "\n",
    "df2.columns = ['subjnotes_embeds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df3 = pd.concat([df1,df2 ], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pmhx_embeds</th>\n",
       "      <th>subjnotes_embeds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>[-5.62175699e-02 -1.55288264e-01 -3.55031192e-...</td>\n",
       "      <td>[-2.55204886e-01  6.01891279e-02  2.71235794e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>[-2.32482120e-01 -3.98706704e-01  5.75849652e-...</td>\n",
       "      <td>[ 2.34645531e-01 -1.87844783e-01  4.77293253e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>[ 7.09933490e-02 -1.90701023e-01 -3.40518981e-...</td>\n",
       "      <td>[-2.65869528e-01 -1.80039495e-01  3.75602454e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>[-6.41224608e-02  1.80907622e-02 -2.60267198e-...</td>\n",
       "      <td>[-2.00648651e-01 -2.00332478e-01  3.26978832e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>[-3.08350593e-01 -8.54802653e-02  3.15538704e-...</td>\n",
       "      <td>[-9.09422189e-02 -1.58347234e-01  4.89432931e-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           pmhx_embeds  \\\n",
       "511  [-5.62175699e-02 -1.55288264e-01 -3.55031192e-...   \n",
       "754  [-2.32482120e-01 -3.98706704e-01  5.75849652e-...   \n",
       "755  [ 7.09933490e-02 -1.90701023e-01 -3.40518981e-...   \n",
       "757  [-6.41224608e-02  1.80907622e-02 -2.60267198e-...   \n",
       "758  [-3.08350593e-01 -8.54802653e-02  3.15538704e-...   \n",
       "\n",
       "                                      subjnotes_embeds  \n",
       "511  [-2.55204886e-01  6.01891279e-02  2.71235794e-...  \n",
       "754  [ 2.34645531e-01 -1.87844783e-01  4.77293253e-...  \n",
       "755  [-2.65869528e-01 -1.80039495e-01  3.75602454e-...  \n",
       "757  [-2.00648651e-01 -2.00332478e-01  3.26978832e-...  \n",
       "758  [-9.09422189e-02 -1.58347234e-01  4.89432931e-...  "
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "overlap = [x for x in  df3.index if x in balanced_data.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(overlap) == sorted(list(balanced_data.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ltd_data = df3.loc[overlap]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ltd_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "balanced = pd.concat([balanced_data, ltd_data], axis = 1)\n",
    "\n",
    "#tweaking so there's a change to put on github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>ChartNumber</th>\n",
       "      <th>EncounterNumber</th>\n",
       "      <th>TriageLevel</th>\n",
       "      <th>AgeNumber</th>\n",
       "      <th>AgeInYrs</th>\n",
       "      <th>GenderDesc</th>\n",
       "      <th>Triage Date &amp; Time</th>\n",
       "      <th>Reg Date &amp; Time</th>\n",
       "      <th>PIA Date &amp; Time</th>\n",
       "      <th>...</th>\n",
       "      <th>target2</th>\n",
       "      <th>discharge</th>\n",
       "      <th>target3</th>\n",
       "      <th>dispo</th>\n",
       "      <th>target4</th>\n",
       "      <th>ICUvsother</th>\n",
       "      <th>target5</th>\n",
       "      <th>pmhx</th>\n",
       "      <th>pmhx_embeds</th>\n",
       "      <th>subjnotes_embeds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1184</th>\n",
       "      <td>1185</td>\n",
       "      <td>E8443276</td>\n",
       "      <td>EE001185/18</td>\n",
       "      <td>2.0</td>\n",
       "      <td>73</td>\n",
       "      <td>73.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>2018-04-06 10:16:00</td>\n",
       "      <td>2018-04-06 10:20:00</td>\n",
       "      <td>2018-04-06 10:17:00</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>admit</td>\n",
       "      <td>0</td>\n",
       "      <td>sadmit</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>bowel obstruction d/t bowel adhesions, htn, afib</td>\n",
       "      <td>[-1.18588388e-01 -3.62613685e-02  1.71774179e-...</td>\n",
       "      <td>[-2.39613533e-01  4.64705452e-02  4.14689839e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1620</th>\n",
       "      <td>1621</td>\n",
       "      <td>E3111507</td>\n",
       "      <td>EE001622/18</td>\n",
       "      <td>5.0</td>\n",
       "      <td>82</td>\n",
       "      <td>82.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>2018-04-08 11:17:00</td>\n",
       "      <td>2018-04-08 11:21:00</td>\n",
       "      <td>2018-04-08 11:28:00</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>admit</td>\n",
       "      <td>0</td>\n",
       "      <td>sadmit</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>diverticulitis, high bp, high cholesterol, thy...</td>\n",
       "      <td>[-1.94503769e-01 -8.38923976e-02  5.67541644e-...</td>\n",
       "      <td>[-1.24572255e-01 -2.15024259e-02  4.72823471e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1713</th>\n",
       "      <td>1714</td>\n",
       "      <td>E8216415</td>\n",
       "      <td>EE001716/18</td>\n",
       "      <td>2.0</td>\n",
       "      <td>49</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>2018-04-08 18:47:00</td>\n",
       "      <td>2018-04-08 18:50:00</td>\n",
       "      <td>2018-04-08 18:50:00</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>admit</td>\n",
       "      <td>0</td>\n",
       "      <td>madmit</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>liver and kidney failure</td>\n",
       "      <td>[-6.44557178e-02  2.12498493e-02 -4.99889851e-...</td>\n",
       "      <td>[-6.32119700e-02 -1.49392709e-01  4.46838409e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1836</th>\n",
       "      <td>1837</td>\n",
       "      <td>E8152804</td>\n",
       "      <td>EE001838/18</td>\n",
       "      <td>2.0</td>\n",
       "      <td>57</td>\n",
       "      <td>57.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>2018-04-09 10:59:00</td>\n",
       "      <td>2018-04-09 11:02:00</td>\n",
       "      <td>2018-04-09 11:10:00</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>admit</td>\n",
       "      <td>0</td>\n",
       "      <td>sadmit</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>htn, diabetic, thyroid, rt total nephrectomy, ...</td>\n",
       "      <td>[-1.45752514e-02 -3.72009605e-01  2.15191156e-...</td>\n",
       "      <td>[-1.14206485e-01 -3.34909745e-02  3.48307520e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1837</th>\n",
       "      <td>1838</td>\n",
       "      <td>E8181432</td>\n",
       "      <td>EE001839/18</td>\n",
       "      <td>2.0</td>\n",
       "      <td>75</td>\n",
       "      <td>75.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>2018-04-09 11:11:00</td>\n",
       "      <td>2018-04-09 11:15:00</td>\n",
       "      <td>2018-04-09 11:16:00</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>admit</td>\n",
       "      <td>0</td>\n",
       "      <td>sadmit</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>no significant medical history</td>\n",
       "      <td>[-6.41224608e-02  1.80907622e-02 -2.60267198e-...</td>\n",
       "      <td>[-1.96476385e-01 -1.18435726e-01  5.01800537e-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID ChartNumber EncounterNumber  TriageLevel  AgeNumber  AgeInYrs  \\\n",
       "1184  1185    E8443276     EE001185/18          2.0         73      73.0   \n",
       "1620  1621    E3111507     EE001622/18          5.0         82      82.0   \n",
       "1713  1714    E8216415     EE001716/18          2.0         49      49.0   \n",
       "1836  1837    E8152804     EE001838/18          2.0         57      57.0   \n",
       "1837  1838    E8181432     EE001839/18          2.0         75      75.0   \n",
       "\n",
       "     GenderDesc   Triage Date & Time      Reg Date & Time  \\\n",
       "1184       Male  2018-04-06 10:16:00  2018-04-06 10:20:00   \n",
       "1620     Female  2018-04-08 11:17:00  2018-04-08 11:21:00   \n",
       "1713       Male  2018-04-08 18:47:00  2018-04-08 18:50:00   \n",
       "1836       Male  2018-04-09 10:59:00  2018-04-09 11:02:00   \n",
       "1837       Male  2018-04-09 11:11:00  2018-04-09 11:15:00   \n",
       "\n",
       "          PIA Date & Time                        ...                          \\\n",
       "1184  2018-04-06 10:17:00                        ...                           \n",
       "1620  2018-04-08 11:28:00                        ...                           \n",
       "1713  2018-04-08 18:50:00                        ...                           \n",
       "1836  2018-04-09 11:10:00                        ...                           \n",
       "1837  2018-04-09 11:16:00                        ...                           \n",
       "\n",
       "     target2  discharge target3   dispo  target4 ICUvsother target5  \\\n",
       "1184       3      admit       0  sadmit      2.0        NaN       0   \n",
       "1620       3      admit       0  sadmit      2.0        NaN       0   \n",
       "1713       2      admit       0  madmit      1.0        NaN       0   \n",
       "1836       3      admit       0  sadmit      2.0        NaN       0   \n",
       "1837       3      admit       0  sadmit      2.0        NaN       0   \n",
       "\n",
       "                                                   pmhx  \\\n",
       "1184   bowel obstruction d/t bowel adhesions, htn, afib   \n",
       "1620  diverticulitis, high bp, high cholesterol, thy...   \n",
       "1713                           liver and kidney failure   \n",
       "1836  htn, diabetic, thyroid, rt total nephrectomy, ...   \n",
       "1837                     no significant medical history   \n",
       "\n",
       "                                            pmhx_embeds  \\\n",
       "1184  [-1.18588388e-01 -3.62613685e-02  1.71774179e-...   \n",
       "1620  [-1.94503769e-01 -8.38923976e-02  5.67541644e-...   \n",
       "1713  [-6.44557178e-02  2.12498493e-02 -4.99889851e-...   \n",
       "1836  [-1.45752514e-02 -3.72009605e-01  2.15191156e-...   \n",
       "1837  [-6.41224608e-02  1.80907622e-02 -2.60267198e-...   \n",
       "\n",
       "                                       subjnotes_embeds  \n",
       "1184  [-2.39613533e-01  4.64705452e-02  4.14689839e-...  \n",
       "1620  [-1.24572255e-01 -2.15024259e-02  4.72823471e-...  \n",
       "1713  [-6.32119700e-02 -1.49392709e-01  4.46838409e-...  \n",
       "1836  [-1.14206485e-01 -3.34909745e-02  3.48307520e-...  \n",
       "1837  [-1.96476385e-01 -1.18435726e-01  5.01800537e-...  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 48)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "balanced.to_csv(data_path +'/total_balanced_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### now that I have the \"balanced\" dataframe, I can build the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 48)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 859,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'ChartNumber', 'EncounterNumber', 'TriageLevel', 'AgeNumber',\n",
       "       'AgeInYrs', 'GenderDesc', 'Triage Date & Time', 'Reg Date & Time',\n",
       "       'PIA Date & Time', 'Disposition Date & Time', 'DischargeDisposition',\n",
       "       'DischargeDispositionDesc', 'Left ED Date & Time',\n",
       "       'PresentingComplaint', 'PresentingComplaintDesc', 'MainDiagnosisCode',\n",
       "       'MainDiagnosisCodeDesc', 'AdmitLocation', 'PatientService',\n",
       "       'SubjectiveNotes', 'InfectionControlScreening', 'MedicalHistory',\n",
       "       'BloodPressure_LastEDReading', 'O2Saturation_LastEDReading',\n",
       "       'Pulse_LastEDReading', 'Temperature_LastEDReading', 'o2sat', 'pulse',\n",
       "       'temp', 'CleanSubjectiveNotes', 'BP', 'systolic', 'diastolic', 'Gender',\n",
       "       'outcome', 'target', 'service', 'target2', 'discharge', 'target3',\n",
       "       'dispo', 'target4', 'ICUvsother', 'target5', 'pmhx', 'pmhx_embeds',\n",
       "       'subjnotes_embeds', 'AgeInYrs_norm', 'o2sat_norm', 'temp_norm',\n",
       "       'pulse_norm', 'systolic_norm', 'diastolic_norm'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 859,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turning the embedding columns into arrays along the lines of what I created bedore\n",
    "\n",
    "subj = np.array([s[1:-1].split() for s in list(balanced.subjnotes_embeds)]).astype(np.float32)\n",
    "medhx = np.array([s[1:-1].split() for s in list(balanced.pmhx_embeds)]).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dtype('float32'), dtype('float32'))"
      ]
     },
     "execution_count": 614,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subj.dtype, medhx.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [],
   "source": [
    "#each of these will start as a list of relevant columns and be handled differently\n",
    "cont_vars = ['AgeInYrs', 'o2sat', 'temp', 'pulse', 'systolic', 'diastolic']\n",
    "cat_vars = ['TriageLevel', 'Gender', 'PresentingComplaint']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making the labels\n",
    "labels = balanced.target2.values - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(df, columns):\n",
    "        print (columns)\n",
    "        \"Compute the means and stds of `self.cont_names` columns to normalize them.\"\n",
    "        new_cols = []\n",
    "        for n in columns:\n",
    "            df[n + '_norm'] = (df[n]-df[n].mean()) / (1e-7 + df[n].std())\n",
    "            new_cols.append(n+ '_norm')\n",
    "            \n",
    "            \n",
    "        for n in new_cols:\n",
    "            if pd.isnull(df[n]).sum():\n",
    "                filler = df[n].median()\n",
    "                df[n] = df[n].fillna(filler)\n",
    "        return new_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AgeInYrs', 'o2sat', 'temp', 'pulse', 'systolic', 'diastolic']\n"
     ]
    }
   ],
   "source": [
    "new_cols = normalize(balanced, cont_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>ChartNumber</th>\n",
       "      <th>EncounterNumber</th>\n",
       "      <th>TriageLevel</th>\n",
       "      <th>AgeNumber</th>\n",
       "      <th>AgeInYrs</th>\n",
       "      <th>GenderDesc</th>\n",
       "      <th>Triage Date &amp; Time</th>\n",
       "      <th>Reg Date &amp; Time</th>\n",
       "      <th>PIA Date &amp; Time</th>\n",
       "      <th>...</th>\n",
       "      <th>target5</th>\n",
       "      <th>pmhx</th>\n",
       "      <th>pmhx_embeds</th>\n",
       "      <th>subjnotes_embeds</th>\n",
       "      <th>AgeInYrs_norm</th>\n",
       "      <th>o2sat_norm</th>\n",
       "      <th>temp_norm</th>\n",
       "      <th>pulse_norm</th>\n",
       "      <th>systolic_norm</th>\n",
       "      <th>diastolic_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1184</th>\n",
       "      <td>1185</td>\n",
       "      <td>E8443276</td>\n",
       "      <td>EE001185/18</td>\n",
       "      <td>2.0</td>\n",
       "      <td>73</td>\n",
       "      <td>73.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>2018-04-06 10:16:00</td>\n",
       "      <td>2018-04-06 10:20:00</td>\n",
       "      <td>2018-04-06 10:17:00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>bowel obstruction d/t bowel adhesions, htn, afib</td>\n",
       "      <td>[-1.18588388e-01 -3.62613685e-02  1.71774179e-...</td>\n",
       "      <td>[-2.39613533e-01  4.64705452e-02  4.14689839e-...</td>\n",
       "      <td>0.797240</td>\n",
       "      <td>0.301261</td>\n",
       "      <td>-0.180775</td>\n",
       "      <td>-0.841688</td>\n",
       "      <td>0.573110</td>\n",
       "      <td>0.286222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1620</th>\n",
       "      <td>1621</td>\n",
       "      <td>E3111507</td>\n",
       "      <td>EE001622/18</td>\n",
       "      <td>5.0</td>\n",
       "      <td>82</td>\n",
       "      <td>82.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>2018-04-08 11:17:00</td>\n",
       "      <td>2018-04-08 11:21:00</td>\n",
       "      <td>2018-04-08 11:28:00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>diverticulitis, high bp, high cholesterol, thy...</td>\n",
       "      <td>[-1.94503769e-01 -8.38923976e-02  5.67541644e-...</td>\n",
       "      <td>[-1.24572255e-01 -2.15024259e-02  4.72823471e-...</td>\n",
       "      <td>1.174497</td>\n",
       "      <td>0.826922</td>\n",
       "      <td>-1.263975</td>\n",
       "      <td>-1.384923</td>\n",
       "      <td>-0.264089</td>\n",
       "      <td>-0.016198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1713</th>\n",
       "      <td>1714</td>\n",
       "      <td>E8216415</td>\n",
       "      <td>EE001716/18</td>\n",
       "      <td>2.0</td>\n",
       "      <td>49</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>2018-04-08 18:47:00</td>\n",
       "      <td>2018-04-08 18:50:00</td>\n",
       "      <td>2018-04-08 18:50:00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>liver and kidney failure</td>\n",
       "      <td>[-6.44557178e-02  2.12498493e-02 -4.99889851e-...</td>\n",
       "      <td>[-6.32119700e-02 -1.49392709e-01  4.46838409e-...</td>\n",
       "      <td>-0.208779</td>\n",
       "      <td>-1.538556</td>\n",
       "      <td>-0.180775</td>\n",
       "      <td>0.516400</td>\n",
       "      <td>-1.021555</td>\n",
       "      <td>-0.456082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1836</th>\n",
       "      <td>1837</td>\n",
       "      <td>E8152804</td>\n",
       "      <td>EE001838/18</td>\n",
       "      <td>2.0</td>\n",
       "      <td>57</td>\n",
       "      <td>57.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>2018-04-09 10:59:00</td>\n",
       "      <td>2018-04-09 11:02:00</td>\n",
       "      <td>2018-04-09 11:10:00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>htn, diabetic, thyroid, rt total nephrectomy, ...</td>\n",
       "      <td>[-1.45752514e-02 -3.72009605e-01  2.15191156e-...</td>\n",
       "      <td>[-1.14206485e-01 -3.34909745e-02  3.48307520e-...</td>\n",
       "      <td>0.126560</td>\n",
       "      <td>0.564091</td>\n",
       "      <td>0.767024</td>\n",
       "      <td>1.104905</td>\n",
       "      <td>-0.343823</td>\n",
       "      <td>-0.126169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1837</th>\n",
       "      <td>1838</td>\n",
       "      <td>E8181432</td>\n",
       "      <td>EE001839/18</td>\n",
       "      <td>2.0</td>\n",
       "      <td>75</td>\n",
       "      <td>75.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>2018-04-09 11:11:00</td>\n",
       "      <td>2018-04-09 11:15:00</td>\n",
       "      <td>2018-04-09 11:16:00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>no significant medical history</td>\n",
       "      <td>[-6.41224608e-02  1.80907622e-02 -2.60267198e-...</td>\n",
       "      <td>[-1.96476385e-01 -1.18435726e-01  5.01800537e-...</td>\n",
       "      <td>0.881075</td>\n",
       "      <td>-0.487232</td>\n",
       "      <td>0.090025</td>\n",
       "      <td>-1.430192</td>\n",
       "      <td>-0.104623</td>\n",
       "      <td>-0.126169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID ChartNumber EncounterNumber TriageLevel  AgeNumber  AgeInYrs  \\\n",
       "1184  1185    E8443276     EE001185/18         2.0         73      73.0   \n",
       "1620  1621    E3111507     EE001622/18         5.0         82      82.0   \n",
       "1713  1714    E8216415     EE001716/18         2.0         49      49.0   \n",
       "1836  1837    E8152804     EE001838/18         2.0         57      57.0   \n",
       "1837  1838    E8181432     EE001839/18         2.0         75      75.0   \n",
       "\n",
       "     GenderDesc   Triage Date & Time      Reg Date & Time  \\\n",
       "1184       Male  2018-04-06 10:16:00  2018-04-06 10:20:00   \n",
       "1620     Female  2018-04-08 11:17:00  2018-04-08 11:21:00   \n",
       "1713       Male  2018-04-08 18:47:00  2018-04-08 18:50:00   \n",
       "1836       Male  2018-04-09 10:59:00  2018-04-09 11:02:00   \n",
       "1837       Male  2018-04-09 11:11:00  2018-04-09 11:15:00   \n",
       "\n",
       "          PIA Date & Time      ...       target5  \\\n",
       "1184  2018-04-06 10:17:00      ...             0   \n",
       "1620  2018-04-08 11:28:00      ...             0   \n",
       "1713  2018-04-08 18:50:00      ...             0   \n",
       "1836  2018-04-09 11:10:00      ...             0   \n",
       "1837  2018-04-09 11:16:00      ...             0   \n",
       "\n",
       "                                                   pmhx  \\\n",
       "1184   bowel obstruction d/t bowel adhesions, htn, afib   \n",
       "1620  diverticulitis, high bp, high cholesterol, thy...   \n",
       "1713                           liver and kidney failure   \n",
       "1836  htn, diabetic, thyroid, rt total nephrectomy, ...   \n",
       "1837                     no significant medical history   \n",
       "\n",
       "                                            pmhx_embeds  \\\n",
       "1184  [-1.18588388e-01 -3.62613685e-02  1.71774179e-...   \n",
       "1620  [-1.94503769e-01 -8.38923976e-02  5.67541644e-...   \n",
       "1713  [-6.44557178e-02  2.12498493e-02 -4.99889851e-...   \n",
       "1836  [-1.45752514e-02 -3.72009605e-01  2.15191156e-...   \n",
       "1837  [-6.41224608e-02  1.80907622e-02 -2.60267198e-...   \n",
       "\n",
       "                                       subjnotes_embeds AgeInYrs_norm  \\\n",
       "1184  [-2.39613533e-01  4.64705452e-02  4.14689839e-...      0.797240   \n",
       "1620  [-1.24572255e-01 -2.15024259e-02  4.72823471e-...      1.174497   \n",
       "1713  [-6.32119700e-02 -1.49392709e-01  4.46838409e-...     -0.208779   \n",
       "1836  [-1.14206485e-01 -3.34909745e-02  3.48307520e-...      0.126560   \n",
       "1837  [-1.96476385e-01 -1.18435726e-01  5.01800537e-...      0.881075   \n",
       "\n",
       "     o2sat_norm temp_norm pulse_norm systolic_norm diastolic_norm  \n",
       "1184   0.301261 -0.180775  -0.841688      0.573110       0.286222  \n",
       "1620   0.826922 -1.263975  -1.384923     -0.264089      -0.016198  \n",
       "1713  -1.538556 -0.180775   0.516400     -1.021555      -0.456082  \n",
       "1836   0.564091  0.767024   1.104905     -0.343823      -0.126169  \n",
       "1837  -0.487232  0.090025  -1.430192     -0.104623      -0.126169  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "execution_count": 623,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont = np.array(balanced[new_cols]).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 6)"
      ]
     },
     "execution_count": 628,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cont.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 2, 69]"
      ]
     },
     "execution_count": 630,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_lengths = [len(set(balanced[cat])) for cat in cat_vars]\n",
    "class_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cat_data = []\n",
    "for cat in cat_vars:\n",
    "    #first make a dictionary mapping original name to a number\n",
    "    cat_to_num  = {cat:i for i,cat in enumerate(list(set(balanced[cat])))}\n",
    "    #then replace the categorgal label with numbers and add to output list\n",
    "    numerical_cat_data.append([cat_to_num[item] for item in balanced[cat]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 3)"
      ]
     },
     "execution_count": 632,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this makes a vertical array out of the categorical data\n",
    "cats_array = np.vstack(np.array(numerical_cat_data).astype(int)).transpose(); cats_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5, 4), (2, 2), (69, 17)]"
      ]
     },
     "execution_count": 633,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating a set of embedding sizes for each categorical variable\n",
    "emb_szs = [(length, min(600, round(1.6 * length **0.56))) for length in class_lengths]\n",
    "emb_szs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subj, validation_subj = train_test_split(subj, random_state = 42, test_size=0.1)\n",
    "train_medhx, validation_medhx = train_test_split(medhx, random_state = 42, test_size=0.1)\n",
    "train_cont, validation_cont = train_test_split(cont, random_state = 42, test_size=0.1)\n",
    "train_cats, validation_cats = train_test_split(cats_array, random_state = 42, test_size=0.1)\n",
    "train_labels, validation_labels = train_test_split(labels, random_state = 42, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subj = torch.tensor(train_subj)\n",
    "validation_subj = torch.tensor(validation_subj)\n",
    "train_medhx = torch.tensor(train_medhx)\n",
    "validation_medhx = torch.tensor(validation_medhx)\n",
    "train_cont = torch.tensor(train_cont)\n",
    "validation_cont = torch.tensor(validation_cont)\n",
    "train_cats = torch.tensor(train_cats)\n",
    "validation_cats = torch.tensor(validation_cats)\n",
    "train_labels = torch.tensor(train_labels)\n",
    "validation_labels = torch.tensor(validation_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "\n",
    "train_data = TensorDataset(train_subj, train_medhx, train_cont,train_cats,train_labels)\n",
    "trainloader = DataLoader(train_data, batch_size=batch_size, shuffle = True)\n",
    "\n",
    "valid_data = TensorDataset(validation_subj, validation_medhx, validation_cont, validation_cats, validation_labels)\n",
    "validloader = DataLoader(valid_data, batch_size=batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 867,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net3(nn.Module):\n",
    "    def __init__(self, emb_szs):\n",
    "        super(Net3, self).__init__()\n",
    "        \n",
    "        #first create the embedding layers for each of the categorical variables\n",
    "        self.embed_layers = nn.ModuleList([nn.Embedding(ni, nf) for ni,nf in emb_szs])\n",
    "        n_emb = sum(e.embedding_dim for e in self.embed_layers)\n",
    "        \n",
    "        #define dropouts\n",
    "        self.emb_drop = nn.Dropout(0.5)\n",
    "        self.lin_drop = nn.Dropout(0.5)\n",
    "        \n",
    "        #define batchnorms\n",
    "        self.nlp1_bn = nn.BatchNorm1d(768)\n",
    "        self.nlp2_bn = nn.BatchNorm1d(768)\n",
    "        self.comb_bn = nn.BatchNorm1d(36)\n",
    "        self.comb_bn2 = nn.BatchNorm1d(200)\n",
    "        \n",
    "        self.linear_subjective = nn.Linear(768,10)  \n",
    "        self.linear_medhx = nn.Linear(768, 10)\n",
    "        self.linear_cat = nn.Linear(n_emb,10)\n",
    "        self.linear_combined1 = nn.Linear(36, 200)\n",
    "        self.linear_combined2 = nn.Linear(200,100)\n",
    "        self.out = nn.Linear(100,4)\n",
    "\n",
    "    def forward(self, subj,medhx,cont,cat_var):\n",
    "        #first we run each BERT vector through a linear layer and activation\n",
    "        nlp1 = F.relu(self.linear_subjective(self.lin_drop(subj)))\n",
    "        nlp2 = F.relu(self.linear_medhx(self.lin_drop(medhx)))\n",
    "        \n",
    "        #now we pass each categorical variable through an embedding layer, combine output and pass through\n",
    "        #a linear layer with activation\n",
    "        embeds = [e(cat_var[:,i]) for i,e in enumerate(self.embed_layers)]\n",
    "        embeds = torch.cat(embeds, 1)\n",
    "        embeds = self.linear_cat(embeds)\n",
    "        embeds = self.emb_drop(embeds)\n",
    "        #embeds = F.relu(self.linear_cat(embeds))  #they dont have an activation after the embeddings in fast.ai\n",
    "        \n",
    "        #now we combine all four sources of input and pass through a layer with activation\n",
    "        combined = torch.cat((nlp1,nlp2,cont,embeds), axis = 1)\n",
    "        combined_norm = self.lin_drop(self.comb_bn(combined))\n",
    "        x = F.relu(self.linear_combined1(combined_norm))\n",
    "        x = F.relu(self.linear_combined2(self.lin_drop(self.comb_bn2(x))))\n",
    "        \n",
    "        #compute logits\n",
    "        x = self.out(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 868,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net3(\n",
       "  (embed_layers): ModuleList(\n",
       "    (0): Embedding(5, 4)\n",
       "    (1): Embedding(2, 2)\n",
       "    (2): Embedding(69, 17)\n",
       "  )\n",
       "  (emb_drop): Dropout(p=0.5, inplace=False)\n",
       "  (lin_drop): Dropout(p=0.5, inplace=False)\n",
       "  (nlp1_bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (nlp2_bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (comb_bn): BatchNorm1d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (comb_bn2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (linear_subjective): Linear(in_features=768, out_features=10, bias=True)\n",
       "  (linear_medhx): Linear(in_features=768, out_features=10, bias=True)\n",
       "  (linear_cat): Linear(in_features=23, out_features=10, bias=True)\n",
       "  (linear_combined1): Linear(in_features=36, out_features=200, bias=True)\n",
       "  (linear_combined2): Linear(in_features=200, out_features=100, bias=True)\n",
       "  (out): Linear(in_features=100, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 868,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Net3(emb_szs)\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 869,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1,x2,x3,x4,x5 = next(iter(trainloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 870,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4133, -0.0332, -0.4821,  0.3188],\n",
       "        [-0.4989, -0.0729,  0.3424, -0.5555],\n",
       "        [-0.2026,  0.6119, -0.2030, -0.4365],\n",
       "        [-0.1506,  0.2384, -0.5336, -0.3117]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 870,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(x1,x2,x3,x4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 871,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  0.467 sec\n",
      "Training loss = 1.3977\n",
      "Validation loss = 1.3572\n",
      "\n",
      "Epoch 2:  0.476 sec\n",
      "Training loss = 1.3244\n",
      "Validation loss = 1.4125\n",
      "\n",
      "Epoch 3:  0.443 sec\n",
      "Training loss = 1.3577\n",
      "Validation loss = 1.3353\n",
      "\n",
      "Epoch 4:  0.445 sec\n",
      "Training loss = 1.3845\n",
      "Validation loss = 1.2872\n",
      "\n",
      "Epoch 5:  0.441 sec\n",
      "Training loss = 1.3467\n",
      "Validation loss = 1.3325\n",
      "\n",
      "Epoch 6:  0.450 sec\n",
      "Training loss = 1.3024\n",
      "Validation loss = 1.3217\n",
      "\n",
      "Epoch 7:  0.488 sec\n",
      "Training loss = 1.3461\n",
      "Validation loss = 1.3372\n",
      "\n",
      "Epoch 8:  0.448 sec\n",
      "Training loss = 1.3148\n",
      "Validation loss = 1.3448\n",
      "\n",
      "Epoch 9:  0.447 sec\n",
      "Training loss = 1.3299\n",
      "Validation loss = 1.4178\n",
      "\n",
      "Epoch 10:  0.482 sec\n",
      "Training loss = 1.3200\n",
      "Validation loss = 1.4277\n",
      "\n",
      "Epoch 11:  0.476 sec\n",
      "Training loss = 1.3020\n",
      "Validation loss = 1.3817\n",
      "\n",
      "Epoch 12:  0.478 sec\n",
      "Training loss = 1.2925\n",
      "Validation loss = 1.3332\n",
      "\n",
      "Epoch 13:  0.588 sec\n",
      "Training loss = 1.3147\n",
      "Validation loss = 1.2378\n",
      "\n",
      "Epoch 14:  0.471 sec\n",
      "Training loss = 1.2555\n",
      "Validation loss = 1.2823\n",
      "\n",
      "Epoch 15:  0.487 sec\n",
      "Training loss = 1.2874\n",
      "Validation loss = 1.2805\n",
      "\n",
      "Epoch 16:  0.450 sec\n",
      "Training loss = 1.3175\n",
      "Validation loss = 1.2859\n",
      "\n",
      "Epoch 17:  0.453 sec\n",
      "Training loss = 1.3029\n",
      "Validation loss = 1.2662\n",
      "\n",
      "Epoch 18:  0.456 sec\n",
      "Training loss = 1.3035\n",
      "Validation loss = 1.2529\n",
      "\n",
      "Epoch 19:  0.451 sec\n",
      "Training loss = 1.2823\n",
      "Validation loss = 1.2504\n",
      "\n",
      "Epoch 20:  0.452 sec\n",
      "Training loss = 1.2629\n",
      "Validation loss = 1.2955\n",
      "\n",
      "Epoch 21:  0.452 sec\n",
      "Training loss = 1.2859\n",
      "Validation loss = 1.3927\n",
      "\n",
      "Epoch 22:  0.450 sec\n",
      "Training loss = 1.2612\n",
      "Validation loss = 1.3014\n",
      "\n",
      "Epoch 23:  0.450 sec\n",
      "Training loss = 1.2280\n",
      "Validation loss = 1.3091\n",
      "\n",
      "Epoch 24:  0.455 sec\n",
      "Training loss = 1.2507\n",
      "Validation loss = 1.3313\n",
      "\n",
      "Epoch 25:  0.456 sec\n",
      "Training loss = 1.2646\n",
      "Validation loss = 1.2975\n",
      "\n",
      "Epoch 26:  0.451 sec\n",
      "Training loss = 1.2101\n",
      "Validation loss = 1.2178\n",
      "\n",
      "Epoch 27:  0.450 sec\n",
      "Training loss = 1.2559\n",
      "Validation loss = 1.2705\n",
      "\n",
      "Epoch 28:  0.483 sec\n",
      "Training loss = 1.2138\n",
      "Validation loss = 1.2047\n",
      "\n",
      "Epoch 29:  0.479 sec\n",
      "Training loss = 1.2700\n",
      "Validation loss = 1.1906\n",
      "\n",
      "Epoch 30:  0.452 sec\n",
      "Training loss = 1.2439\n",
      "Validation loss = 1.2779\n",
      "\n",
      "Epoch 31:  0.457 sec\n",
      "Training loss = 1.1907\n",
      "Validation loss = 1.2380\n",
      "\n",
      "Epoch 32:  0.448 sec\n",
      "Training loss = 1.1884\n",
      "Validation loss = 1.2411\n",
      "\n",
      "Epoch 33:  0.451 sec\n",
      "Training loss = 1.1895\n",
      "Validation loss = 1.2255\n",
      "\n",
      "Epoch 34:  0.447 sec\n",
      "Training loss = 1.2305\n",
      "Validation loss = 1.2564\n",
      "\n",
      "Epoch 35:  0.565 sec\n",
      "Training loss = 1.1968\n",
      "Validation loss = 1.2372\n",
      "\n",
      "Epoch 36:  0.566 sec\n",
      "Training loss = 1.1858\n",
      "Validation loss = 1.2593\n",
      "\n",
      "Epoch 37:  0.541 sec\n",
      "Training loss = 1.2311\n",
      "Validation loss = 1.2204\n",
      "\n",
      "Epoch 38:  0.476 sec\n",
      "Training loss = 1.2218\n",
      "Validation loss = 1.2717\n",
      "\n",
      "Epoch 39:  0.534 sec\n",
      "Training loss = 1.2114\n",
      "Validation loss = 1.2941\n",
      "\n",
      "Epoch 40:  0.643 sec\n",
      "Training loss = 1.1328\n",
      "Validation loss = 1.3067\n",
      "\n",
      "Epoch 41:  0.662 sec\n",
      "Training loss = 1.2086\n",
      "Validation loss = 1.2075\n",
      "\n",
      "Epoch 42:  0.558 sec\n",
      "Training loss = 1.1333\n",
      "Validation loss = 1.2648\n",
      "\n",
      "Epoch 43:  0.481 sec\n",
      "Training loss = 1.1932\n",
      "Validation loss = 1.2032\n",
      "\n",
      "Epoch 44:  0.450 sec\n",
      "Training loss = 1.1481\n",
      "Validation loss = 1.2232\n",
      "\n",
      "Epoch 45:  0.452 sec\n",
      "Training loss = 1.1825\n",
      "Validation loss = 1.2358\n",
      "\n",
      "Epoch 46:  0.448 sec\n",
      "Training loss = 1.1996\n",
      "Validation loss = 1.2335\n",
      "\n",
      "Epoch 47:  0.449 sec\n",
      "Training loss = 1.1808\n",
      "Validation loss = 1.1612\n",
      "\n",
      "Epoch 48:  0.451 sec\n",
      "Training loss = 1.1657\n",
      "Validation loss = 1.1987\n",
      "\n",
      "Epoch 49:  0.451 sec\n",
      "Training loss = 1.2527\n",
      "Validation loss = 1.2093\n",
      "\n",
      "Epoch 50:  0.452 sec\n",
      "Training loss = 1.1539\n",
      "Validation loss = 1.2647\n",
      "\n"
     ]
    }
   ],
   "source": [
    "net = Net3(emb_szs)\n",
    "tloss, vloss = train_model3(net, lr = 1e-3,epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 872,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(tloss,'b', label = 'train')\n",
    "plt.plot(vloss,'g', label = 'valid')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 873,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "  discharge       0.36      0.44      0.40         9\n",
      "     madmit       0.21      0.75      0.33         4\n",
      "     sadmit       1.00      0.38      0.55        16\n",
      "        ICU       0.67      0.55      0.60        11\n",
      "\n",
      "avg / total       0.69      0.47      0.51        40\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4 4 0 1]\n",
      " [0 3 0 1]\n",
      " [6 3 6 1]\n",
      " [1 4 0 6]]\n",
      "\n",
      "accuracy =  47.5 %\n"
     ]
    }
   ],
   "source": [
    "#let's do some inference\n",
    "net.eval()\n",
    "pred_matrix = []\n",
    "label_matrix = []\n",
    "\n",
    "for batch_data in validloader:\n",
    "            \n",
    "    cont_var, subj_notes, medhx, cat_var, labels = tuple(t.to(device) for t in batch_data)\n",
    "            \n",
    "    logits = net(cont_var, subj_notes, medhx, cat_var)\n",
    "        \n",
    "    preds = np.argmax(logits.detach().numpy(), axis = 1)\n",
    "    pred_matrix.append(preds)\n",
    "    \n",
    "    labels = labels.detach().numpy()\n",
    "    label_matrix.append(labels)\n",
    "\n",
    "y_pred = [item for sublist in pred_matrix for item in sublist]\n",
    "y_true = [item for sublist in label_matrix for item in sublist]\n",
    "\n",
    "classification = metrics.classification_report(y_pred,y_true, target_names = ['discharge', 'madmit', 'sadmit', 'ICU'])\n",
    "conf = metrics.confusion_matrix(y_pred,y_true)\n",
    "acc = metrics.accuracy_score(y_pred,y_true)\n",
    "print ('Classification Report:')\n",
    "print(classification)\n",
    "print ()\n",
    "print('Confusion Matrix:')\n",
    "print (conf)\n",
    "print()\n",
    "print ('accuracy = ', acc *100, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for the most part, the best I can do with this model is 47.5% accuracy. \n",
    "\n",
    "next step will be to add the comorbid column.  will need to reembed the cleaned versions of the notes and medhx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
