{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from torch.optim import Adam\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj = torch.rand(160,768).numpy()\n",
    "medhx = torch.rand(160,768).numpy()\n",
    "cont = torch.rand(160,10).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = torch.randint(0,3,(160,)).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((160, 768), (160, 768), (160, 10), (160,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subj.shape, medhx.shape, cont.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subj, validation_subj = train_test_split(subj, random_state = 42, test_size=0.1)\n",
    "train_medhx, validation_medhx = train_test_split(medhx, random_state = 42, test_size=0.1)\n",
    "train_cont, validation_cont = train_test_split(cont, random_state = 42, test_size=0.1)\n",
    "train_labels, validation_labels = train_test_split(labels, random_state = 42, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subj = torch.tensor(train_subj)\n",
    "validation_subj = torch.tensor(validation_subj)\n",
    "train_medhx = torch.tensor(train_medhx)\n",
    "validation_medhx = torch.tensor(validation_medhx)\n",
    "train_cont = torch.tensor(train_cont)\n",
    "validation_cont = torch.tensor(validation_cont)\n",
    "train_labels = torch.tensor(train_labels)\n",
    "validation_labels = torch.tensor(validation_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a batch size for training. For fine-tuning BERT on a specific task, the authors recommend a batch size of 16 or 32\n",
    "batch_size = 4\n",
    "\n",
    "# Create an iterator of our data with torch DataLoader. This helps save on memory during training because, unlike a for loop, \n",
    "# with an iterator the entire dataset does not need to be loaded into memory\n",
    "\n",
    "train_data = TensorDataset(train_subj, train_medhx, train_cont,train_labels)\n",
    "trainloader = DataLoader(train_data, batch_size=batch_size)\n",
    "\n",
    "valid_data = TensorDataset(validation_subj, validation_medhx, validation_cont, validation_labels)\n",
    "validloader = DataLoader(valid_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameters\n",
    "lr = 1\n",
    "epochs = 10\n",
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.linear_subjective = nn.Linear(768,10)  \n",
    "        self.linear_medhx = nn.Linear(768, 10)\n",
    "        self.linear_combined = nn.Linear(30, 10)\n",
    "        self.out = nn.Linear(10,4)\n",
    "\n",
    "    def forward(self, subj,medhx,cont):\n",
    "        nlp1 = F.relu(self.linear_subjective(subj))\n",
    "        nlp2 = F.relu(self.linear_medhx(medhx))\n",
    "        combined = torch.cat((nlp1,nlp2,cont), axis = 1)\n",
    "        x = F.relu(self.linear_combined(combined))\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (linear_subjective): Linear(in_features=768, out_features=10, bias=True)\n",
       "  (linear_medhx): Linear(in_features=768, out_features=10, bias=True)\n",
       "  (linear_combined): Linear(in_features=30, out_features=10, bias=True)\n",
       "  (out): Linear(in_features=10, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Net()\n",
    "net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### testing the forward method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1,x2,x3,x4 = next(iter(trainloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2226,  0.1290,  0.1714, -0.1460],\n",
       "        [-0.1716,  0.1199,  0.1439, -0.2022],\n",
       "        [-0.1964,  0.1718,  0.1426, -0.1359],\n",
       "        [-0.2518,  0.0691,  0.1552, -0.1029]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(x1,x2,x3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trying the training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model):\n",
    "    optimizer = Adam(model.parameters(), lr = lr)\n",
    "    running_loss = []\n",
    "    for epoch_num in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for step_num, batch_data in enumerate(trainloader):\n",
    "        \n",
    "            cont_var, subj_notes, medhx, labels = tuple(t.to(device) for t in batch_data)\n",
    "        \n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "            logits = model(cont_var, subj_notes, medhx)#, cat_var)\n",
    "        \n",
    "            batch_loss = loss_func(logits, labels)\n",
    "        \n",
    "            train_loss += batch_loss.item()\n",
    "        \n",
    "            batch_loss.backward()\n",
    "        \n",
    "\n",
    "            clip_grad_norm_(parameters=model.parameters(), max_norm=1.0)\n",
    "        \n",
    "            optimizer.step()\n",
    "        \n",
    "            if step_num %12 == 0:\n",
    "                print('Epoch: ', epoch_num + 1)\n",
    "                print(\"\\r\" + \"{0}/{1} loss: {2} \".format(step_num, len(train_data) / batch_size, train_loss / (step_num + 1)))\n",
    "            \n",
    "        running_loss.append(train_loss)\n",
    "\n",
    "    return running_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1\n",
      "0/36.0 loss: 1.0526337623596191 \n",
      "Epoch:  1\n",
      "12/36.0 loss: 41.83641877999673 \n",
      "Epoch:  1\n",
      "24/36.0 loss: 22.575640099048613 \n",
      "Epoch:  2\n",
      "0/36.0 loss: 1.0975940227508545 \n",
      "Epoch:  2\n",
      "12/36.0 loss: 1.2829447663747346 \n",
      "Epoch:  2\n",
      "24/36.0 loss: 1.3403034138679504 \n",
      "Epoch:  3\n",
      "0/36.0 loss: 1.0640887022018433 \n",
      "Epoch:  3\n",
      "12/36.0 loss: 1.2593571910491357 \n",
      "Epoch:  3\n",
      "24/36.0 loss: 1.2724158573150635 \n",
      "Epoch:  4\n",
      "0/36.0 loss: 1.0711201429367065 \n",
      "Epoch:  4\n",
      "12/36.0 loss: 1.2784013610619764 \n",
      "Epoch:  4\n",
      "24/36.0 loss: 1.2847436308860778 \n",
      "Epoch:  5\n",
      "0/36.0 loss: 1.072556495666504 \n",
      "Epoch:  5\n",
      "12/36.0 loss: 1.2776251710378206 \n",
      "Epoch:  5\n",
      "24/36.0 loss: 1.283041579723358 \n",
      "Epoch:  6\n",
      "0/36.0 loss: 1.0720102787017822 \n",
      "Epoch:  6\n",
      "12/36.0 loss: 1.276703880383418 \n",
      "Epoch:  6\n",
      "24/36.0 loss: 1.282629632949829 \n",
      "Epoch:  7\n",
      "0/36.0 loss: 1.07192862033844 \n",
      "Epoch:  7\n",
      "12/36.0 loss: 1.2761239959643438 \n",
      "Epoch:  7\n",
      "24/36.0 loss: 1.2822259831428529 \n",
      "Epoch:  8\n",
      "0/36.0 loss: 1.0718587636947632 \n",
      "Epoch:  8\n",
      "12/36.0 loss: 1.2757156766377962 \n",
      "Epoch:  8\n",
      "24/36.0 loss: 1.281968376636505 \n",
      "Epoch:  9\n",
      "0/36.0 loss: 1.0717960596084595 \n",
      "Epoch:  9\n",
      "12/36.0 loss: 1.2754059571486254 \n",
      "Epoch:  9\n",
      "24/36.0 loss: 1.2817796087265014 \n",
      "Epoch:  10\n",
      "0/36.0 loss: 1.0717322826385498 \n",
      "Epoch:  10\n",
      "12/36.0 loss: 1.2751541412793672 \n",
      "Epoch:  10\n",
      "24/36.0 loss: 1.2816333770751953 \n"
     ]
    }
   ],
   "source": [
    "cum_loss = train_model(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[580.8011103272438,\n",
       " 47.519757986068726,\n",
       " 45.66475993394852,\n",
       " 46.122944831848145,\n",
       " 46.101360857486725,\n",
       " 46.10654467344284,\n",
       " 46.104398012161255,\n",
       " 46.10389906167984,\n",
       " 46.103628158569336,\n",
       " 46.1034300327301]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cum_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a251c6518>]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(cum_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## now we are going to make the model more complex and add embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = np.random.randint(1, 30, size=(160))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(cats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_size = min(50, len(set(cats))+1// 2);\n",
    "embedding_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subj, validation_subj = train_test_split(subj, random_state = 42, test_size=0.1)\n",
    "train_medhx, validation_medhx = train_test_split(medhx, random_state = 42, test_size=0.1)\n",
    "train_cont, validation_cont = train_test_split(cont, random_state = 42, test_size=0.1)\n",
    "train_cats, validation_cats = train_test_split(cats, random_state = 42, test_size=0.1)\n",
    "train_labels, validation_labels = train_test_split(labels, random_state = 42, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subj = torch.tensor(train_subj)\n",
    "validation_subj = torch.tensor(validation_subj)\n",
    "train_medhx = torch.tensor(train_medhx)\n",
    "validation_medhx = torch.tensor(validation_medhx)\n",
    "train_cont = torch.tensor(train_cont)\n",
    "validation_cont = torch.tensor(validation_cont)\n",
    "train_cats = torch.tensor(train_cats)\n",
    "validation_cats = torch.tensor(validation_cats)\n",
    "train_labels = torch.tensor(train_labels)\n",
    "validation_labels = torch.tensor(validation_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a batch size for training. For fine-tuning BERT on a specific task, the authors recommend a batch size of 16 or 32\n",
    "batch_size = 4\n",
    "\n",
    "# Create an iterator of our data with torch DataLoader. This helps save on memory during training because, unlike a for loop, \n",
    "# with an iterator the entire dataset does not need to be loaded into memory\n",
    "\n",
    "train_data = TensorDataset(train_subj, train_medhx, train_cont,train_cats,train_labels)\n",
    "trainloader = DataLoader(train_data, batch_size=batch_size)\n",
    "\n",
    "valid_data = TensorDataset(validation_subj, validation_medhx, validation_cont, validation_cats, validation_labels)\n",
    "validloader = DataLoader(valid_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net1, self).__init__()\n",
    "        \n",
    "        self.linear_subjective = nn.Linear(768,10)  \n",
    "        self.linear_medhx = nn.Linear(768, 10)\n",
    "        self.embedding = nn.Embedding(len(set(cats))+1, embedding_size + 1)\n",
    "        self.linear_cat = nn.Linear(30,10)\n",
    "        self.linear_combined = nn.Linear(40, 10)\n",
    "        self.out = nn.Linear(10,4)\n",
    "\n",
    "    def forward(self, subj,medhx,cont,cat_var):\n",
    "        nlp1 = F.relu(self.linear_subjective(subj))\n",
    "        nlp2 = F.relu(self.linear_medhx(medhx))\n",
    "        embeds = self.embedding(cat_var)\n",
    "        cats = F.relu(self.linear_cat(embeds))\n",
    "        combined = torch.cat((nlp1,nlp2,cont,cats), axis = 1)\n",
    "        x = F.relu(self.linear_combined(combined))\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model2(model):\n",
    "    optimizer = Adam(model.parameters(), lr = lr)\n",
    "    running_loss = []\n",
    "    for epoch_num in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for step_num, batch_data in enumerate(trainloader):\n",
    "        \n",
    "            cont_var, subj_notes, medhx, cat_var, labels = tuple(t.to(device) for t in batch_data)\n",
    "        \n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "            logits = model(cont_var, subj_notes, medhx, cat_var)\n",
    "        \n",
    "            batch_loss = loss_func(logits, labels)\n",
    "        \n",
    "            train_loss += batch_loss.item()\n",
    "        \n",
    "            batch_loss.backward()\n",
    "        \n",
    "\n",
    "            clip_grad_norm_(parameters=model.parameters(), max_norm=1.0)\n",
    "        \n",
    "            optimizer.step()\n",
    "        \n",
    "            if step_num %12 == 0:\n",
    "                print('Epoch: ', epoch_num + 1)\n",
    "                print(\"\\r\" + \"{0}/{1} loss: {2} \".format(step_num, len(train_data) / batch_size, train_loss / (step_num + 1)))\n",
    "            \n",
    "        running_loss.append(train_loss)\n",
    "\n",
    "    return running_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net1(\n",
      "  (linear_subjective): Linear(in_features=768, out_features=10, bias=True)\n",
      "  (linear_medhx): Linear(in_features=768, out_features=10, bias=True)\n",
      "  (embedding): Embedding(30, 30)\n",
      "  (linear_cat): Linear(in_features=30, out_features=10, bias=True)\n",
      "  (linear_combined): Linear(in_features=40, out_features=10, bias=True)\n",
      "  (out): Linear(in_features=10, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = Net1()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x1,x2,x3,x4,x5 = next(iter(trainloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0868,  0.2228,  0.2944, -0.3075],\n",
       "        [ 0.1226,  0.1630,  0.3105, -0.2854],\n",
       "        [ 0.1171,  0.2344,  0.3092, -0.2632],\n",
       "        [ 0.0056,  0.2224,  0.2286, -0.2938]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(x1,x2,x3,x4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1\n",
      "0/36.0 loss: 1.3173404932022095 \n",
      "Epoch:  1\n",
      "12/36.0 loss: 478.08799888995975 \n",
      "Epoch:  1\n",
      "24/36.0 loss: 249.2812801194191 \n",
      "Epoch:  2\n",
      "0/36.0 loss: 1.1423039436340332 \n",
      "Epoch:  2\n",
      "12/36.0 loss: 1.3834199492747967 \n",
      "Epoch:  2\n",
      "24/36.0 loss: 1.3714889669418335 \n",
      "Epoch:  3\n",
      "0/36.0 loss: 1.0904712677001953 \n",
      "Epoch:  3\n",
      "12/36.0 loss: 1.2680792395885174 \n",
      "Epoch:  3\n",
      "24/36.0 loss: 1.269689657688141 \n",
      "Epoch:  4\n",
      "0/36.0 loss: 1.0702341794967651 \n",
      "Epoch:  4\n",
      "12/36.0 loss: 1.2725507708696218 \n",
      "Epoch:  4\n",
      "24/36.0 loss: 1.281328055858612 \n",
      "Epoch:  5\n",
      "0/36.0 loss: 1.0719343423843384 \n",
      "Epoch:  5\n",
      "12/36.0 loss: 1.2722261456342845 \n",
      "Epoch:  5\n",
      "24/36.0 loss: 1.2796733736991883 \n",
      "Epoch:  6\n",
      "0/36.0 loss: 1.0713878870010376 \n",
      "Epoch:  6\n",
      "12/36.0 loss: 1.2723769316306481 \n",
      "Epoch:  6\n",
      "24/36.0 loss: 1.2800783824920654 \n",
      "Epoch:  7\n",
      "0/36.0 loss: 1.0713046789169312 \n",
      "Epoch:  7\n",
      "12/36.0 loss: 1.2725464426554167 \n",
      "Epoch:  7\n",
      "24/36.0 loss: 1.2801926112174988 \n",
      "Epoch:  8\n",
      "0/36.0 loss: 1.071189045906067 \n",
      "Epoch:  8\n",
      "12/36.0 loss: 1.2726234518564665 \n",
      "Epoch:  8\n",
      "24/36.0 loss: 1.2802767443656922 \n",
      "Epoch:  9\n",
      "0/36.0 loss: 1.071110486984253 \n",
      "Epoch:  9\n",
      "12/36.0 loss: 1.2726850463793828 \n",
      "Epoch:  9\n",
      "24/36.0 loss: 1.2803366351127625 \n",
      "Epoch:  10\n",
      "0/36.0 loss: 1.0710506439208984 \n",
      "Epoch:  10\n",
      "12/36.0 loss: 1.2727304421938384 \n",
      "Epoch:  10\n",
      "24/36.0 loss: 1.2803806591033935 \n"
     ]
    }
   ],
   "source": [
    "cum_loss = train_model2(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### now I'm going to go through the process of creating a category variable and turing it into embedded classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "animals = ['manatee', 'dog', 'giraffe', 'narwhal', 'cat', 'elephant', 'mouse', 'dingo', 'wombat', 'skunk']\n",
    "cat_data = [[animal]* 16 for animal in animals]\n",
    "cat_data = [item for sublist in cat_data for item in sublist]\n",
    "random.shuffle(cat_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "animal_to_num = {animal:i for i,animal in enumerate(list(set(cat_data)))}\n",
    "num_to_animal = {i:animal for animal, i in enumerate(list(set(cat_data)))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cat_data = [animal_to_num[item] for item in cat_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(numerical_cat_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(numerical_cat_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
