{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "7_FXneEfpdMM",
    "outputId": "ff8057f1-23dc-49b8-b11c-f68823bf6f90"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytorch_pretrained_bert in /usr/local/lib/python3.6/site-packages (0.6.2)\n",
      "Requirement already satisfied: pytorch-nlp in /usr/local/lib/python3.6/site-packages (0.4.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/site-packages (from pytorch_pretrained_bert) (1.15.4)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.6/site-packages (from pytorch_pretrained_bert) (2019.8.19)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/site-packages (from pytorch_pretrained_bert) (2.21.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/site-packages (from pytorch_pretrained_bert) (4.31.1)\n",
      "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/site-packages (from pytorch_pretrained_bert) (1.0.1.post2)\n",
      "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/site-packages (from pytorch_pretrained_bert) (1.9.237)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.6/site-packages (from pytorch-nlp) (0.23.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/site-packages (from requests->pytorch_pretrained_bert) (2019.3.9)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/site-packages (from requests->pytorch_pretrained_bert) (2.8)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/site-packages (from requests->pytorch_pretrained_bert) (1.24.2)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/site-packages (from requests->pytorch_pretrained_bert) (3.0.4)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/site-packages (from boto3->pytorch_pretrained_bert) (0.9.4)\n",
      "Requirement already satisfied: botocore<1.13.0,>=1.12.237 in /usr/local/lib/python3.6/site-packages (from boto3->pytorch_pretrained_bert) (1.12.237)\n",
      "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/site-packages (from boto3->pytorch_pretrained_bert) (0.2.1)\n",
      "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/site-packages (from pandas->pytorch-nlp) (2018.7)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/site-packages (from pandas->pytorch-nlp) (2.7.5)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/site-packages (from botocore<1.13.0,>=1.12.237->boto3->pytorch_pretrained_bert) (0.15.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/site-packages (from python-dateutil>=2.5.0->pandas->pytorch-nlp) (1.12.0)\n",
      "\u001b[31mmenpo 0.8.1 has requirement matplotlib<2.0,>=1.4, but you'll have matplotlib 3.0.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mmenpo 0.8.1 has requirement pillow<5.0,>=3.0, but you'll have pillow 5.4.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mmenpo 0.8.1 has requirement scipy<1.0,>=0.16, but you'll have scipy 1.2.0 which is incompatible.\u001b[0m\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.2.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch_pretrained_bert pytorch-nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "EnVIV6Vt8f4d",
    "outputId": "3c8e3d88-13b0-4652-973d-3fa2c023e48e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jjaskolkambp/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import random as rn\n",
    "import torch\n",
    "from pytorch_pretrained_bert import BertModel\n",
    "from torch import nn\n",
    "from torchnlp.datasets import imdb_dataset\n",
    "from pytorch_pretrained_bert import BertTokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from torch.optim import Adam\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cUYrv06z8gaF"
   },
   "outputs": [],
   "source": [
    "rn.seed(321)\n",
    "np.random.seed(321)\n",
    "torch.manual_seed(321)\n",
    "torch.cuda.manual_seed(321)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rgkbhHcB17GY"
   },
   "source": [
    "## Prepare the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ur8i7boP6qtb"
   },
   "outputs": [],
   "source": [
    "train_data, test_data = imdb_dataset(train=True, test=True)\n",
    "rn.shuffle(train_data)\n",
    "rn.shuffle(test_data)\n",
    "train_data = train_data[:1000]\n",
    "test_data = test_data[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "l1VENo6tqG7J",
    "outputId": "5f10799f-d17d-42fd-a4c2-c760b61f7ed8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1000, 100, 100)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_texts, train_labels = list(zip(*map(lambda d: (d['text'], d['sentiment']), train_data)))\n",
    "test_texts, test_labels = list(zip(*map(lambda d: (d['text'], d['sentiment']), test_data)))\n",
    "\n",
    "len(train_texts), len(train_labels), len(test_texts), len(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ty24UrRjqIsb"
   },
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "1k9rcOzQr5Zm",
    "outputId": "b9b59a4e-57bd-4e9c-fcd1-2a4ba1fadc0e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 100)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tokens = list(map(lambda t: ['[CLS]'] + tokenizer.tokenize(t)[:510] + ['[SEP]'], train_texts))\n",
    "test_tokens = list(map(lambda t: ['[CLS]'] + tokenizer.tokenize(t)[:510] + ['[SEP]'], test_texts))\n",
    "\n",
    "len(train_tokens), len(test_tokens)                   \n",
    "                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "9Ca7KKnhuT5c",
    "outputId": "69ba3b87-4d86-448b-c9cb-7be8361182f6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 512), (100, 512))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tokens_ids = pad_sequences(list(map(tokenizer.convert_tokens_to_ids, train_tokens)), maxlen=512, truncating=\"post\", padding=\"post\", dtype=\"int\")\n",
    "test_tokens_ids = pad_sequences(list(map(tokenizer.convert_tokens_to_ids, test_tokens)), maxlen=512, truncating=\"post\", padding=\"post\", dtype=\"int\")\n",
    "\n",
    "train_tokens_ids.shape, test_tokens_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "F7POtHuIOV-6",
    "outputId": "a5447340-6da3-4f2c-d284-098c4c906c47"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000,), (100,), 0.489, 0.5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y = np.array(train_labels) == 'pos'\n",
    "test_y = np.array(test_labels) == 'pos'\n",
    "train_y.shape, test_y.shape, np.mean(train_y), np.mean(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U-xXMEqXOWTE"
   },
   "outputs": [],
   "source": [
    "train_masks = [[float(i > 0) for i in ii] for ii in train_tokens_ids]\n",
    "test_masks = [[float(i > 0) for i in ii] for ii in test_tokens_ids]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT outside the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = torch.tensor(train_masks[:1]).long().to(device)\n",
    "x = torch.tensor(train_tokens_ids[:1]).long().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    y,pool = model(x,m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512, 768])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([1, 512, 768])\n"
     ]
    }
   ],
   "source": [
    "for item in y:\n",
    "    print (item.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of layers: 12\n",
      "Number of batches: 1\n",
      "Number of tokens: 512\n",
      "Number of hidden units: 768\n"
     ]
    }
   ],
   "source": [
    "print (\"Number of layers:\", len(y))\n",
    "layer_i = 0\n",
    "\n",
    "print (\"Number of batches:\", len(y[layer_i]))\n",
    "batch_i = 0\n",
    "\n",
    "print (\"Number of tokens:\", len(y[layer_i][batch_i]))\n",
    "token_i = 0\n",
    "\n",
    "print (\"Number of hidden units:\", len(y[layer_i][batch_i][token_i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# For the 5th token in our sentence, select its feature values from layer 5.\n",
    "token_i = 5\n",
    "layer_i = 5\n",
    "vec = y[layer_i][batch_i][token_i].cpu()\n",
    "\n",
    "# Plot the values as a histogram to show their distribution.\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.hist(vec, bins=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens in sequence: 328\n",
      "Number of layers per token: 12\n",
      "length of sentence: 328\n"
     ]
    }
   ],
   "source": [
    "tokenized_text = train_tokens[0]\n",
    "# Convert the hidden state embeddings into single token vectors\n",
    "\n",
    "# Holds the list of 12 layer embeddings for each token\n",
    "# Will have the shape: [# tokens, # layers, # features]\n",
    "token_embeddings = [] \n",
    "\n",
    "# For each token in the sentence...\n",
    "for token_i in range(len(tokenized_text)):\n",
    "  \n",
    "  # Holds 12 layers of hidden states for each token \n",
    "    hidden_layers = [] \n",
    "  \n",
    "  # For each of the 12 layers...\n",
    "    for layer_i in range(len(y)):\n",
    "    \n",
    "        # Lookup the vector for `token_i` in `layer_i`\n",
    "        vec = y[layer_i][batch_i][token_i]\n",
    "    \n",
    "        hidden_layers.append(vec)\n",
    "    \n",
    "    token_embeddings.append(hidden_layers)\n",
    "\n",
    "# Sanity check the dimensions:\n",
    "print (\"Number of tokens in sequence:\", len(token_embeddings))\n",
    "print (\"Number of layers per token:\", len(token_embeddings[0]))\n",
    "print (\"length of sentence:\", len(tokenized_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, torch.Size([768]))"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(token_embeddings[0][0]), token_embeddings[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_last_4_layers = [torch.cat((layer[-1], layer[-2], layer[-3], layer[-4]), 0) for layer in token_embeddings] # [number_of_tokens, 3072]\n",
    "\n",
    "summed_last_4_layers = [torch.sum(torch.stack(layer)[-4:], 0) for layer in token_embeddings] # [number_of_tokens, 768]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(328, 3072)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(concatenated_last_4_layers), len(concatenated_last_4_layers[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3072"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "768*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(328, 768)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(summed_last_4_layers), len(summed_last_4_layers[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512, 768])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[11].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_embedding = torch.mean(y[11], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our final sentence embedding vector of shape:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, 768)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (\"Our final sentence embedding vector of shape:\"), sentence_embedding[0].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so basically, the entire sentence is embedded by taking the 11th layer of the output\n",
    "and averaging the 768 long vector for each token into a single 768 element vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [CLS]\n",
      "1 i\n",
      "2 loved\n",
      "3 the\n",
      "4 story\n",
      "5 .\n",
      "6 somewhere\n",
      "7 ,\n",
      "8 a\n",
      "9 poster\n",
      "10 said\n",
      "11 there\n",
      "12 are\n",
      "13 no\n",
      "14 families\n",
      "15 like\n",
      "16 the\n",
      "17 one\n",
      "18 portrayed\n",
      "19 in\n",
      "20 this\n",
      "21 film\n",
      "22 .\n",
      "23 well\n",
      "24 maybe\n",
      "25 there\n",
      "26 ought\n",
      "27 to\n",
      "28 be\n",
      "29 .\n",
      "30 i\n",
      "31 thought\n",
      "32 everybody\n",
      "33 seemed\n",
      "34 really\n",
      "35 human\n",
      "36 and\n",
      "37 bel\n",
      "38 ##ie\n",
      "39 ##vable\n",
      "40 .\n",
      "41 what\n",
      "42 a\n",
      "43 top\n",
      "44 notch\n",
      "45 cast\n",
      "46 .\n",
      "47 what\n",
      "48 great\n",
      "49 music\n",
      "50 on\n",
      "51 the\n",
      "52 soundtrack\n",
      "53 .\n",
      "54 what\n",
      "55 a\n",
      "56 nice\n",
      "57 this\n",
      "58 ,\n",
      "59 and\n",
      "60 what\n",
      "61 a\n",
      "62 nice\n",
      "63 that\n",
      "64 ,\n",
      "65 but\n",
      "66 most\n",
      "67 of\n",
      "68 all\n",
      "69 ,\n",
      "70 i\n",
      "71 will\n",
      "72 say\n",
      "73 two\n",
      "74 words\n",
      "75 to\n",
      "76 recommend\n",
      "77 this\n",
      "78 film\n",
      "79 .\n",
      "80 <\n",
      "81 br\n",
      "82 /\n",
      "83 >\n",
      "84 <\n",
      "85 br\n",
      "86 /\n",
      "87 >\n",
      "88 steve\n",
      "89 care\n",
      "90 ##ll\n",
      "91 .\n",
      "92 <\n",
      "93 br\n",
      "94 /\n",
      "95 >\n",
      "96 <\n",
      "97 br\n",
      "98 /\n",
      "99 >\n",
      "100 he\n",
      "101 really\n",
      "102 showed\n",
      "103 a\n",
      "104 nice\n",
      "105 ,\n",
      "106 subtle\n",
      "107 depth\n",
      "108 that\n",
      "109 touched\n",
      "110 me\n",
      "111 .\n",
      "112 he\n",
      "113 was\n",
      "114 truly\n",
      "115 commanding\n",
      "116 as\n",
      "117 a\n",
      "118 widow\n",
      "119 ##er\n",
      "120 who\n",
      "121 had\n",
      "122 dedicated\n",
      "123 himself\n",
      "124 maybe\n",
      "125 a\n",
      "126 little\n",
      "127 too\n",
      "128 much\n",
      "129 to\n",
      "130 being\n",
      "131 a\n",
      "132 good\n",
      "133 dad\n",
      "134 first\n",
      "135 ,\n",
      "136 at\n",
      "137 the\n",
      "138 cost\n",
      "139 of\n",
      "140 denying\n",
      "141 his\n",
      "142 own\n",
      "143 needs\n",
      "144 .\n",
      "145 <\n",
      "146 br\n",
      "147 /\n",
      "148 >\n",
      "149 <\n",
      "150 br\n",
      "151 /\n",
      "152 >\n",
      "153 did\n",
      "154 he\n",
      "155 act\n",
      "156 like\n",
      "157 a\n",
      "158 pet\n",
      "159 ##ula\n",
      "160 ##nt\n",
      "161 ass\n",
      "162 ?\n",
      "163 why\n",
      "164 ,\n",
      "165 yes\n",
      "166 he\n",
      "167 did\n",
      "168 .\n",
      "169 <\n",
      "170 br\n",
      "171 /\n",
      "172 >\n",
      "173 <\n",
      "174 br\n",
      "175 /\n",
      "176 >\n",
      "177 and\n",
      "178 you\n",
      "179 see\n",
      "180 ,\n",
      "181 that\n",
      "182 '\n",
      "183 s\n",
      "184 what\n",
      "185 was\n",
      "186 perfect\n",
      "187 about\n",
      "188 this\n",
      "189 film\n",
      "190 .\n",
      "191 the\n",
      "192 actor\n",
      "193 who\n",
      "194 played\n",
      "195 this\n",
      "196 character\n",
      "197 made\n",
      "198 me\n",
      "199 believe\n",
      "200 he\n",
      "201 was\n",
      "202 feeling\n",
      "203 something\n",
      "204 ,\n",
      "205 and\n",
      "206 not\n",
      "207 simply\n",
      "208 acting\n",
      "209 like\n",
      "210 he\n",
      "211 was\n",
      "212 feeling\n",
      "213 something\n",
      "214 ,\n",
      "215 and\n",
      "216 he\n",
      "217 conveyed\n",
      "218 to\n",
      "219 me\n",
      "220 perfectly\n",
      "221 what\n",
      "222 it\n",
      "223 was\n",
      "224 that\n",
      "225 he\n",
      "226 was\n",
      "227 feeling\n",
      "228 ,\n",
      "229 and\n",
      "230 what\n",
      "231 he\n",
      "232 was\n",
      "233 feeling\n",
      "234 was\n",
      "235 denied\n",
      "236 .\n",
      "237 <\n",
      "238 br\n",
      "239 /\n",
      "240 >\n",
      "241 <\n",
      "242 br\n",
      "243 /\n",
      "244 >\n",
      "245 denied\n",
      "246 happiness\n",
      "247 .\n",
      "248 <\n",
      "249 br\n",
      "250 /\n",
      "251 >\n",
      "252 <\n",
      "253 br\n",
      "254 /\n",
      "255 >\n",
      "256 denied\n",
      "257 fulfillment\n",
      "258 .\n",
      "259 <\n",
      "260 br\n",
      "261 /\n",
      "262 >\n",
      "263 <\n",
      "264 br\n",
      "265 /\n",
      "266 >\n",
      "267 denied\n",
      "268 love\n",
      "269 .\n",
      "270 <\n",
      "271 br\n",
      "272 /\n",
      "273 >\n",
      "274 <\n",
      "275 br\n",
      "276 /\n",
      "277 >\n",
      "278 losing\n",
      "279 your\n",
      "280 love\n",
      "281 is\n",
      "282 painful\n",
      "283 beyond\n",
      "284 belief\n",
      "285 ,\n",
      "286 and\n",
      "287 many\n",
      "288 who\n",
      "289 do\n",
      "290 so\n",
      "291 will\n",
      "292 never\n",
      "293 feel\n",
      "294 something\n",
      "295 like\n",
      "296 that\n",
      "297 again\n",
      "298 .\n",
      "299 <\n",
      "300 br\n",
      "301 /\n",
      "302 >\n",
      "303 <\n",
      "304 br\n",
      "305 /\n",
      "306 >\n",
      "307 beautiful\n",
      "308 film\n",
      "309 .\n",
      "310 <\n",
      "311 br\n",
      "312 /\n",
      "313 >\n",
      "314 <\n",
      "315 br\n",
      "316 /\n",
      "317 >\n",
      "318 i\n",
      "319 gave\n",
      "320 it\n",
      "321 an\n",
      "322 eight\n",
      "323 out\n",
      "324 of\n",
      "325 ten\n",
      "326 .\n",
      "327 [SEP]\n"
     ]
    }
   ],
   "source": [
    "for i,x in enumerate(tokenized_text):\n",
    "    print (i,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First fifteen values of 'truly':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 1.2784, -1.1363,  7.1270, -0.7993,  2.7548,  1.6524,  4.2326, -1.4705,\n",
       "         1.9733, -0.1732,  1.5759, -3.4783, -1.3119, -1.6201,  4.0390],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (\"First fifteen values of 'truly':\")\n",
    "summed_last_4_layers[114][:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r_hEhebQ3YqI"
   },
   "source": [
    "# Bert Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E234ByBa3Qtb"
   },
   "outputs": [],
   "source": [
    "class BertBinaryClassifier(nn.Module):\n",
    "    def __init__(self, dropout=0.1):\n",
    "        super(BertBinaryClassifier, self).__init__()\n",
    "\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(768, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, tokens, masks=None):\n",
    "        _, pooled_output = self.bert(tokens, attention_mask=masks, output_all_encoded_layers=False)\n",
    "        dropout_output = self.dropout(pooled_output)\n",
    "        linear_output = self.linear(dropout_output)\n",
    "        proba = self.sigmoid(linear_output)\n",
    "        return proba\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ED9SE1Ka8W9x",
    "outputId": "ab8b549b-137b-491a-cf6f-f20718dd73ff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "FNZ_3auqDbjl",
    "outputId": "1c20ee58-abb4-4bf2-f79a-851ab54c31eb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'438.881792M'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(torch.cuda.memory_allocated(device)/1000000 ) + 'M'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Sf9n8zouENRi"
   },
   "outputs": [],
   "source": [
    "bert_clf = BertBinaryClassifier()\n",
    "bert_clf = bert_clf.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "LbHkaJuZEkYr",
    "outputId": "dff4b8e7-db91-46de-8b8c-bf0cddccaba9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'438.881792M'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(torch.cuda.memory_allocated(device)/1000000 ) + 'M'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "LOQ-870M7VWy",
    "outputId": "f7c010bf-eb70-413f-96db-c0eb14769cfa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 512]), torch.Size([3, 512, 768]), torch.Size([3, 768]))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor(train_tokens_ids[:3]).to(device)\n",
    "y, pooled = bert_clf.bert(x, output_all_encoded_layers=False)\n",
    "x.shape, y.shape, pooled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "LCb_pK4X7hb9",
    "outputId": "77237549-1b51-4d51-a11e-84e53fa82cb3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.480183  ],\n",
       "       [0.4748414 ],\n",
       "       [0.40391952]], dtype=float32)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = bert_clf(x)\n",
    "y.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "MUm-gFCuFkoI",
    "outputId": "4cac9ca3-1080-4307-81a4-d2a7d7618eab"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'8010.245632M'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(torch.cuda.memory_allocated(device)/1000000 ) + 'M'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "KzzsUZOUFcxp",
    "outputId": "fdb38786-4df8-473d-cf45-f635741a868e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'11563.497984M'"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y, x, pooled = None, None, None\n",
    "torch.cuda.empty_cache()\n",
    "str(torch.cuda.memory_allocated(device)/1000000 ) + 'M'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c9LPIYcn99r8"
   },
   "source": [
    "# Fine-tune BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZUkXhM1k_TAl"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train_y.astype(float)\n",
    "test_y = test_y.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "jGwV0yqg_o2u",
    "outputId": "236eae60-f405-4f2b-89be-1164fb924b91"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'438.881792M'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tokens_tensor = torch.tensor(train_tokens_ids)\n",
    "train_y_tensor = torch.tensor(train_y.reshape(-1, 1)).float()\n",
    "\n",
    "test_tokens_tensor = torch.tensor(test_tokens_ids)\n",
    "test_y_tensor = torch.tensor(test_y.reshape(-1, 1)).float()\n",
    "\n",
    "train_masks_tensor = torch.tensor(train_masks)\n",
    "test_masks_tensor = torch.tensor(test_masks)\n",
    "\n",
    "str(torch.cuda.memory_allocated(device)/1000000 ) + 'M'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2Yl2JpCe9YAu"
   },
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(train_tokens_tensor, train_masks_tensor, train_y_tensor)\n",
    "train_sampler = RandomSampler(train_dataset)\n",
    "train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=BATCH_SIZE)\n",
    "\n",
    "test_dataset = TensorDataset(test_tokens_tensor, test_masks_tensor, test_y_tensor)\n",
    "test_sampler = SequentialSampler(test_dataset)\n",
    "test_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JF_QD0naS8EQ"
   },
   "outputs": [],
   "source": [
    "param_optimizer = list(bert_clf.sigmoid.named_parameters()) \n",
    "optimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b28PcoDh_cyd"
   },
   "outputs": [],
   "source": [
    "optimizer = Adam(bert_clf.parameters(), lr=3e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z6yIChYvBP5F"
   },
   "outputs": [],
   "source": [
    " torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "mqh8tCl4AFjo",
    "outputId": "15c746cf-ba17-483a-d0ff-0bcbf9e96431"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  10\n",
      "249/250.0 loss: 0.036980899441521616 \n"
     ]
    }
   ],
   "source": [
    "for epoch_num in range(EPOCHS):\n",
    "    bert_clf.train()\n",
    "    train_loss = 0\n",
    "    for step_num, batch_data in enumerate(train_dataloader):\n",
    "        token_ids, masks, labels = tuple(t.to(device) for t in batch_data)\n",
    "        print(str(torch.cuda.memory_allocated(device)/1000000 ) + 'M')\n",
    "        logits = bert_clf(token_ids, masks)\n",
    "        \n",
    "        loss_func = nn.BCELoss()\n",
    "\n",
    "        batch_loss = loss_func(logits, labels)\n",
    "        train_loss += batch_loss.item()\n",
    "        \n",
    "        \n",
    "        bert_clf.zero_grad()\n",
    "        batch_loss.backward()\n",
    "        \n",
    "\n",
    "        clip_grad_norm_(parameters=bert_clf.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        print('Epoch: ', epoch_num + 1)\n",
    "        print(\"\\r\" + \"{0}/{1} loss: {2} \".format(step_num, len(train_data) / BATCH_SIZE, train_loss / (step_num + 1)))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GHFWhkRYHv5l"
   },
   "outputs": [],
   "source": [
    "bert_clf.eval()\n",
    "bert_predicted = []\n",
    "all_logits = []\n",
    "with torch.no_grad():\n",
    "    for step_num, batch_data in enumerate(test_dataloader):\n",
    "\n",
    "        token_ids, masks, labels = tuple(t.to(device) for t in batch_data)\n",
    "\n",
    "        logits = bert_clf(token_ids, masks)\n",
    "        loss_func = nn.BCELoss()\n",
    "        loss = loss_func(logits, labels)\n",
    "        numpy_logits = logits.cpu().detach().numpy()\n",
    "        \n",
    "        bert_predicted += list(numpy_logits[:, 0] > 0.5)\n",
    "        all_logits += list(numpy_logits[:, 0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "vg_sX9BjooL-",
    "outputId": "2e85f485-c125-4ed6-bb8a-07ed708c54f9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(bert_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "-DmIJqUnkVM8",
    "outputId": "de735d0b-ad04-4d81-ef14-c6394bab92d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.96      0.93        50\n",
      "         1.0       0.96      0.90      0.93        50\n",
      "\n",
      "   micro avg       0.93      0.93      0.93       100\n",
      "   macro avg       0.93      0.93      0.93       100\n",
      "weighted avg       0.93      0.93      0.93       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_y, bert_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bert_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, False, False, True, False, True, True, True, True, False]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_predicted[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9994505,\n",
       " 0.0006819216,\n",
       " 0.00068550307,\n",
       " 0.9993869,\n",
       " 0.0007141872,\n",
       " 0.9995022,\n",
       " 0.9968591,\n",
       " 0.9991862,\n",
       " 0.52991986,\n",
       " 0.0012265648]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_logits[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_data = next(iter(test_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batch_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y,z = tuple(t.to(device) for t in batch_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 512])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 512])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.,  ..., 0., 0., 0.],\n",
       "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
       "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
       "        [1., 1., 1.,  ..., 0., 0., 0.]], device='cuda:0')"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.cuda()\n",
    "y.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = bert_clf(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9.9945e-01],\n",
       "        [6.8192e-04],\n",
       "        [6.8550e-04],\n",
       "        [9.9939e-01]], device='cuda:0', grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BERT without fine tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first we are going to embed each review with BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tensor_masks = torch.tensor(train_masks[:50]).long().to(device)\n",
    "inputs = torch.tensor(train_tokens_ids[:50]).long().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 512])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 512])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making a dataloader outof the first 100 reviews\n",
    "dataset = TensorDataset(inputs, masks)\n",
    "sampler = RandomSampler(dataset)\n",
    "dataloader = DataLoader(dataset, sampler=sampler, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0\n",
      "step: 1\n",
      "step: 2\n",
      "step: 3\n",
      "step: 4\n",
      "step: 5\n",
      "step: 6\n",
      "step: 7\n",
      "step: 8\n",
      "step: 9\n",
      "step: 10\n",
      "step: 11\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-434bdb497432>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mtoken_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;31m#logits = bert_clf(token_ids, masks)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0membeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpooled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0membedded_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mpooled_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpooled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pytorch_pretrained_bert/modeling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, attention_mask, output_all_encoded_layers)\u001b[0m\n\u001b[1;32m    731\u001b[0m         encoded_layers = self.encoder(embedding_output,\n\u001b[1;32m    732\u001b[0m                                       \u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 733\u001b[0;31m                                       output_all_encoded_layers=output_all_encoded_layers)\n\u001b[0m\u001b[1;32m    734\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoded_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m         \u001b[0mpooled_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpooler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pytorch_pretrained_bert/modeling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, output_all_encoded_layers)\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[0mall_encoder_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer_module\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0moutput_all_encoded_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m                 \u001b[0mall_encoder_layers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pytorch_pretrained_bert/modeling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pytorch_pretrained_bert/modeling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_tensor, attention_mask)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m         \u001b[0mself_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pytorch_pretrained_bert/modeling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask)\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;31m# This is actually dropping out entire tokens to attend to, which might\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0;31m# seem a bit unusual, but is taken from the original Transformer paper.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0mattention_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_probs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0mcontext_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/dropout.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m    804\u001b[0m     return (_VF.dropout_(input, p, training)\n\u001b[1;32m    805\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 806\u001b[0;31m             else _VF.dropout(input, p, training))\n\u001b[0m\u001b[1;32m    807\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#this loop is just for embedding the input without training first.\n",
    "# getting the whole 12 layer embedding + also the pooled output for each input\n",
    "embedded_output = []\n",
    "pooled_output = []\n",
    "with torch.no_grad():\n",
    "    for step_num, batch_data in enumerate(dataloader):\n",
    "        print ('step:', step_num)\n",
    "        token_ids, masks = tuple(t.to(device) for t in batch_data)\n",
    "        #logits = bert_clf(token_ids, masks)\n",
    "        embeds, pooled = model(token_ids, masks)\n",
    "        embedded_output.append(embeds)\n",
    "        pooled_output.append(pooled)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "stopped early because I got tired and impatient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#so we got 11 steps through, each of which is a batch of 4\n",
    "len(embedded_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[ 0.0195, -0.1025, -0.1798,  ...,  0.2839, -0.0542, -0.0541],\n",
       "          [-0.6134,  0.0310, -0.0523,  ...,  0.2957,  0.2439,  0.2182],\n",
       "          [-0.7719, -1.4415,  0.0866,  ...,  0.4891,  0.1766,  0.3654],\n",
       "          ...,\n",
       "          [ 0.9035, -0.0795, -0.5768,  ..., -0.0357,  0.5418, -0.5784],\n",
       "          [ 0.9905, -0.2518, -0.0539,  ...,  0.0549,  0.0431, -0.2083],\n",
       "          [ 0.3334, -0.7698, -0.3189,  ...,  0.0770,  0.6037, -1.2794]],\n",
       " \n",
       "         [[ 0.0051, -0.1354, -0.1266,  ...,  0.0908,  0.1125,  0.0419],\n",
       "          [-0.1086, -0.0718, -0.3147,  ...,  0.4675,  0.8267, -0.9194],\n",
       "          [-0.7246,  0.2356, -0.2195,  ...,  0.3732,  0.4304, -0.0977],\n",
       "          ...,\n",
       "          [ 0.6090, -0.1513,  0.1237,  ..., -0.2063, -0.2100, -0.4494],\n",
       "          [ 0.6491, -0.4255,  0.5876,  ...,  0.3462, -0.3546, -0.4542],\n",
       "          [ 0.2439, -0.7559,  0.3585,  ...,  0.6854,  0.2912, -1.2619]],\n",
       " \n",
       "         [[ 0.0432, -0.0272, -0.2169,  ...,  0.2831, -0.0093,  0.0498],\n",
       "          [-0.5014, -0.3557, -0.0099,  ...,  0.4150,  0.6388,  0.4921],\n",
       "          [-1.1461, -1.0614, -0.6659,  ...,  0.7707,  0.3984,  0.8275],\n",
       "          ...,\n",
       "          [ 0.9323, -0.1489, -0.6656,  ...,  0.0650, -0.1399, -0.3991],\n",
       "          [ 1.1139, -0.3820, -0.1291,  ...,  0.1150, -0.0422, -0.7170],\n",
       "          [ 0.4772,  0.4041, -0.0301,  ...,  0.2476,  0.4718, -1.2797]],\n",
       " \n",
       "         [[ 0.0425, -0.0479, -0.1623,  ...,  0.2772, -0.2476, -0.0054],\n",
       "          [-0.1202,  0.3765,  0.0112,  ..., -0.1561,  0.3617, -0.7643],\n",
       "          [ 0.1261, -0.4541, -1.0056,  ...,  0.5987,  1.0524, -0.6163],\n",
       "          ...,\n",
       "          [ 0.7218,  0.0650, -0.7968,  ..., -0.0205,  0.2719, -0.6261],\n",
       "          [-0.1453, -0.3523, -0.1673,  ...,  0.0353, -0.0382, -0.3005],\n",
       "          [ 0.5662, -0.6920,  0.0961,  ...,  0.0305,  0.5650, -1.4891]]]),\n",
       " tensor([[[ 0.0900, -0.4267, -0.1347,  ...,  0.2658, -0.1704, -0.0346],\n",
       "          [-0.7003,  0.0340,  0.4309,  ...,  0.4315,  0.3822,  0.1969],\n",
       "          [-1.0024, -1.2345,  0.0868,  ...,  0.3399,  0.5765,  0.4838],\n",
       "          ...,\n",
       "          [ 1.4838, -0.3760,  0.1778,  ...,  0.1104,  0.8020, -1.1035],\n",
       "          [ 1.5219, -0.4681,  0.9138,  ...,  0.2436,  0.0150, -0.4562],\n",
       "          [ 0.2191, -1.0076,  1.0139,  ...,  0.3351,  0.9243, -2.1556]],\n",
       " \n",
       "         [[-0.1361, -0.1428, -0.4508,  ...,  0.0498,  0.2108, -0.1024],\n",
       "          [-0.1857, -0.0916, -0.0830,  ...,  0.6810,  0.4250, -0.7480],\n",
       "          [-0.6160, -0.0358, -0.1966,  ...,  0.6401,  0.7809,  0.3970],\n",
       "          ...,\n",
       "          [ 0.2749,  0.3429,  0.4297,  ...,  0.3473, -0.3158, -0.5358],\n",
       "          [ 0.7116, -0.4321,  0.9996,  ...,  1.0588, -0.4395, -0.8840],\n",
       "          [-0.0044, -0.7400,  0.9130,  ...,  1.4364,  0.5387, -1.7889]],\n",
       " \n",
       "         [[ 0.0333, -0.4023, -0.2260,  ...,  0.2509,  0.0140, -0.0529],\n",
       "          [-0.8052, -0.5182,  0.1564,  ...,  0.5548,  0.7914,  0.6374],\n",
       "          [-1.2764, -1.2759, -0.2202,  ...,  0.6196,  0.5116,  0.9468],\n",
       "          ...,\n",
       "          [ 1.4189, -0.3167,  0.0308,  ...,  0.1133,  0.1003, -1.2133],\n",
       "          [ 1.3621, -0.5893, -0.0213,  ...,  0.0632,  0.2501, -1.4116],\n",
       "          [ 0.5038,  0.2846,  1.0993,  ...,  0.7682,  0.8648, -2.0445]],\n",
       " \n",
       "         [[ 0.0286, -0.3308, -0.1058,  ...,  0.2601, -0.3195, -0.0851],\n",
       "          [ 0.1138, -0.2103,  0.9326,  ...,  0.2918,  0.4588, -0.8534],\n",
       "          [ 0.5577, -0.6115, -0.4773,  ...,  0.6974,  1.1155, -0.8604],\n",
       "          ...,\n",
       "          [ 0.9887,  0.0351, -0.1742,  ...,  0.0384,  0.3643, -1.0589],\n",
       "          [-0.0320, -0.7522,  0.8016,  ...,  0.0828, -0.1415, -0.8977],\n",
       "          [ 0.7406, -1.3723,  1.2448,  ...,  0.2219,  0.6992, -2.1827]]]),\n",
       " tensor([[[-2.0749e-02, -4.6678e-01, -2.9566e-01,  ...,  2.8975e-01,\n",
       "            1.2287e-02,  2.2725e-02],\n",
       "          [-5.3726e-01, -1.9767e-01,  3.3814e-01,  ...,  3.3655e-01,\n",
       "            3.8741e-01,  4.2756e-01],\n",
       "          [-8.4698e-01, -1.2373e+00,  5.6180e-01,  ...,  1.5638e-01,\n",
       "            4.6133e-01,  6.3545e-01],\n",
       "          ...,\n",
       "          [ 1.1881e+00, -1.3415e-01, -7.2604e-02,  ...,  4.7941e-02,\n",
       "            1.3275e+00, -9.8535e-01],\n",
       "          [ 1.4282e+00, -6.9138e-02,  7.3917e-01,  ...,  2.3784e-01,\n",
       "            3.8899e-01, -3.5260e-01],\n",
       "          [ 6.8462e-02, -8.2472e-01,  6.4824e-01,  ...,  3.9105e-01,\n",
       "            6.2740e-01, -2.2204e+00]],\n",
       " \n",
       "         [[-8.1436e-02, -2.5628e-01, -3.2287e-01,  ...,  2.1704e-01,\n",
       "            1.9498e-01,  1.9166e-02],\n",
       "          [-3.6977e-01, -2.5672e-01,  7.8082e-02,  ...,  7.2783e-01,\n",
       "            6.6501e-01, -6.9851e-01],\n",
       "          [-8.5223e-01,  3.9162e-01, -2.3713e-01,  ...,  2.5150e-01,\n",
       "            8.3730e-01,  2.3023e-01],\n",
       "          ...,\n",
       "          [-1.6394e-03,  2.6505e-01,  3.9795e-01,  ...,  4.4864e-01,\n",
       "           -2.3998e-01, -7.3921e-01],\n",
       "          [ 6.3241e-01, -4.1704e-01,  1.2144e+00,  ...,  1.1489e+00,\n",
       "           -2.0641e-01, -1.2135e+00],\n",
       "          [-1.8983e-01, -7.9789e-01,  8.3109e-01,  ...,  1.1753e+00,\n",
       "            1.9362e-01, -2.0701e+00]],\n",
       " \n",
       "         [[ 1.1936e-01, -4.2072e-01, -2.6186e-01,  ...,  2.3730e-01,\n",
       "            2.7979e-01,  5.9184e-02],\n",
       "          [-7.0400e-01, -8.2867e-01,  1.1352e-01,  ...,  4.8490e-01,\n",
       "            5.8800e-01,  6.1129e-01],\n",
       "          [-1.4186e+00, -1.1049e+00, -3.1742e-01,  ...,  3.8197e-01,\n",
       "            1.5275e-01,  9.0247e-01],\n",
       "          ...,\n",
       "          [ 1.4999e+00, -5.7438e-01, -2.9780e-01,  ..., -1.1252e-01,\n",
       "            7.5802e-01, -1.8052e+00],\n",
       "          [ 1.1624e+00, -3.3113e-01, -2.2848e-01,  ...,  1.6772e-01,\n",
       "            7.1673e-01, -1.6580e+00],\n",
       "          [ 4.0603e-01,  1.5012e-01,  9.4514e-01,  ...,  7.4847e-01,\n",
       "            8.6221e-01, -1.9391e+00]],\n",
       " \n",
       "         [[ 1.0729e-01, -3.3180e-01, -1.3486e-01,  ...,  2.3003e-01,\n",
       "           -4.6481e-02, -1.8213e-01],\n",
       "          [ 3.9701e-01,  1.2574e-01,  1.1039e+00,  ..., -1.8998e-02,\n",
       "           -6.1761e-02, -1.0848e+00],\n",
       "          [ 6.3921e-01, -4.8098e-01, -2.2456e-01,  ...,  4.7039e-01,\n",
       "            1.4337e+00, -1.0551e+00],\n",
       "          ...,\n",
       "          [ 7.7921e-01,  5.0887e-01, -6.1454e-01,  ..., -3.0932e-01,\n",
       "            1.1419e+00, -1.2952e+00],\n",
       "          [-6.1703e-02, -4.7561e-01,  8.2466e-01,  ..., -2.6741e-02,\n",
       "            5.7255e-01, -1.1202e+00],\n",
       "          [ 8.4423e-01, -1.3480e+00,  9.6469e-01,  ...,  1.7386e-01,\n",
       "            8.2004e-01, -2.2379e+00]]]),\n",
       " tensor([[[ 0.0487, -0.9979, -0.5769,  ...,  0.1419, -0.0470,  0.2855],\n",
       "          [-0.2565, -0.3173, -0.2009,  ...,  0.6410,  0.2511,  0.5440],\n",
       "          [-0.5586, -1.4150, -0.0962,  ...,  0.4253,  0.3945,  0.9194],\n",
       "          ...,\n",
       "          [ 1.1573,  0.1297, -0.1380,  ...,  0.5005,  0.8713, -0.7211],\n",
       "          [ 1.4701, -0.0822,  0.5363,  ...,  0.8948,  0.4408, -0.1808],\n",
       "          [ 0.1393, -0.4421,  0.9577,  ...,  1.3318,  0.4489, -1.9613]],\n",
       " \n",
       "         [[-0.0669, -0.6084, -0.6221,  ..., -0.1270,  0.0967,  0.0196],\n",
       "          [-0.4926, -0.3846, -0.1677,  ...,  0.7481,  0.7582, -1.0796],\n",
       "          [-0.7495,  0.3512,  0.0637,  ...,  0.1109,  0.8483,  0.8085],\n",
       "          ...,\n",
       "          [-0.0449,  0.1056,  0.3699,  ...,  0.6632,  0.0528, -1.0461],\n",
       "          [ 0.6586, -0.3923,  1.5308,  ...,  1.1088,  0.2982, -1.5156],\n",
       "          [ 0.0901, -0.3940,  1.4858,  ...,  1.2276,  0.2230, -1.9034]],\n",
       " \n",
       "         [[ 0.0239, -0.8965, -0.4402,  ..., -0.0576,  0.0523,  0.5218],\n",
       "          [-0.4749, -0.9497, -0.1241,  ...,  0.5677, -0.0251,  0.4348],\n",
       "          [-1.5715, -1.6439, -0.6410,  ...,  0.2872,  0.3498,  1.0270],\n",
       "          ...,\n",
       "          [ 1.5145, -0.2535, -0.1777,  ...,  0.2544,  0.4558, -1.8483],\n",
       "          [ 0.9297, -0.1543,  0.1509,  ...,  0.4949,  0.6380, -1.7434],\n",
       "          [ 0.5825,  0.4878,  1.1066,  ...,  1.4081,  0.6501, -1.6602]],\n",
       " \n",
       "         [[ 0.1090, -0.8978, -0.4573,  ..., -0.0775, -0.0751,  0.3512],\n",
       "          [ 0.9993, -0.0937,  0.8489,  ...,  0.2665, -0.0385, -0.9704],\n",
       "          [ 0.9940, -0.1602, -0.3371,  ...,  0.2815,  0.8428, -0.9534],\n",
       "          ...,\n",
       "          [ 0.7480,  0.6575, -0.1950,  ...,  0.2768,  0.8935, -1.1404],\n",
       "          [-0.2161, -0.2050,  1.1000,  ...,  0.6480,  0.4881, -0.8431],\n",
       "          [ 0.8027, -0.7829,  1.6416,  ...,  0.3160,  0.6345, -2.2484]]]),\n",
       " tensor([[[-9.0496e-02, -1.0457e+00, -2.3265e-01,  ...,  5.8994e-01,\n",
       "            2.1491e-01,  4.7683e-01],\n",
       "          [-1.8691e-02,  2.0224e-01, -8.9249e-03,  ...,  2.9543e-01,\n",
       "            6.8511e-01,  7.1151e-01],\n",
       "          [-2.8563e-01, -1.0817e+00,  1.0559e-02,  ..., -8.3686e-02,\n",
       "            6.0446e-01,  1.1399e+00],\n",
       "          ...,\n",
       "          [ 1.2510e+00,  1.7054e-01, -1.4536e-01,  ...,  3.9888e-01,\n",
       "            6.7745e-01, -8.7647e-01],\n",
       "          [ 1.5934e+00,  2.0318e-01,  1.7301e-01,  ...,  6.6644e-01,\n",
       "            3.9991e-01, -2.4892e-01],\n",
       "          [ 5.6697e-01,  5.9241e-01,  1.0393e+00,  ...,  1.2240e+00,\n",
       "            2.1939e-01, -1.6690e+00]],\n",
       " \n",
       "         [[-5.1626e-02, -7.4073e-01, -2.7911e-01,  ..., -1.8489e-03,\n",
       "            3.3789e-01,  2.5568e-01],\n",
       "          [-2.8899e-01, -7.0577e-01, -2.4219e-01,  ...,  8.0609e-01,\n",
       "            9.9005e-01, -3.8963e-01],\n",
       "          [-5.9686e-01,  7.6050e-01,  2.2790e-01,  ...,  5.9692e-02,\n",
       "            7.9519e-01,  9.3405e-01],\n",
       "          ...,\n",
       "          [ 1.7830e-01,  5.4763e-01,  8.8917e-01,  ...,  3.6500e-01,\n",
       "           -4.4122e-01, -1.2847e+00],\n",
       "          [ 5.6038e-01, -2.1067e-02,  1.7819e+00,  ...,  1.1159e+00,\n",
       "            6.5154e-02, -1.8051e+00],\n",
       "          [ 3.4062e-01,  8.1890e-03,  1.5226e+00,  ...,  1.0893e+00,\n",
       "            5.1093e-01, -1.4690e+00]],\n",
       " \n",
       "         [[-1.6757e-01, -1.1602e+00, -1.2680e-01,  ...,  4.8275e-01,\n",
       "            1.4181e-01,  7.0224e-01],\n",
       "          [-4.9595e-01, -2.4838e-01,  2.0866e-01,  ...,  5.2893e-01,\n",
       "            5.3634e-01,  7.3424e-01],\n",
       "          [-1.5660e+00, -1.2098e+00, -1.3549e-01,  ...,  4.4223e-01,\n",
       "            4.1178e-01,  9.7062e-01],\n",
       "          ...,\n",
       "          [ 1.2516e+00,  4.0469e-01, -9.2542e-02,  ...,  2.8369e-01,\n",
       "            5.4998e-01, -1.7621e+00],\n",
       "          [ 8.9442e-01,  1.4079e-01,  3.3507e-01,  ...,  4.5838e-01,\n",
       "            6.7704e-01, -1.7361e+00],\n",
       "          [ 6.1609e-01,  1.1658e+00,  1.0724e+00,  ...,  1.1494e+00,\n",
       "            3.7544e-01, -1.7121e+00]],\n",
       " \n",
       "         [[-1.8179e-01, -1.0293e+00, -8.0063e-03,  ...,  2.6359e-01,\n",
       "            9.2023e-02,  5.2844e-01],\n",
       "          [ 1.0200e+00, -1.1223e-01,  8.8570e-01,  ...,  1.6107e-01,\n",
       "            4.5862e-01, -5.4988e-01],\n",
       "          [ 9.0295e-01, -5.1283e-02, -5.3914e-01,  ..., -1.3466e-01,\n",
       "            1.1392e+00, -7.3543e-01],\n",
       "          ...,\n",
       "          [ 8.9465e-01,  1.3050e+00, -6.2019e-02,  ...,  3.8534e-01,\n",
       "            7.8723e-01, -9.4055e-01],\n",
       "          [ 2.8504e-01,  3.3640e-01,  6.7442e-01,  ...,  6.7197e-01,\n",
       "            5.0114e-01, -9.2237e-01],\n",
       "          [ 9.6533e-01, -3.2313e-02,  1.6743e+00,  ...,  7.1479e-01,\n",
       "            4.0930e-01, -1.9640e+00]]]),\n",
       " tensor([[[-1.7407e-01, -1.0328e+00, -2.8122e-02,  ...,  5.5871e-01,\n",
       "            2.8763e-04,  2.4891e-01],\n",
       "          [ 1.9928e-01,  4.9263e-01, -3.9888e-01,  ..., -6.7142e-02,\n",
       "            6.3874e-01,  9.4818e-01],\n",
       "          [-3.0137e-01, -6.8314e-01,  3.1842e-01,  ..., -8.1516e-01,\n",
       "            5.1137e-01,  1.7284e+00],\n",
       "          ...,\n",
       "          [ 8.6168e-01,  3.9920e-01,  4.9492e-01,  ...,  6.4627e-02,\n",
       "            4.3501e-01, -1.0241e+00],\n",
       "          [ 1.2499e+00,  1.9233e-01,  3.7443e-01,  ...,  2.7946e-01,\n",
       "            2.5934e-01, -4.6907e-01],\n",
       "          [ 4.3300e-02,  7.5065e-01,  1.1139e+00,  ...,  6.4775e-01,\n",
       "            2.2378e-01, -1.5880e+00]],\n",
       " \n",
       "         [[-1.3799e-01, -8.5019e-01, -3.3709e-01,  ...,  9.9654e-02,\n",
       "            6.1500e-01,  6.1401e-01],\n",
       "          [-3.8430e-01, -3.1104e-01, -2.2228e-01,  ...,  5.7819e-01,\n",
       "            1.3385e+00, -3.9112e-01],\n",
       "          [-6.4129e-01,  8.0944e-01, -6.3547e-02,  ...,  1.2066e-01,\n",
       "            7.3570e-01,  1.3111e+00],\n",
       "          ...,\n",
       "          [-1.8711e-01,  2.7574e-01,  1.1843e+00,  ..., -5.3153e-01,\n",
       "           -3.8303e-01, -1.1981e+00],\n",
       "          [ 1.4681e-01, -2.7911e-01,  1.5472e+00,  ...,  4.2113e-01,\n",
       "            6.1087e-01, -1.9911e+00],\n",
       "          [ 2.8024e-01, -1.1341e-02,  1.2969e+00,  ...,  8.6651e-01,\n",
       "            5.7109e-01, -1.6064e+00]],\n",
       " \n",
       "         [[-4.7641e-01, -1.3391e+00, -4.8229e-02,  ...,  4.1897e-01,\n",
       "            2.0645e-01,  4.0645e-01],\n",
       "          [-5.0745e-01, -1.5994e-01, -3.0328e-01,  ..., -1.1585e-01,\n",
       "            8.1544e-01,  1.1700e+00],\n",
       "          [-1.2708e+00, -1.2956e+00,  1.4966e-01,  ..., -4.2113e-02,\n",
       "            4.7209e-01,  1.6251e+00],\n",
       "          ...,\n",
       "          [ 7.3967e-01,  6.3349e-01,  3.7781e-02,  ...,  1.1086e-01,\n",
       "            3.7428e-01, -2.0059e+00],\n",
       "          [ 4.9367e-01,  2.1952e-01,  5.1962e-01,  ...,  3.3739e-01,\n",
       "            3.2106e-01, -2.0344e+00],\n",
       "          [ 1.8941e-01,  1.1181e+00,  1.2667e+00,  ...,  9.2506e-01,\n",
       "            4.3317e-01, -1.8759e+00]],\n",
       " \n",
       "         [[-1.0205e-01, -1.2001e+00,  1.1412e-01,  ...,  1.8370e-01,\n",
       "            1.4071e-01,  4.1854e-01],\n",
       "          [ 1.0528e+00,  1.3281e-01,  1.0218e+00,  ...,  3.4711e-01,\n",
       "            4.2409e-01,  3.2205e-02],\n",
       "          [ 9.0386e-01,  3.5653e-01, -6.0323e-01,  ..., -6.5152e-01,\n",
       "            1.3891e+00, -8.9281e-01],\n",
       "          ...,\n",
       "          [ 5.7929e-01,  1.3260e+00,  1.5814e-01,  ...,  4.6486e-02,\n",
       "            7.2609e-01, -1.2667e+00],\n",
       "          [-9.6424e-02,  4.8899e-01,  6.3051e-01,  ...,  2.3296e-02,\n",
       "            1.8204e-01, -1.1990e+00],\n",
       "          [ 4.3957e-01,  3.0358e-01,  1.6874e+00,  ...,  1.7309e-01,\n",
       "            3.0971e-01, -1.9178e+00]]]),\n",
       " tensor([[[-0.2286, -0.7158,  0.2705,  ...,  0.4732,  0.0325,  0.4215],\n",
       "          [-0.2047,  0.8208, -0.1258,  ..., -0.1430,  0.5009,  0.6308],\n",
       "          [-0.3583, -0.3373,  0.2285,  ..., -0.6924,  0.9924,  1.5775],\n",
       "          ...,\n",
       "          [ 1.0834,  0.9948,  0.5882,  ...,  0.0803,  0.2736, -1.3007],\n",
       "          [ 1.3425,  0.6046,  0.4912,  ..., -0.0566,  0.6276, -0.7269],\n",
       "          [-0.0887,  1.1675,  0.6772,  ...,  0.3586,  0.1896, -2.0960]],\n",
       " \n",
       "         [[-0.2203, -0.3564, -0.2100,  ..., -0.0070,  0.5197,  0.7174],\n",
       "          [-0.5431, -0.1719,  0.0381,  ...,  0.5635,  0.9060, -0.4759],\n",
       "          [-0.6714,  0.9405,  0.4533,  ...,  0.2937,  0.9022,  1.0908],\n",
       "          ...,\n",
       "          [-0.3400,  0.7847,  0.8824,  ..., -1.1303, -0.5075, -0.2755],\n",
       "          [-0.0637, -0.3401,  1.1419,  ..., -0.2220,  0.3015, -1.8808],\n",
       "          [ 0.2905,  0.0059,  1.1817,  ..., -0.2080,  0.2684, -1.6558]],\n",
       " \n",
       "         [[-0.7472, -0.4677,  0.0669,  ...,  0.4259,  0.1969,  0.2716],\n",
       "          [-0.7905, -0.0164, -0.3660,  ..., -0.1188,  0.7912,  0.7352],\n",
       "          [-1.2780, -0.5066,  0.1508,  ..., -0.0726,  0.9160,  1.5733],\n",
       "          ...,\n",
       "          [ 0.8748,  0.9976, -0.0986,  ..., -0.0988,  0.3680, -2.2320],\n",
       "          [ 0.5111,  0.6534,  0.2192,  ...,  0.2855,  0.4248, -2.2019],\n",
       "          [ 0.1445,  1.2773,  0.5557,  ...,  0.3919,  0.4086, -2.3268]],\n",
       " \n",
       "         [[-0.2296, -1.1501,  0.5642,  ...,  0.1427,  0.1918,  0.2844],\n",
       "          [ 1.3878,  0.6972,  1.2239,  ...,  0.0981,  0.8686,  0.2606],\n",
       "          [ 0.6724,  0.4880, -0.3033,  ..., -0.4844,  1.3160, -1.0704],\n",
       "          ...,\n",
       "          [ 0.6614,  1.7233, -0.0469,  ..., -0.1989,  0.6258, -1.3655],\n",
       "          [-0.0147,  0.8103,  0.3724,  ...,  0.1334,  0.2597, -1.3381],\n",
       "          [ 0.3940,  0.4993,  1.0360,  ..., -0.1318,  0.1685, -1.9058]]]),\n",
       " tensor([[[-0.2260, -0.6056,  0.1411,  ...,  0.1660, -0.0319,  0.2079],\n",
       "          [-0.0467,  0.4818, -0.2655,  ...,  0.0745,  0.7291,  0.7260],\n",
       "          [-0.5616, -0.2901,  0.0120,  ..., -0.1000,  0.6028,  1.5917],\n",
       "          ...,\n",
       "          [ 0.8369,  0.6036,  0.7965,  ...,  0.1529,  0.0185, -1.4201],\n",
       "          [ 1.0794,  0.3520,  0.6536,  ..., -0.2365,  0.5022, -0.7834],\n",
       "          [-0.1199,  1.2152,  0.3349,  ...,  0.1563, -0.2852, -1.9034]],\n",
       " \n",
       "         [[-0.3572, -0.0412, -0.4313,  ..., -0.2371,  0.7254,  0.4328],\n",
       "          [-0.5148,  0.3743, -0.4758,  ...,  0.6158,  0.7538,  0.1728],\n",
       "          [-0.6813,  1.0414,  0.4491,  ...,  0.2227,  0.7628,  0.9848],\n",
       "          ...,\n",
       "          [-0.1386,  0.8918,  0.7693,  ..., -1.4150, -0.7556,  0.5623],\n",
       "          [-0.4467, -0.2333,  0.5587,  ..., -0.1140,  0.1253, -1.6955],\n",
       "          [ 0.3017,  0.2376,  0.5016,  ..., -0.5166,  0.3233, -1.3851]],\n",
       " \n",
       "         [[-0.5332, -0.4792,  0.1020,  ...,  0.5290,  0.3080,  0.1622],\n",
       "          [-0.4583, -0.6659, -1.0166,  ..., -0.0314,  1.0153,  0.5609],\n",
       "          [-0.8708, -0.6054, -0.5123,  ...,  0.3446,  0.9352,  1.4675],\n",
       "          ...,\n",
       "          [ 0.6422,  0.8177, -0.0766,  ..., -0.2780,  0.0660, -2.2327],\n",
       "          [-0.0548,  0.3760,  0.1386,  ...,  0.3530,  0.2462, -2.1186],\n",
       "          [ 0.0227,  1.1847,  0.3513,  ...,  0.3541,  0.1461, -2.1800]],\n",
       " \n",
       "         [[-0.2365, -1.0048,  0.2309,  ...,  0.0914,  0.2549,  0.0171],\n",
       "          [ 1.1442,  0.5949,  1.1784,  ..., -0.4956,  1.1562,  0.2000],\n",
       "          [ 0.5709,  0.2757, -0.2069,  ..., -0.4698,  1.3683, -1.0710],\n",
       "          ...,\n",
       "          [ 0.4950,  1.5730,  0.1362,  ..., -0.0093,  0.2873, -1.3220],\n",
       "          [-0.2473,  0.7701,  0.1868,  ...,  0.5275, -0.2105, -1.3521],\n",
       "          [ 0.0984,  0.4854,  0.5398,  ..., -0.1431, -0.0435, -1.8034]]]),\n",
       " tensor([[[-0.2033, -0.6441,  0.1355,  ...,  0.2248,  0.0065, -0.1443],\n",
       "          [-0.5196,  0.3838,  0.5323,  ...,  0.6351,  0.8075,  0.2991],\n",
       "          [-0.5717, -0.3526, -0.1256,  ...,  0.6977,  0.6200,  1.3981],\n",
       "          ...,\n",
       "          [ 0.5109,  0.3744,  0.9621,  ..., -0.4265,  0.1048, -1.4355],\n",
       "          [ 0.9839, -0.1240,  0.6972,  ..., -0.6667,  0.4972, -0.7256],\n",
       "          [ 0.0764,  1.0087,  0.4182,  ..., -0.2379, -0.4768, -1.9363]],\n",
       " \n",
       "         [[-1.3698, -0.2251, -0.1589,  ...,  0.3670,  1.1063,  0.1169],\n",
       "          [-1.1457,  0.7779,  0.2428,  ...,  0.6104,  0.9327,  0.2184],\n",
       "          [-0.6972,  0.5280,  0.5676,  ...,  0.1652,  0.9895,  1.0809],\n",
       "          ...,\n",
       "          [-0.3370,  0.7721,  1.0870,  ..., -1.0010, -1.0831, -0.1514],\n",
       "          [-0.3710, -0.5630,  0.6007,  ..., -0.2984, -0.2416, -1.9947],\n",
       "          [-0.0022, -0.0575,  0.7283,  ..., -0.4692,  0.1136, -1.9780]],\n",
       " \n",
       "         [[-0.4421, -0.3901, -0.0824,  ...,  0.4121,  0.3933, -0.0352],\n",
       "          [-0.5830, -1.1984, -0.5151,  ..., -0.4005,  1.4605,  0.1201],\n",
       "          [-1.0290, -0.9140, -0.5098,  ...,  0.2363,  1.5536,  0.9805],\n",
       "          ...,\n",
       "          [ 0.3827,  0.6423, -0.0355,  ..., -0.3117,  0.0224, -2.1244],\n",
       "          [-0.6251,  0.0324,  0.2245,  ..., -0.0081,  0.3889, -2.1009],\n",
       "          [ 0.0902,  0.8999,  0.3494,  ...,  0.0857, -0.0827, -2.1063]],\n",
       " \n",
       "         [[-0.3902, -0.7097,  0.1955,  ...,  0.2525,  0.2767, -0.3438],\n",
       "          [ 0.8017,  0.4893,  1.2327,  ..., -0.8000,  1.4654,  0.0129],\n",
       "          [ 0.4646,  0.0487, -0.7477,  ..., -0.0499,  1.0241, -1.6732],\n",
       "          ...,\n",
       "          [ 0.4111,  1.3693,  0.1914,  ..., -0.3340,  0.2336, -1.3719],\n",
       "          [-0.4538,  0.5629,  0.1582,  ...,  0.1100, -0.1011, -1.3653],\n",
       "          [ 0.2539,  0.4863,  0.4373,  ..., -0.8309, -0.0145, -1.8215]]]),\n",
       " tensor([[[-5.6148e-01, -7.1904e-01,  4.6536e-01,  ..., -1.9087e-01,\n",
       "            2.5339e-01, -4.4946e-01],\n",
       "          [-6.1928e-01,  3.2082e-01,  1.7319e-01,  ..., -1.1323e-03,\n",
       "            5.9923e-01, -2.0500e-01],\n",
       "          [-7.5368e-01, -3.3971e-01,  3.6845e-01,  ...,  3.9594e-01,\n",
       "            4.5078e-01,  6.8139e-01],\n",
       "          ...,\n",
       "          [ 3.8212e-01,  4.9217e-01,  8.8901e-01,  ..., -5.9617e-01,\n",
       "           -1.9089e-01, -1.8671e+00],\n",
       "          [ 8.6794e-01,  1.0258e-01,  6.2385e-01,  ..., -7.7939e-01,\n",
       "            1.0148e-01, -8.0823e-01],\n",
       "          [ 5.6300e-02,  8.5516e-01,  3.8994e-01,  ..., -3.8223e-01,\n",
       "           -7.1678e-01, -2.7190e+00]],\n",
       " \n",
       "         [[-1.9607e+00, -4.0160e-01,  6.5021e-02,  ...,  4.8649e-01,\n",
       "            1.1764e+00,  1.8963e-01],\n",
       "          [-1.0302e+00,  6.9750e-01,  7.8111e-01,  ...,  3.8040e-01,\n",
       "            9.8080e-01, -4.4289e-02],\n",
       "          [-1.2171e+00,  4.5203e-01,  5.2840e-01,  ...,  2.3002e-02,\n",
       "            4.5804e-01,  1.2465e+00],\n",
       "          ...,\n",
       "          [-2.3239e-01,  3.9292e-01,  1.0562e+00,  ..., -8.6952e-01,\n",
       "           -5.9823e-01, -1.2105e-01],\n",
       "          [-7.4353e-01, -5.9900e-01,  6.8354e-01,  ..., -2.7116e-01,\n",
       "           -9.6911e-02, -1.8594e+00],\n",
       "          [-3.2826e-01,  7.5647e-02,  1.0005e+00,  ..., -3.5257e-01,\n",
       "            2.9810e-01, -1.8467e+00]],\n",
       " \n",
       "         [[-7.3762e-01, -8.5678e-01,  1.8362e-01,  ..., -1.4987e-01,\n",
       "            6.2172e-01, -2.7001e-01],\n",
       "          [-8.2310e-01, -1.5577e+00, -5.6663e-01,  ..., -1.1930e+00,\n",
       "            1.7614e+00, -5.2580e-01],\n",
       "          [-1.3519e+00, -1.0665e+00, -1.3147e-02,  ..., -3.0736e-01,\n",
       "            1.2045e+00,  5.5114e-01],\n",
       "          ...,\n",
       "          [ 3.1962e-01,  3.6901e-01,  1.1630e-01,  ..., -4.7984e-01,\n",
       "           -2.3055e-01, -2.6365e+00],\n",
       "          [-4.1510e-01,  1.9792e-03,  2.9583e-01,  ..., -4.1238e-01,\n",
       "           -1.7987e-02, -2.6779e+00],\n",
       "          [ 1.8873e-01,  9.5311e-01,  5.1012e-01,  ..., -1.8327e-01,\n",
       "            5.9876e-03, -2.5040e+00]],\n",
       " \n",
       "         [[-6.4385e-01, -1.3149e+00,  6.2325e-01,  ..., -2.0736e-01,\n",
       "            7.7626e-01, -3.8995e-01],\n",
       "          [ 8.0089e-01, -2.5817e-02,  1.6847e+00,  ..., -7.0720e-01,\n",
       "            1.5461e+00, -3.2960e-01],\n",
       "          [ 1.1694e-01, -3.9024e-01, -5.4836e-01,  ..., -1.4934e-01,\n",
       "            1.0484e+00, -1.8246e+00],\n",
       "          ...,\n",
       "          [ 4.7158e-01,  1.5599e+00,  4.7419e-02,  ..., -4.3673e-01,\n",
       "            2.6238e-01, -1.9770e+00],\n",
       "          [-3.4721e-01,  5.0926e-01,  2.2186e-01,  ..., -1.3011e-01,\n",
       "           -2.8449e-01, -1.8927e+00],\n",
       "          [ 1.5730e-01,  5.6647e-01,  5.4619e-01,  ..., -1.0900e+00,\n",
       "           -2.4896e-01, -2.2375e+00]]]),\n",
       " tensor([[[-0.2537, -0.3346,  0.3552,  ..., -0.1028,  0.0752, -0.0222],\n",
       "          [-0.6070,  0.2053,  0.1099,  ..., -0.6121,  0.3485,  0.3231],\n",
       "          [-0.9276, -1.0350,  0.2784,  ...,  0.6535,  0.4231,  1.4474],\n",
       "          ...,\n",
       "          [ 0.7331,  1.1346,  0.9898,  ..., -0.5561, -0.4994, -1.8632],\n",
       "          [ 0.9936,  0.5325,  0.6770,  ..., -0.7995, -0.0990, -0.7607],\n",
       "          [ 0.3748,  1.4964,  0.8079,  ..., -0.4817, -0.8620, -2.7197]],\n",
       " \n",
       "         [[-1.5876,  0.0585,  0.0100,  ...,  0.7222,  0.8419,  0.5269],\n",
       "          [-1.0785,  0.9703,  0.4505,  ...,  0.8032,  0.6783,  0.0214],\n",
       "          [-0.7077,  0.6484,  0.4001,  ...,  0.5008, -0.0169,  1.6611],\n",
       "          ...,\n",
       "          [-0.2270,  0.7387,  1.0118,  ..., -0.3312, -0.3592, -0.0888],\n",
       "          [-0.8033, -0.2232,  1.0368,  ..., -0.1313,  0.2402, -1.2966],\n",
       "          [-0.4048,  0.6265,  1.3313,  ...,  0.0424,  0.5239, -1.5739]],\n",
       " \n",
       "         [[-0.3314, -0.5637,  0.5129,  ..., -0.2806,  0.7850,  0.0727],\n",
       "          [-0.0787, -1.5062, -0.0782,  ..., -0.6957,  1.7255,  0.4647],\n",
       "          [-1.1096, -0.7575,  0.4197,  ..., -0.3366,  0.8388,  1.2864],\n",
       "          ...,\n",
       "          [ 0.5337,  0.8304,  0.1786,  ..., -0.3600, -0.3607, -2.7282],\n",
       "          [-0.2087,  0.5557,  0.4197,  ..., -0.3598, -0.3727, -2.6827],\n",
       "          [ 0.5077,  1.5009,  0.7055,  ..., -0.3218, -0.2840, -2.6276]],\n",
       " \n",
       "         [[-0.5456, -0.9073,  0.6328,  ..., -0.3681,  0.5679,  0.0795],\n",
       "          [ 0.8801,  0.2529,  1.4527,  ..., -0.5596,  1.2984,  0.1489],\n",
       "          [ 0.1814, -0.4571, -0.8010,  ..., -0.1719,  0.8700, -1.0781],\n",
       "          ...,\n",
       "          [ 0.7596,  1.7061,  0.2118,  ..., -0.4754,  0.0290, -2.0177],\n",
       "          [ 0.0846,  0.8424,  0.3218,  ..., -0.2525, -0.4446, -1.9021],\n",
       "          [ 0.5879,  0.8959,  0.4375,  ..., -1.0215, -0.4158, -2.2857]]]),\n",
       " tensor([[[-0.3197,  0.0934,  0.0889,  ...,  0.0972,  0.8729, -0.6124],\n",
       "          [-0.4706,  0.1316,  0.0668,  ..., -0.5188,  0.4779,  0.1656],\n",
       "          [-0.5445, -0.5114,  0.2942,  ...,  0.2115,  0.0493,  0.4135],\n",
       "          ...,\n",
       "          [ 0.3734,  0.7922,  0.4432,  ..., -0.5941, -0.3962, -1.3385],\n",
       "          [ 0.7346,  0.4303,  0.3500,  ..., -0.5156,  0.1739, -1.0665],\n",
       "          [ 0.2053,  0.8461,  0.2671,  ..., -0.7701, -0.3519, -1.6761]],\n",
       " \n",
       "         [[-1.2355,  0.2370,  0.1777,  ...,  0.5765,  0.7536,  0.5262],\n",
       "          [-0.7631,  0.1336,  0.1085,  ...,  0.4801,  0.7898, -0.0360],\n",
       "          [-0.6505,  0.2527,  0.2956,  ...,  0.1500, -0.2190,  1.0051],\n",
       "          ...,\n",
       "          [-0.1220,  0.4618,  0.7904,  ..., -0.1765,  0.1683,  0.0495],\n",
       "          [-0.3344, -0.0049,  0.4038,  ..., -0.0151,  0.3978, -0.5223],\n",
       "          [-0.1384,  0.1556,  0.3634,  ...,  0.1394,  0.6511, -0.5178]],\n",
       " \n",
       "         [[ 0.2022, -0.3184,  0.1753,  ...,  0.2226,  0.8097, -0.5447],\n",
       "          [ 0.0246, -0.8697, -0.1025,  ..., -0.5082,  1.3349,  0.3334],\n",
       "          [-0.4685, -0.6788,  0.4902,  ...,  0.1674,  0.3700,  0.9485],\n",
       "          ...,\n",
       "          [ 0.4666,  0.4340,  0.0633,  ..., -0.2460, -0.2530, -1.6283],\n",
       "          [ 0.1443,  0.3288,  0.2295,  ..., -0.6145, -0.3138, -1.7636],\n",
       "          [ 0.3399,  0.9376,  0.3288,  ..., -0.6707,  0.1528, -1.7936]],\n",
       " \n",
       "         [[-0.4454, -0.4686,  0.4588,  ..., -0.1468,  0.9275, -0.7896],\n",
       "          [ 0.5824,  0.2134,  1.2182,  ..., -0.2144,  0.9312,  0.2462],\n",
       "          [-0.0237, -0.2358, -0.4066,  ..., -0.1145,  0.5323, -0.5404],\n",
       "          ...,\n",
       "          [ 0.4129,  0.9084, -0.0444,  ..., -0.6554,  0.0362, -1.6586],\n",
       "          [ 0.2475,  0.4868,  0.1481,  ..., -0.5151,  0.1076, -1.3847],\n",
       "          [ 0.3620,  0.5650,  0.1289,  ..., -0.9522,  0.0769, -1.5356]]])]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the first batch\n",
    "embedded_output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the first line in the output is is a list with 12 items\n",
    "len(embedded_output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 512, 768])\n",
      "torch.Size([4, 512, 768])\n",
      "torch.Size([4, 512, 768])\n",
      "torch.Size([4, 512, 768])\n",
      "torch.Size([4, 512, 768])\n",
      "torch.Size([4, 512, 768])\n",
      "torch.Size([4, 512, 768])\n",
      "torch.Size([4, 512, 768])\n",
      "torch.Size([4, 512, 768])\n",
      "torch.Size([4, 512, 768])\n",
      "torch.Size([4, 512, 768])\n",
      "torch.Size([4, 512, 768])\n"
     ]
    }
   ],
   "source": [
    "for out in embedded_output[0]:\n",
    "    print (out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so each item in the embedded output list, contains a list of 12 layers\n",
    "within in item in this list is 4 examples from the batch\n",
    "so the first item in each of these layers is from one input in the batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([512, 768]), torch.Size([512, 768]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this will be the 11th layer for inputs 1 and 2 of this batch\n",
    "embedded_output[0][11][0].shape, embedded_output[0][11][1].shape,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "res=embedded_output[0][11][0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((512, 768), numpy.ndarray)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.shape, type(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pooled_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.7482,  0.3478,  0.8021,  ...,  0.4991,  0.4105, -0.5332],\n",
       "        [ 0.3405, -0.3445, -0.8764,  ..., -0.6117, -0.4320,  0.1388],\n",
       "        [ 0.8870,  0.6238,  0.9685,  ...,  0.8919,  0.7436, -0.6107],\n",
       "        [ 0.8353,  0.4483,  0.8908,  ...,  0.7918,  0.6251, -0.7177]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#each item in the pooled output is tensor, where each output corresponds in the pooled result of an input\n",
    "pooled_output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 768])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pooled_output[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([768])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pooled_output[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is going to be an ugly way to turn my pooled layers back into a single input tensor\n",
    "pooled_inputs = []\n",
    "for item in pooled_output:\n",
    "    for pool in item:\n",
    "        pooled_inputs.append(pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#and same for the embeddings, as well\n",
    "embedded_inputs = []\n",
    "for item in embedded_output:\n",
    "    for mat in item[11]:\n",
    "        embedded_inputs.append(mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embedded_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 768])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_inputs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([768])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pooled_inputs[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the problem with this is that I don't have labels to train with so I'm going to redo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokens_tensor = torch.tensor(train_tokens_ids).long().to(device)\n",
    "train_y_tensor = torch.tensor(train_y.reshape(-1, 1)).float()\n",
    "\n",
    "test_tokens_tensor = torch.tensor(test_tokens_ids).long().to(device)\n",
    "test_y_tensor = torch.tensor(test_y.reshape(-1, 1)).float()\n",
    "\n",
    "train_masks_tensor = torch.tensor(train_masks).long().to(device)\n",
    "test_masks_tensor = torch.tensor(test_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(train_tokens_tensor[:50], train_masks_tensor[:50], train_y_tensor[:50])\n",
    "#train_sampler = RandomSampler(train_dataset)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=4)\n",
    "\n",
    "test_dataset = TensorDataset(test_tokens_tensor[-10:], test_masks_tensor[-10:], test_y_tensor[:10])\n",
    "#test_sampler = SequentialSampler(test_dataset)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0\n",
      "step: 1\n",
      "step: 2\n",
      "step: 3\n",
      "step: 4\n",
      "step: 5\n",
      "step: 6\n",
      "step: 7\n",
      "step: 8\n",
      "step: 9\n",
      "step: 10\n",
      "step: 11\n",
      "step: 12\n"
     ]
    }
   ],
   "source": [
    "#this loop is just for embedding the input without training first.\n",
    "# getting the whole 12 layer embedding + also the pooled output for each input\n",
    "embedded_output = []\n",
    "pooled_output = []\n",
    "with torch.no_grad():\n",
    "    for step_num, batch_data in enumerate(train_dataloader):\n",
    "        print ('step:', step_num)\n",
    "        token_ids, masks, _ = tuple(t.to(device) for t in batch_data)\n",
    "        #logits = bert_clf(token_ids, masks)\n",
    "        embeds, pooled = model(token_ids, masks)\n",
    "        embedded_output.append(embeds)\n",
    "        pooled_output.append(pooled)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is going to be an ugly way to turn my pooled layers back into a single input tensor\n",
    "pooled_inputs = []\n",
    "for item in pooled_output:\n",
    "    for pool in item:\n",
    "        pooled_inputs.append(pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#and same for the embeddings, as well\n",
    "embedded_inputs = []\n",
    "for item in embedded_output:\n",
    "    for mat in item[11]:\n",
    "        embedded_inputs.append(mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 50)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pooled_inputs), len(embedded_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([768]), torch.Size([512, 768]))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pooled_inputs[0].shape, embedded_inputs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertLinearClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        self.linear = nn.Linear(768, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, inpute):\n",
    "        linear_output = self.linear(inpute)\n",
    "        proba = self.sigmoid(linear_output)\n",
    "        return proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch_num in range(EPOCHS):\n",
    "    bert_clf.train()\n",
    "    train_loss = 0\n",
    "    for step_num, batch_data in enumerate(train_dataloader):\n",
    "        token_ids, masks, labels = tuple(t.to(device) for t in batch_data)\n",
    "        print(str(torch.cuda.memory_allocated(device)/1000000 ) + 'M')\n",
    "        logits = bert_clf(token_ids, masks)\n",
    "        \n",
    "        loss_func = nn.BCELoss()\n",
    "\n",
    "        batch_loss = loss_func(logits, labels)\n",
    "        train_loss += batch_loss.item()\n",
    "        \n",
    "        \n",
    "        bert_clf.zero_grad()\n",
    "        batch_loss.backward()\n",
    "        \n",
    "\n",
    "        clip_grad_norm_(parameters=bert_clf.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        print('Epoch: ', epoch_num + 1)\n",
    "        print(\"\\r\" + \"{0}/{1} loss: {2} \".format(step_num, len(train_data) / BATCH_SIZE, train_loss / (step_num + 1)))\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "BERT to the rescue.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
