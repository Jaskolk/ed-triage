{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "7_FXneEfpdMM",
    "outputId": "ff8057f1-23dc-49b8-b11c-f68823bf6f90"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytorch_pretrained_bert in /usr/local/lib/python3.6/site-packages (0.6.2)\n",
      "Requirement already satisfied: pytorch-nlp in /usr/local/lib/python3.6/site-packages (0.4.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/site-packages (from pytorch_pretrained_bert) (1.15.4)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.6/site-packages (from pytorch_pretrained_bert) (2019.8.19)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/site-packages (from pytorch_pretrained_bert) (2.21.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/site-packages (from pytorch_pretrained_bert) (4.31.1)\n",
      "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/site-packages (from pytorch_pretrained_bert) (1.0.1.post2)\n",
      "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/site-packages (from pytorch_pretrained_bert) (1.9.237)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.6/site-packages (from pytorch-nlp) (0.23.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/site-packages (from requests->pytorch_pretrained_bert) (2019.3.9)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/site-packages (from requests->pytorch_pretrained_bert) (2.8)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/site-packages (from requests->pytorch_pretrained_bert) (1.24.2)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/site-packages (from requests->pytorch_pretrained_bert) (3.0.4)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/site-packages (from boto3->pytorch_pretrained_bert) (0.9.4)\n",
      "Requirement already satisfied: botocore<1.13.0,>=1.12.237 in /usr/local/lib/python3.6/site-packages (from boto3->pytorch_pretrained_bert) (1.12.237)\n",
      "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/site-packages (from boto3->pytorch_pretrained_bert) (0.2.1)\n",
      "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/site-packages (from pandas->pytorch-nlp) (2018.7)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/site-packages (from pandas->pytorch-nlp) (2.7.5)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/site-packages (from botocore<1.13.0,>=1.12.237->boto3->pytorch_pretrained_bert) (0.15.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/site-packages (from python-dateutil>=2.5.0->pandas->pytorch-nlp) (1.12.0)\n",
      "\u001b[31mmenpo 0.8.1 has requirement matplotlib<2.0,>=1.4, but you'll have matplotlib 3.0.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mmenpo 0.8.1 has requirement pillow<5.0,>=3.0, but you'll have pillow 5.4.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mmenpo 0.8.1 has requirement scipy<1.0,>=0.16, but you'll have scipy 1.2.0 which is incompatible.\u001b[0m\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.2.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch_pretrained_bert pytorch-nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "EnVIV6Vt8f4d",
    "outputId": "3c8e3d88-13b0-4652-973d-3fa2c023e48e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import random as rn\n",
    "import torch\n",
    "from pytorch_pretrained_bert import BertModel\n",
    "from torch import nn\n",
    "from torchnlp.datasets import imdb_dataset\n",
    "from pytorch_pretrained_bert import BertTokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from torch.optim import Adam\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cUYrv06z8gaF"
   },
   "outputs": [],
   "source": [
    "rn.seed(321)\n",
    "np.random.seed(321)\n",
    "torch.manual_seed(321)\n",
    "torch.cuda.manual_seed(321)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rgkbhHcB17GY"
   },
   "source": [
    "## Prepare the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ur8i7boP6qtb"
   },
   "outputs": [],
   "source": [
    "train_data, test_data = imdb_dataset(train=True, test=True)\n",
    "rn.shuffle(train_data)\n",
    "rn.shuffle(test_data)\n",
    "train_data = train_data[:1000]\n",
    "test_data = test_data[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "l1VENo6tqG7J",
    "outputId": "5f10799f-d17d-42fd-a4c2-c760b61f7ed8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1000, 100, 100)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_texts, train_labels = list(zip(*map(lambda d: (d['text'], d['sentiment']), train_data)))\n",
    "test_texts, test_labels = list(zip(*map(lambda d: (d['text'], d['sentiment']), test_data)))\n",
    "\n",
    "len(train_texts), len(train_labels), len(test_texts), len(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ty24UrRjqIsb"
   },
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "1k9rcOzQr5Zm",
    "outputId": "b9b59a4e-57bd-4e9c-fcd1-2a4ba1fadc0e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 100)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tokens = list(map(lambda t: ['[CLS]'] + tokenizer.tokenize(t)[:510] + ['[SEP]'], train_texts))\n",
    "test_tokens = list(map(lambda t: ['[CLS]'] + tokenizer.tokenize(t)[:510] + ['[SEP]'], test_texts))\n",
    "\n",
    "len(train_tokens), len(test_tokens)                   \n",
    "                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "9Ca7KKnhuT5c",
    "outputId": "69ba3b87-4d86-448b-c9cb-7be8361182f6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 512), (100, 512))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tokens_ids = pad_sequences(list(map(tokenizer.convert_tokens_to_ids, train_tokens)), maxlen=512, truncating=\"post\", padding=\"post\", dtype=\"int\")\n",
    "test_tokens_ids = pad_sequences(list(map(tokenizer.convert_tokens_to_ids, test_tokens)), maxlen=512, truncating=\"post\", padding=\"post\", dtype=\"int\")\n",
    "\n",
    "train_tokens_ids.shape, test_tokens_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "F7POtHuIOV-6",
    "outputId": "a5447340-6da3-4f2c-d284-098c4c906c47"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000,), (100,), 0.489, 0.5)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y = np.array(train_labels) == 'pos'\n",
    "test_y = np.array(test_labels) == 'pos'\n",
    "train_y.shape, test_y.shape, np.mean(train_y), np.mean(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U-xXMEqXOWTE"
   },
   "outputs": [],
   "source": [
    "train_masks = [[float(i > 0) for i in ii] for ii in train_tokens_ids]\n",
    "test_masks = [[float(i > 0) for i in ii] for ii in test_tokens_ids]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT outside the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = torch.tensor(train_masks[:1]).long().to(device)\n",
    "x = torch.tensor(train_tokens_ids[:1]).long().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    y,pool = model(x,m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512, 768])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([1, 512, 768])\n",
      "torch.Size([1, 512, 768])\n"
     ]
    }
   ],
   "source": [
    "for item in y:\n",
    "    print (item.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of layers: 12\n",
      "Number of batches: 1\n",
      "Number of tokens: 512\n",
      "Number of hidden units: 768\n"
     ]
    }
   ],
   "source": [
    "print (\"Number of layers:\", len(y))\n",
    "layer_i = 0\n",
    "\n",
    "print (\"Number of batches:\", len(y[layer_i]))\n",
    "batch_i = 0\n",
    "\n",
    "print (\"Number of tokens:\", len(y[layer_i][batch_i]))\n",
    "token_i = 0\n",
    "\n",
    "print (\"Number of hidden units:\", len(y[layer_i][batch_i][token_i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# For the 5th token in our sentence, select its feature values from layer 5.\n",
    "token_i = 5\n",
    "layer_i = 5\n",
    "vec = y[layer_i][batch_i][token_i].cpu()\n",
    "\n",
    "# Plot the values as a histogram to show their distribution.\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.hist(vec, bins=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens in sequence: 328\n",
      "Number of layers per token: 12\n",
      "length of sentence: 328\n"
     ]
    }
   ],
   "source": [
    "tokenized_text = train_tokens[0]\n",
    "# Convert the hidden state embeddings into single token vectors\n",
    "\n",
    "# Holds the list of 12 layer embeddings for each token\n",
    "# Will have the shape: [# tokens, # layers, # features]\n",
    "token_embeddings = [] \n",
    "\n",
    "# For each token in the sentence...\n",
    "for token_i in range(len(tokenized_text)):\n",
    "  \n",
    "  # Holds 12 layers of hidden states for each token \n",
    "    hidden_layers = [] \n",
    "  \n",
    "  # For each of the 12 layers...\n",
    "    for layer_i in range(len(y)):\n",
    "    \n",
    "        # Lookup the vector for `token_i` in `layer_i`\n",
    "        vec = y[layer_i][batch_i][token_i]\n",
    "    \n",
    "        hidden_layers.append(vec)\n",
    "    \n",
    "    token_embeddings.append(hidden_layers)\n",
    "\n",
    "# Sanity check the dimensions:\n",
    "print (\"Number of tokens in sequence:\", len(token_embeddings))\n",
    "print (\"Number of layers per token:\", len(token_embeddings[0]))\n",
    "print (\"length of sentence:\", len(tokenized_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, torch.Size([768]))"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(token_embeddings[0][0]), token_embeddings[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_last_4_layers = [torch.cat((layer[-1], layer[-2], layer[-3], layer[-4]), 0) for layer in token_embeddings] # [number_of_tokens, 3072]\n",
    "\n",
    "summed_last_4_layers = [torch.sum(torch.stack(layer)[-4:], 0) for layer in token_embeddings] # [number_of_tokens, 768]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(328, 3072)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(concatenated_last_4_layers), len(concatenated_last_4_layers[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3072"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "768*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(328, 768)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(summed_last_4_layers), len(summed_last_4_layers[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512, 768])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[11].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_embedding = torch.mean(y[11], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our final sentence embedding vector of shape:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, 768)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (\"Our final sentence embedding vector of shape:\"), sentence_embedding[0].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so basically, the entire sentence is embedded by taking the 11th layer of the output\n",
    "and averaging the 768 long vector for each token into a single 768 element vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [CLS]\n",
      "1 i\n",
      "2 loved\n",
      "3 the\n",
      "4 story\n",
      "5 .\n",
      "6 somewhere\n",
      "7 ,\n",
      "8 a\n",
      "9 poster\n",
      "10 said\n",
      "11 there\n",
      "12 are\n",
      "13 no\n",
      "14 families\n",
      "15 like\n",
      "16 the\n",
      "17 one\n",
      "18 portrayed\n",
      "19 in\n",
      "20 this\n",
      "21 film\n",
      "22 .\n",
      "23 well\n",
      "24 maybe\n",
      "25 there\n",
      "26 ought\n",
      "27 to\n",
      "28 be\n",
      "29 .\n",
      "30 i\n",
      "31 thought\n",
      "32 everybody\n",
      "33 seemed\n",
      "34 really\n",
      "35 human\n",
      "36 and\n",
      "37 bel\n",
      "38 ##ie\n",
      "39 ##vable\n",
      "40 .\n",
      "41 what\n",
      "42 a\n",
      "43 top\n",
      "44 notch\n",
      "45 cast\n",
      "46 .\n",
      "47 what\n",
      "48 great\n",
      "49 music\n",
      "50 on\n",
      "51 the\n",
      "52 soundtrack\n",
      "53 .\n",
      "54 what\n",
      "55 a\n",
      "56 nice\n",
      "57 this\n",
      "58 ,\n",
      "59 and\n",
      "60 what\n",
      "61 a\n",
      "62 nice\n",
      "63 that\n",
      "64 ,\n",
      "65 but\n",
      "66 most\n",
      "67 of\n",
      "68 all\n",
      "69 ,\n",
      "70 i\n",
      "71 will\n",
      "72 say\n",
      "73 two\n",
      "74 words\n",
      "75 to\n",
      "76 recommend\n",
      "77 this\n",
      "78 film\n",
      "79 .\n",
      "80 <\n",
      "81 br\n",
      "82 /\n",
      "83 >\n",
      "84 <\n",
      "85 br\n",
      "86 /\n",
      "87 >\n",
      "88 steve\n",
      "89 care\n",
      "90 ##ll\n",
      "91 .\n",
      "92 <\n",
      "93 br\n",
      "94 /\n",
      "95 >\n",
      "96 <\n",
      "97 br\n",
      "98 /\n",
      "99 >\n",
      "100 he\n",
      "101 really\n",
      "102 showed\n",
      "103 a\n",
      "104 nice\n",
      "105 ,\n",
      "106 subtle\n",
      "107 depth\n",
      "108 that\n",
      "109 touched\n",
      "110 me\n",
      "111 .\n",
      "112 he\n",
      "113 was\n",
      "114 truly\n",
      "115 commanding\n",
      "116 as\n",
      "117 a\n",
      "118 widow\n",
      "119 ##er\n",
      "120 who\n",
      "121 had\n",
      "122 dedicated\n",
      "123 himself\n",
      "124 maybe\n",
      "125 a\n",
      "126 little\n",
      "127 too\n",
      "128 much\n",
      "129 to\n",
      "130 being\n",
      "131 a\n",
      "132 good\n",
      "133 dad\n",
      "134 first\n",
      "135 ,\n",
      "136 at\n",
      "137 the\n",
      "138 cost\n",
      "139 of\n",
      "140 denying\n",
      "141 his\n",
      "142 own\n",
      "143 needs\n",
      "144 .\n",
      "145 <\n",
      "146 br\n",
      "147 /\n",
      "148 >\n",
      "149 <\n",
      "150 br\n",
      "151 /\n",
      "152 >\n",
      "153 did\n",
      "154 he\n",
      "155 act\n",
      "156 like\n",
      "157 a\n",
      "158 pet\n",
      "159 ##ula\n",
      "160 ##nt\n",
      "161 ass\n",
      "162 ?\n",
      "163 why\n",
      "164 ,\n",
      "165 yes\n",
      "166 he\n",
      "167 did\n",
      "168 .\n",
      "169 <\n",
      "170 br\n",
      "171 /\n",
      "172 >\n",
      "173 <\n",
      "174 br\n",
      "175 /\n",
      "176 >\n",
      "177 and\n",
      "178 you\n",
      "179 see\n",
      "180 ,\n",
      "181 that\n",
      "182 '\n",
      "183 s\n",
      "184 what\n",
      "185 was\n",
      "186 perfect\n",
      "187 about\n",
      "188 this\n",
      "189 film\n",
      "190 .\n",
      "191 the\n",
      "192 actor\n",
      "193 who\n",
      "194 played\n",
      "195 this\n",
      "196 character\n",
      "197 made\n",
      "198 me\n",
      "199 believe\n",
      "200 he\n",
      "201 was\n",
      "202 feeling\n",
      "203 something\n",
      "204 ,\n",
      "205 and\n",
      "206 not\n",
      "207 simply\n",
      "208 acting\n",
      "209 like\n",
      "210 he\n",
      "211 was\n",
      "212 feeling\n",
      "213 something\n",
      "214 ,\n",
      "215 and\n",
      "216 he\n",
      "217 conveyed\n",
      "218 to\n",
      "219 me\n",
      "220 perfectly\n",
      "221 what\n",
      "222 it\n",
      "223 was\n",
      "224 that\n",
      "225 he\n",
      "226 was\n",
      "227 feeling\n",
      "228 ,\n",
      "229 and\n",
      "230 what\n",
      "231 he\n",
      "232 was\n",
      "233 feeling\n",
      "234 was\n",
      "235 denied\n",
      "236 .\n",
      "237 <\n",
      "238 br\n",
      "239 /\n",
      "240 >\n",
      "241 <\n",
      "242 br\n",
      "243 /\n",
      "244 >\n",
      "245 denied\n",
      "246 happiness\n",
      "247 .\n",
      "248 <\n",
      "249 br\n",
      "250 /\n",
      "251 >\n",
      "252 <\n",
      "253 br\n",
      "254 /\n",
      "255 >\n",
      "256 denied\n",
      "257 fulfillment\n",
      "258 .\n",
      "259 <\n",
      "260 br\n",
      "261 /\n",
      "262 >\n",
      "263 <\n",
      "264 br\n",
      "265 /\n",
      "266 >\n",
      "267 denied\n",
      "268 love\n",
      "269 .\n",
      "270 <\n",
      "271 br\n",
      "272 /\n",
      "273 >\n",
      "274 <\n",
      "275 br\n",
      "276 /\n",
      "277 >\n",
      "278 losing\n",
      "279 your\n",
      "280 love\n",
      "281 is\n",
      "282 painful\n",
      "283 beyond\n",
      "284 belief\n",
      "285 ,\n",
      "286 and\n",
      "287 many\n",
      "288 who\n",
      "289 do\n",
      "290 so\n",
      "291 will\n",
      "292 never\n",
      "293 feel\n",
      "294 something\n",
      "295 like\n",
      "296 that\n",
      "297 again\n",
      "298 .\n",
      "299 <\n",
      "300 br\n",
      "301 /\n",
      "302 >\n",
      "303 <\n",
      "304 br\n",
      "305 /\n",
      "306 >\n",
      "307 beautiful\n",
      "308 film\n",
      "309 .\n",
      "310 <\n",
      "311 br\n",
      "312 /\n",
      "313 >\n",
      "314 <\n",
      "315 br\n",
      "316 /\n",
      "317 >\n",
      "318 i\n",
      "319 gave\n",
      "320 it\n",
      "321 an\n",
      "322 eight\n",
      "323 out\n",
      "324 of\n",
      "325 ten\n",
      "326 .\n",
      "327 [SEP]\n"
     ]
    }
   ],
   "source": [
    "for i,x in enumerate(tokenized_text):\n",
    "    print (i,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First fifteen values of 'truly':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 1.2784, -1.1363,  7.1270, -0.7993,  2.7548,  1.6524,  4.2326, -1.4705,\n",
       "         1.9733, -0.1732,  1.5759, -3.4783, -1.3119, -1.6201,  4.0390],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (\"First fifteen values of 'truly':\")\n",
    "summed_last_4_layers[114][:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r_hEhebQ3YqI"
   },
   "source": [
    "# Bert Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E234ByBa3Qtb"
   },
   "outputs": [],
   "source": [
    "class BertBinaryClassifier(nn.Module):\n",
    "    def __init__(self, dropout=0.1):\n",
    "        super(BertBinaryClassifier, self).__init__()\n",
    "\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(768, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, tokens, masks=None):\n",
    "        _, pooled_output = self.bert(tokens, attention_mask=masks, output_all_encoded_layers=False)\n",
    "        dropout_output = self.dropout(pooled_output)\n",
    "        linear_output = self.linear(dropout_output)\n",
    "        proba = self.sigmoid(linear_output)\n",
    "        return proba\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ED9SE1Ka8W9x",
    "outputId": "ab8b549b-137b-491a-cf6f-f20718dd73ff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "FNZ_3auqDbjl",
    "outputId": "1c20ee58-abb4-4bf2-f79a-851ab54c31eb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'438.881792M'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(torch.cuda.memory_allocated(device)/1000000 ) + 'M'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Sf9n8zouENRi"
   },
   "outputs": [],
   "source": [
    "bert_clf = BertBinaryClassifier()\n",
    "bert_clf = bert_clf.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "LbHkaJuZEkYr",
    "outputId": "dff4b8e7-db91-46de-8b8c-bf0cddccaba9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'438.881792M'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(torch.cuda.memory_allocated(device)/1000000 ) + 'M'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "LOQ-870M7VWy",
    "outputId": "f7c010bf-eb70-413f-96db-c0eb14769cfa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 512]), torch.Size([3, 512, 768]), torch.Size([3, 768]))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor(train_tokens_ids[:3]).to(device)\n",
    "y, pooled = bert_clf.bert(x, output_all_encoded_layers=False)\n",
    "x.shape, y.shape, pooled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "LCb_pK4X7hb9",
    "outputId": "77237549-1b51-4d51-a11e-84e53fa82cb3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.480183  ],\n",
       "       [0.4748414 ],\n",
       "       [0.40391952]], dtype=float32)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = bert_clf(x)\n",
    "y.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "MUm-gFCuFkoI",
    "outputId": "4cac9ca3-1080-4307-81a4-d2a7d7618eab"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'8010.245632M'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(torch.cuda.memory_allocated(device)/1000000 ) + 'M'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "KzzsUZOUFcxp",
    "outputId": "fdb38786-4df8-473d-cf45-f635741a868e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'11563.497984M'"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y, x, pooled = None, None, None\n",
    "torch.cuda.empty_cache()\n",
    "str(torch.cuda.memory_allocated(device)/1000000 ) + 'M'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c9LPIYcn99r8"
   },
   "source": [
    "# Fine-tune BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZUkXhM1k_TAl"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train_y.astype(float)\n",
    "test_y = test_y.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "jGwV0yqg_o2u",
    "outputId": "236eae60-f405-4f2b-89be-1164fb924b91"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'438.881792M'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tokens_tensor = torch.tensor(train_tokens_ids)\n",
    "train_y_tensor = torch.tensor(train_y.reshape(-1, 1)).float()\n",
    "\n",
    "test_tokens_tensor = torch.tensor(test_tokens_ids)\n",
    "test_y_tensor = torch.tensor(test_y.reshape(-1, 1)).float()\n",
    "\n",
    "train_masks_tensor = torch.tensor(train_masks)\n",
    "test_masks_tensor = torch.tensor(test_masks)\n",
    "\n",
    "str(torch.cuda.memory_allocated(device)/1000000 ) + 'M'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2Yl2JpCe9YAu"
   },
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(train_tokens_tensor, train_masks_tensor, train_y_tensor)\n",
    "train_sampler = RandomSampler(train_dataset)\n",
    "train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=BATCH_SIZE)\n",
    "\n",
    "test_dataset = TensorDataset(test_tokens_tensor, test_masks_tensor, test_y_tensor)\n",
    "test_sampler = SequentialSampler(test_dataset)\n",
    "test_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JF_QD0naS8EQ"
   },
   "outputs": [],
   "source": [
    "param_optimizer = list(bert_clf.sigmoid.named_parameters()) \n",
    "optimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b28PcoDh_cyd"
   },
   "outputs": [],
   "source": [
    "optimizer = Adam(bert_clf.parameters(), lr=3e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z6yIChYvBP5F"
   },
   "outputs": [],
   "source": [
    " torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "mqh8tCl4AFjo",
    "outputId": "15c746cf-ba17-483a-d0ff-0bcbf9e96431"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  10\n",
      "249/250.0 loss: 0.036980899441521616 \n"
     ]
    }
   ],
   "source": [
    "for epoch_num in range(EPOCHS):\n",
    "    bert_clf.train()\n",
    "    train_loss = 0\n",
    "    for step_num, batch_data in enumerate(train_dataloader):\n",
    "        token_ids, masks, labels = tuple(t.to(device) for t in batch_data)\n",
    "        print(str(torch.cuda.memory_allocated(device)/1000000 ) + 'M')\n",
    "        logits = bert_clf(token_ids, masks)\n",
    "        \n",
    "        loss_func = nn.BCELoss()\n",
    "\n",
    "        batch_loss = loss_func(logits, labels)\n",
    "        train_loss += batch_loss.item()\n",
    "        \n",
    "        \n",
    "        bert_clf.zero_grad()\n",
    "        batch_loss.backward()\n",
    "        \n",
    "\n",
    "        clip_grad_norm_(parameters=bert_clf.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        print('Epoch: ', epoch_num + 1)\n",
    "        print(\"\\r\" + \"{0}/{1} loss: {2} \".format(step_num, len(train_data) / BATCH_SIZE, train_loss / (step_num + 1)))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GHFWhkRYHv5l"
   },
   "outputs": [],
   "source": [
    "bert_clf.eval()\n",
    "bert_predicted = []\n",
    "all_logits = []\n",
    "with torch.no_grad():\n",
    "    for step_num, batch_data in enumerate(test_dataloader):\n",
    "\n",
    "        token_ids, masks, labels = tuple(t.to(device) for t in batch_data)\n",
    "\n",
    "        logits = bert_clf(token_ids, masks)\n",
    "        loss_func = nn.BCELoss()\n",
    "        loss = loss_func(logits, labels)\n",
    "        numpy_logits = logits.cpu().detach().numpy()\n",
    "        \n",
    "        bert_predicted += list(numpy_logits[:, 0] > 0.5)\n",
    "        all_logits += list(numpy_logits[:, 0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "vg_sX9BjooL-",
    "outputId": "2e85f485-c125-4ed6-bb8a-07ed708c54f9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(bert_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "-DmIJqUnkVM8",
    "outputId": "de735d0b-ad04-4d81-ef14-c6394bab92d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.96      0.93        50\n",
      "         1.0       0.96      0.90      0.93        50\n",
      "\n",
      "   micro avg       0.93      0.93      0.93       100\n",
      "   macro avg       0.93      0.93      0.93       100\n",
      "weighted avg       0.93      0.93      0.93       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_y, bert_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bert_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, False, False, True, False, True, True, True, True, False]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_predicted[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9994505,\n",
       " 0.0006819216,\n",
       " 0.00068550307,\n",
       " 0.9993869,\n",
       " 0.0007141872,\n",
       " 0.9995022,\n",
       " 0.9968591,\n",
       " 0.9991862,\n",
       " 0.52991986,\n",
       " 0.0012265648]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_logits[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_data = next(iter(test_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batch_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y,z = tuple(t.to(device) for t in batch_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 512])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 512])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.,  ..., 0., 0., 0.],\n",
       "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
       "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
       "        [1., 1., 1.,  ..., 0., 0., 0.]], device='cuda:0')"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.cuda()\n",
    "y.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = bert_clf(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9.9945e-01],\n",
       "        [6.8192e-04],\n",
       "        [6.8550e-04],\n",
       "        [9.9939e-01]], device='cuda:0', grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "BERT to the rescue.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
