{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is a step by step walk through a Pytorch implementation of a gated convolutional neural network (GCNN) from Dauphin et al.'s 2017 paper. I use the wikitext-2 dataset.\n",
    "### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting conda\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/4e/c533c3136427be62c38cc0e038cabf167bb54489c2ced2f6df903c456861/conda-4.3.16.tar.gz (299kB)\n",
      "\u001b[K    100% |████████████████████████████████| 307kB 28.6MB/s \n",
      "\u001b[?25hCollecting pycosat>=0.6.1 (from conda)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c0/fd/e38d68774c0a345b0090d608a90f1fbf423970d812f7ec7aef9ac024e648/pycosat-0.6.3.zip (66kB)\n",
      "\u001b[K    100% |████████████████████████████████| 71kB 23.7MB/s \n",
      "\u001b[?25hRequirement already satisfied: requests>=2.12.4 in /usr/local/lib/python3.6/site-packages (from conda) (2.21.0)\n",
      "Collecting ruamel.yaml>=0.11.14 (from conda)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fa/90/ecff85a2e9c497e2fa7142496e10233556b5137db5bd46f3f3b006935ca8/ruamel.yaml-0.16.5-py2.py3-none-any.whl (123kB)\n",
      "\u001b[K    100% |████████████████████████████████| 133kB 27.6MB/s \n",
      "\u001b[?25hRequirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/site-packages (from requests>=2.12.4->conda) (1.24.2)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/site-packages (from requests>=2.12.4->conda) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/site-packages (from requests>=2.12.4->conda) (2019.3.9)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/site-packages (from requests>=2.12.4->conda) (2.8)\n",
      "Collecting ruamel.yaml.clib>=0.1.2; platform_python_implementation == \"CPython\" and python_version < \"3.8\" (from ruamel.yaml>=0.11.14->conda)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/53/77/4bcd63f362bcb6c8f4f06253c11f9772f64189bf08cf3f40c5ccbda9e561/ruamel.yaml.clib-0.2.0-cp36-cp36m-manylinux1_x86_64.whl (548kB)\n",
      "\u001b[K    100% |████████████████████████████████| 552kB 22.7MB/s \n",
      "\u001b[?25hBuilding wheels for collected packages: conda, pycosat\n",
      "  Running setup.py bdist_wheel for conda ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/a3/50/79/302742d53e2231ec545cb3791abfdd24de234021ed8e0588a0\n",
      "  Running setup.py bdist_wheel for pycosat ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/c4/67/ff/5570304e45814eccef48a3c69c3af25d0456ed3a34eddbbe38\n",
      "Successfully built conda pycosat\n",
      "\u001b[31mmenpo 0.8.1 has requirement matplotlib<2.0,>=1.4, but you'll have matplotlib 3.0.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mmenpo 0.8.1 has requirement pillow<5.0,>=3.0, but you'll have pillow 5.4.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mmenpo 0.8.1 has requirement scipy<1.0,>=0.16, but you'll have scipy 1.2.0 which is incompatible.\u001b[0m\n",
      "Installing collected packages: pycosat, ruamel.yaml.clib, ruamel.yaml, conda\n",
      "Successfully installed conda-4.3.16 pycosat-0.6.3 ruamel.yaml-0.16.5 ruamel.yaml.clib-0.2.0\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.2.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "ERROR: The install method you used for conda--probably either `pip install conda`\n",
      "or `easy_install conda`--is not compatible with using conda as an application.\n",
      "If your intention is to install conda as a standalone application, currently\n",
      "supported install methods include the Anaconda installer and the miniconda\n",
      "installer.  You can download the miniconda installer from\n",
      "https://conda.io/miniconda.html.\n",
      "\n",
      "ERROR: The install method you used for conda--probably either `pip install conda`\n",
      "or `easy_install conda`--is not compatible with using conda as an application.\n",
      "If your intention is to install conda as a standalone application, currently\n",
      "supported install methods include the Anaconda installer and the miniconda\n",
      "installer.  You can download the miniconda installer from\n",
      "https://conda.io/miniconda.html.\n",
      "\n",
      "ERROR: The install method you used for conda--probably either `pip install conda`\n",
      "or `easy_install conda`--is not compatible with using conda as an application.\n",
      "If your intention is to install conda as a standalone application, currently\n",
      "supported install methods include the Anaconda installer and the miniconda\n",
      "installer.  You can download the miniconda installer from\n",
      "https://conda.io/miniconda.html.\n",
      "\n",
      "ERROR: The install method you used for conda--probably either `pip install conda`\n",
      "or `easy_install conda`--is not compatible with using conda as an application.\n",
      "If your intention is to install conda as a standalone application, currently\n",
      "supported install methods include the Anaconda installer and the miniconda\n",
      "installer.  You can download the miniconda installer from\n",
      "https://conda.io/miniconda.html.\n",
      "\n",
      "ERROR: The install method you used for conda--probably either `pip install conda`\n",
      "or `easy_install conda`--is not compatible with using conda as an application.\n",
      "If your intention is to install conda as a standalone application, currently\n",
      "supported install methods include the Anaconda installer and the miniconda\n",
      "installer.  You can download the miniconda installer from\n",
      "https://conda.io/miniconda.html.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Install pytorch and fastai (see https://docs.fast.ai/)\n",
    "!conda update conda --yes\n",
    "!conda install -c pytorch pytorch-nightly cuda90 --yes\n",
    "!conda install -c fastai torchvision-nightly --yes\n",
    "!conda install -c fastai fastai --yes\n",
    "!conda install -c anaconda jupyter unzip cython cupy seaborn --yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.text import * \n",
    "\n",
    "import torch.utils.data as data_utils\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data.sampler import Sampler\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import time\n",
    "import importlib\n",
    "import seaborn as sns\n",
    "\n",
    "from GCNN_textfuncs import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATAPATH = Path('/floyd/home/ed-triage/data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set() #set graph formatting to seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download wikitext-2 dataset and GloVe embeddings\n",
    "#!wget https://s3.amazonaws.com/fast-ai-nlp/wikitext-2.tgz -P /data\n",
    "#!tar xzf /data/wikitext-2.tgz -C /data\n",
    "#!mv /data/wikitext-2/ /data/GCNN/\n",
    "#!wget http://nlp.stanford.edu/data/glove.6B.zip -P /data/GCNN/\n",
    "#!unzip /data/GCNN/glove.6B.zip -d /data/GCNN/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do some preprocessing of the data:\n",
    "\n",
    "#put data into df's w/ columns for 'labels' and 'text'\n",
    "df_trn = pd.read_csv(DATAPATH/'train.csv',header=None,names=['text'])\n",
    "df_test = pd.read_csv(DATAPATH/'test.csv',header=None,names=['text'])\n",
    "df_trn['labels']=0\n",
    "df_test['labels']=0\n",
    "df_trn=df_trn[['labels','text']]\n",
    "df_test=df_test[['labels','text']]\n",
    "\n",
    "#split data into paragraphs, then remove paragraphs <10 or >300 words\n",
    "trn_paragraphs=[]\n",
    "for docnum in range(len(df_trn)):\n",
    "    trn_paragraphs.extend([x for x in df_trn.iloc[docnum].text.split('\\n')])\n",
    "trn_paragraphs.sort(key=len)\n",
    "trn_paragraphs=[par for par in trn_paragraphs if (len(par.split(' '))<300 and len(par.split(' '))>10)]#remove paragraphs >300 and <10 words\n",
    "trn_paragraphs=[par+'xxeos ' for par in trn_paragraphs] #add EOS token at end of each paragraph\n",
    "\n",
    "test_paragraphs=[]\n",
    "for docnum in range(len(df_test)):\n",
    "    test_paragraphs.extend([x for x in df_test.iloc[docnum].text.split('\\n')])\n",
    "test_paragraphs.sort(key=len)\n",
    "test_paragraphs=[par for par in test_paragraphs if (len(par.split(' '))<300 and len(par.split(' '))>10)]#remove paragraphs >300 and <10 words\n",
    "test_paragraphs=[par+'xxeos ' for par in test_paragraphs] #add EOS token at end of each paragraph\n",
    "\n",
    "#put data into csv's\n",
    "df_trn_par = pd.DataFrame({'text':trn_paragraphs})\n",
    "df_test_par = pd.DataFrame({'text':test_paragraphs})\n",
    "\n",
    "df_trn_par['labels']=0\n",
    "df_test_par['labels']=0\n",
    "df_trn_par=df_trn_par[['labels','text']]\n",
    "df_test_par=df_test_par[['labels','text']]\n",
    "\n",
    "df_trn_par.to_csv(DATAPATH/'train_proc_par2.csv', header=False, index=False)\n",
    "df_test_par.to_csv(DATAPATH/'test_proc_par2.csv', header=False, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create modeler class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class modeler():\n",
    "    def __init__(self,trn_dl,val_dl,module,modelvals=None):\n",
    "        self.trn_dl, self.val_dl, self.module = trn_dl, val_dl, module\n",
    "        self.modelvals=modelvals\n",
    "        self.model=self.module.cuda()\n",
    "    def model_fit(self):\n",
    "        samp_n=self.modelvals['samp_n']#the number of iterations in an epoch\n",
    "        starttime=time.time()\n",
    "        train_loss_list=[]; val_loss_list=[]\n",
    "        for epoch in range(0, self.modelvals['epochs']):\n",
    "            pbar=0#progressbar\n",
    "            for batch_idx, (data, target) in enumerate(self.trn_dl):\n",
    "                \n",
    "                #GRAB MINIBATCH OF INPUTS AND TARGETS, SET OPTIMIZER\n",
    "                data = Variable(data)\n",
    "                pbar+=self.modelvals['bs'] #how many iterations have we done in the epoch so far\n",
    "                if self.modelvals['opttype']=='sgd':\n",
    "                    self.optimizer = optim.SGD(self.model.parameters(), lr=self.modelvals['lr'], \n",
    "                                       momentum=self.modelvals['mom'], weight_decay=self.modelvals['wd'],\n",
    "                                              nesterov=self.modelvals['nesterov'])\n",
    "                elif self.modelvals['opttype']=='adam':\n",
    "                    self.optimizer = optim.Adam(self.model.parameters(), lr=self.modelvals['lr'], \n",
    "                                        betas=(self.modelvals['mom'], 0.999))\n",
    "                self.optimizer.zero_grad()\n",
    "                \n",
    "                #FORWARD PASS\n",
    "                output = self.model(data)\n",
    "                \n",
    "                #CALCULATE AND BACKPROP THE LOSS\n",
    "                loss= output.loss\n",
    "                loss.backward()\n",
    "                if self.modelvals['grad_clip']!=0: #gradient clipping\n",
    "                    torch.nn.utils.clip_grad_value_(self.model.parameters(), self.modelvals['grad_clip'])\n",
    "                    \n",
    "                #UPDATE THE WEIGHTS\n",
    "                self.optimizer.step()\n",
    "                \n",
    "                #PRINT OUT TRAINING UPDATES\n",
    "                train_loss_list.append([epoch,pbar+epoch*samp_n,loss.data.item(),self.modelvals['lr']])\n",
    "                if batch_idx % 100 == 0:\n",
    "                    elapsed_time=time.time()-starttime\n",
    "                    train_update_format_string = 'Train Epoch: {}'\n",
    "                    train_update_format_string += '\\tTotal_its: {:.2f}M [{:.2f}M/{:.2f}M]'\n",
    "                    train_update_format_string += '\\tPercdone: {:.2f}'\n",
    "                    train_update_format_string += '\\tLoss: {:.4f}'\n",
    "                    train_update_format_string += '\\tTime: {:.2f}'\n",
    "                    train_update_format_string += '\\tLR: {:.4f}'\n",
    "                    train_update_string=train_update_format_string.format(\n",
    "                            epoch,\n",
    "                            (pbar + epoch * samp_n) / 1000000, pbar / 1000000, samp_n / 1000000,\n",
    "                            pbar / samp_n,\n",
    "                            loss.data.item(),\n",
    "                            elapsed_time / 60,\n",
    "                            self.modelvals['lr'])\n",
    "                    print(train_update_string)\n",
    "            final_train_loss=loss.data.item()\n",
    "            \n",
    "            #NOW TEST VALIDATION SET\n",
    "            val_loss=[]\n",
    "            self.model.eval() #important to set to eval mode for testing, so that eg batchnorm and dropout aren't used\n",
    "            for batch_idx, (data, target) in enumerate(self.val_dl):\n",
    "                data = Variable(data)\n",
    "                self.optimizer.zero_grad()\n",
    "                #ONLY NEED FORWARD PASS... NO BACKPROP\n",
    "                output = self.model(data)\n",
    "                loss= output.loss\n",
    "                output=output.output\n",
    "                val_loss.append(loss.data.item())\n",
    "            self.model.train() #set back to training mode\n",
    "            ave_val_loss=sum(val_loss) / len(val_loss)\n",
    "            val_update_string='Validation Loss: {:.4f}\\tPerp: {:.4f}'.format(\n",
    "                ave_val_loss,np.exp(ave_val_loss))\n",
    "            print(val_update_string)\n",
    "            val_loss_list.append([epoch,ave_val_loss, np.exp(ave_val_loss),elapsed_time/60])\n",
    "        self.modelvals['val_loss_list']=val_loss_list\n",
    "        self.modelvals['train_loss_list']=train_loss_list\n",
    "        print('The end! {:.2f} minutes'.format((time.time()-starttime)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set hyperparameters and build embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set hyperparameters\n",
    "bs=50 #batch-size\n",
    "emb_sz=300 #size of the embedding matrix\n",
    "nl=4 #number of layers\n",
    "nh=600 #number hidden units\n",
    "lr=1 #learning rate\n",
    "mom=.95 #momentum\n",
    "wd=5e-5 #weight-decay. Only has effect if opttype==sgd\n",
    "epochs=50\n",
    "nesterov=True #Nesterov momentum. only has effect if opttype==sgd\n",
    "grad_clip=0.07 #gradient clipping value. Set to 0 for no effect. See nn.utils.clip_grad_value_\n",
    "opttype='sgd' #adam, sgd\n",
    "k=4 #kernel_width\n",
    "downbot=20# in the bottleneck layers, how much to decrease channel depth?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use fast.ai to create a TextLMDataBunch object. See http://docs.fast.ai/text.data.html#class-textlmdatabunch\n",
    "#This tokenizes and numericalizes the data\n",
    "data_lm = TextLMDataBunch.from_csv(path=DATAPATH, csv_name='train_proc_par2.csv', test='test_proc_par2.csv')\n",
    "itos=data_lm.train_ds.vocab.itos# the vocab\n",
    "vs=len(itos)# vs is the length of the vocab\n",
    "\n",
    "#Grab the numericalized data from the TextLMDataBunch dataset, then construct new custom dataset using LMDataset_GCNN\n",
    "trn_tokens=[data_lm.train_ds[i][0].data for i in range(len(data_lm.train_ds))]\n",
    "traindataset=LMDataset_GCNN(trn_tokens)\n",
    "valid_tokens=[data_lm.valid_ds[i][0].data for i in range(len(data_lm.valid_ds))]\n",
    "validdataset=LMDataset_GCNN(valid_tokens)\n",
    "\n",
    "#Create data loaders for training and validation sets\n",
    "trn_samp=SortishSampler_GCNN(data_length=len(traindataset),key=lambda x:len(traindataset[x][0]), bs=bs)\n",
    "val_samp=SortSampler_GCNN(validdataset,key=lambda x:len(validdataset[x][0]))\n",
    "train_loader = data_utils.DataLoader(traindataset, batch_size=bs, collate_fn=pad_collate_GCNN, sampler=trn_samp,  pin_memory=False)\n",
    "val_loader = data_utils.DataLoader(validdataset, batch_size=bs, collate_fn=pad_collate_GCNN,sampler=val_samp,  pin_memory=False)\n",
    "samp_n=len(traindataset)\n",
    "val_samp_n=len(validdataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13927"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trn_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xxunk',\n",
       " 'xxpad',\n",
       " 'xxbos',\n",
       " 'xxeos',\n",
       " 'xxfld',\n",
       " 'xxmaj',\n",
       " 'xxup',\n",
       " 'xxrep',\n",
       " 'xxwrep',\n",
       " 'the',\n",
       " ',',\n",
       " '.',\n",
       " 'of',\n",
       " 'and',\n",
       " 'in',\n",
       " 'to',\n",
       " 'a',\n",
       " '\"',\n",
       " 'was',\n",
       " 'on']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itos[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Text xxbos xxmaj on their second date , xxmaj harmony suggests that they have sex , but xxmaj keith declines the proposal . xxmaj on the way back , xxmaj keith ’ s becomes involved in a traffic collision , but the xxunk catches him . xxmaj this traumatic experience makes him go back to xxmaj harmony , and they sleep together . xxmaj veronica talks to xxmaj tim xxmaj foyle , who made her follow the trail of \" xxmaj rory xxmaj finch \" deliberately in order for her to discover the professor ’ s affair . xxmaj tim was the professor ’ s protégé , and he wants xxmaj veronica to discover xxmaj hank 's flaws before she becomes more involved with him . xxmaj logan runs up to xxmaj veronica and tells her that xxmaj mercer has been arrested for the rapes on campus , despite the fact that he believes that xxmaj mercer is innocent . xxmaj logan begs xxmaj veronica to defend xxmaj mercer , as he was with him the night of one of the rapes . xxmaj however , he refuses to tell xxmaj veronica what they were doing . xxeos,\n",
       " EmptyLabel )"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_lm.train_ds[0][0], data_lm.train_ds[0][1], "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   2,    5,   19,   43, ...,   36, 1465,   11,    3])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tokenized version of the data\n",
    "data_lm.train_ds[0][0].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put hyperparameters into a dictionary\n",
    "def get_modelvals():\n",
    "    modelvals=dict((name,eval(name)) for name in [\n",
    "        'lr','mom','wd','opttype','epochs','samp_n','val_samp_n',\n",
    "        'bs','emb_sz','vs', 'nh', 'nl','DATAPATH','nesterov','grad_clip',\n",
    "        'k','downbot'] )\n",
    "    return modelvals\n",
    "\n",
    "modelvals=get_modelvals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr': 1,\n",
       " 'mom': 0.95,\n",
       " 'wd': 5e-05,\n",
       " 'opttype': 'sgd',\n",
       " 'epochs': 50,\n",
       " 'samp_n': 13927,\n",
       " 'val_samp_n': 3483,\n",
       " 'bs': 50,\n",
       " 'emb_sz': 300,\n",
       " 'vs': 28127,\n",
       " 'nh': 600,\n",
       " 'nl': 4,\n",
       " 'DATAPATH': PosixPath('/floyd/home/ed-triage/data'),\n",
       " 'nesterov': True,\n",
       " 'grad_clip': 0.07,\n",
       " 'k': 4,\n",
       " 'downbot': 20}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grab GloVe embeddings:\n",
    "#create vocab itos2 from downloaded glove file\n",
    "words = []  #list of words from glove embeddings\n",
    "idx = 0\n",
    "word2idx = {}  #dict mapping glove words to numbers on order they appear\n",
    "vectors = [] #list of vectors from glove embeddings\n",
    "with open('/floyd/home/ed-triage/data/glove.6B.300d.txt', 'rb') as f:\n",
    "    for l in f:\n",
    "        line = l.decode().split()  #takes one line from the file, turns to unicode and splits\n",
    "        word = line[0] #embedded word is first item in list\n",
    "        words.append(word)  #add that to list of words\n",
    "        word2idx[word] = idx  #add that word to the dicitonary with current idx as it's number\n",
    "        idx += 1\n",
    "        vectors.append(line[1:])  #add the vector which is the rest of the line to the vector list\n",
    "itos2=words\n",
    "\n",
    "#grab the glove embeddings we need, based on the words in our vocab\n",
    "stoi2 = collections.defaultdict(lambda:-1, {v:k for k,v in enumerate(itos2)}) #default -1 means its not in glove's itos2\n",
    "row_m = vectors[-1] #this is default vector... for <unk>\n",
    "new_w = np.zeros((vs, emb_sz), dtype=np.float32)#initialize new weights to zeros of size (vocab_size,embedding size) e.g. (60002,300)... we're creating an embedding matrix \n",
    "for i,w in enumerate(itos): #for index,word in our itos dict, get r index of the word in word2vec's dict. r will be -1 if it doesn't exist in word2vec's dict\n",
    "    r = stoi2[w]#r index of the word in word2vec's dict\n",
    "    new_w[i] = vectors[r] if r>=0 else row_m #for our new embedding matrix, set the embedding at the index from our dict equal to the embedding from index r from word2vec's dict\n",
    "np.save(DATAPATH/'emb_wgts300_proc_par2.npy', new_w) #save the embedding weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of words in our dataset: 28087\n",
      "# of words in glove word list: 400000\n"
     ]
    }
   ],
   "source": [
    "print ('# of words in our dataset:',len(itos))\n",
    "print ('# of words in glove word list:',len(itos2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0.429191',\n",
       " '-0.296897',\n",
       " '0.15011',\n",
       " '0.245201',\n",
       " '-0.00352027',\n",
       " '-0.0576971',\n",
       " '0.1409',\n",
       " '-0.222294',\n",
       " '0.221153',\n",
       " '0.767218',\n",
       " '-0.0772662',\n",
       " '-0.0710635',\n",
       " '0.0629486',\n",
       " '-0.220179',\n",
       " '-0.108197',\n",
       " '-0.301419',\n",
       " '0.232164',\n",
       " '0.168669',\n",
       " '-0.00452476',\n",
       " '0.168254',\n",
       " '-0.0579106',\n",
       " '-0.0362662',\n",
       " '-0.273464',\n",
       " '-0.162976',\n",
       " '0.239398',\n",
       " '-0.0119058',\n",
       " '0.044685',\n",
       " '0.105252',\n",
       " '0.102867',\n",
       " '-0.0232984',\n",
       " '-0.0114432',\n",
       " '-0.381673',\n",
       " '0.06122',\n",
       " '0.0170547',\n",
       " '0.415463',\n",
       " '-0.109101',\n",
       " '0.0959916',\n",
       " '0.19149',\n",
       " '-0.00752907',\n",
       " '-0.194603',\n",
       " '-0.0431976',\n",
       " '0.259788',\n",
       " '0.00527856',\n",
       " '-0.183626',\n",
       " '0.225188',\n",
       " '-0.0187726',\n",
       " '-0.158172',\n",
       " '-0.586937',\n",
       " '0.249259',\n",
       " '-0.130252',\n",
       " '-0.0537497',\n",
       " '0.0315535',\n",
       " '-0.18562',\n",
       " '0.0610198',\n",
       " '-0.0850566',\n",
       " '-0.0965162',\n",
       " '0.278621',\n",
       " '-0.247254',\n",
       " '-0.153895',\n",
       " '0.0418453',\n",
       " '0.0704212',\n",
       " '-0.062286',\n",
       " '-0.284913',\n",
       " '0.0152124',\n",
       " '0.144002',\n",
       " '0.335902',\n",
       " '-0.288315',\n",
       " '-0.00253548',\n",
       " '-0.0876423',\n",
       " '-0.0574409',\n",
       " '0.00670068',\n",
       " '-0.0753335',\n",
       " '-0.0677815',\n",
       " '-0.056624',\n",
       " '0.19296',\n",
       " '0.0250159',\n",
       " '-0.39188',\n",
       " '-0.159278',\n",
       " '0.26123',\n",
       " '0.10221',\n",
       " '0.0877169',\n",
       " '0.0433055',\n",
       " '-0.179803',\n",
       " '-0.189744',\n",
       " '0.0510538',\n",
       " '-0.0164141',\n",
       " '-0.00714073',\n",
       " '-0.327697',\n",
       " '-0.207509',\n",
       " '-0.0213479',\n",
       " '0.116692',\n",
       " '-0.0675631',\n",
       " '0.268143',\n",
       " '0.0961855',\n",
       " '0.0516012',\n",
       " '-0.0365261',\n",
       " '0.317162',\n",
       " '-0.158929',\n",
       " '-0.055459',\n",
       " '0.287867',\n",
       " '-0.140655',\n",
       " '-0.22574',\n",
       " '-0.0546181',\n",
       " '0.212033',\n",
       " '-0.0359359',\n",
       " '-0.0979935',\n",
       " '-0.0192465',\n",
       " '-0.186423',\n",
       " '0.298623',\n",
       " '-0.133734',\n",
       " '-0.114258',\n",
       " '0.303311',\n",
       " '0.142693',\n",
       " '0.0511059',\n",
       " '0.111157',\n",
       " '-0.106419',\n",
       " '0.246942',\n",
       " '-0.0651711',\n",
       " '0.137669',\n",
       " '0.227577',\n",
       " '-0.0368457',\n",
       " '0.139383',\n",
       " '-0.110347',\n",
       " '-0.0728796',\n",
       " '0.0965853',\n",
       " '0.0341107',\n",
       " '0.266715',\n",
       " '-0.00704015',\n",
       " '0.0284732',\n",
       " '-0.285951',\n",
       " '0.148497',\n",
       " '-0.351773',\n",
       " '-0.180508',\n",
       " '0.0751255',\n",
       " '-0.0413605',\n",
       " '0.0231546',\n",
       " '0.134506',\n",
       " '0.234478',\n",
       " '0.00781917',\n",
       " '-0.43099',\n",
       " '-0.171226',\n",
       " '-0.0480835',\n",
       " '-0.144825',\n",
       " '-0.105583',\n",
       " '0.412142',\n",
       " '-0.0439167',\n",
       " '-0.122553',\n",
       " '-0.105488',\n",
       " '0.186419',\n",
       " '-0.0874551',\n",
       " '-0.361173',\n",
       " '0.136994',\n",
       " '-0.144939',\n",
       " '0.0686074',\n",
       " '-0.451632',\n",
       " '-0.074767',\n",
       " '0.235809',\n",
       " '-0.147076',\n",
       " '-0.208566',\n",
       " '0.0402512',\n",
       " '-0.259224',\n",
       " '0.291085',\n",
       " '-0.0382213',\n",
       " '-0.206058',\n",
       " '-0.0899165',\n",
       " '0.0435619',\n",
       " '-0.181273',\n",
       " '-0.0926961',\n",
       " '0.072062',\n",
       " '-0.328039',\n",
       " '-0.048914',\n",
       " '-0.0823928',\n",
       " '0.590713',\n",
       " '-0.331955',\n",
       " '0.150388',\n",
       " '-0.0932722',\n",
       " '0.125483',\n",
       " '0.231407',\n",
       " '0.038411',\n",
       " '-0.309962',\n",
       " '-0.176691',\n",
       " '-0.176243',\n",
       " '-0.0882869',\n",
       " '0.0158377',\n",
       " '0.211813',\n",
       " '0.21001',\n",
       " '0.373582',\n",
       " '0.00851073',\n",
       " '0.162029',\n",
       " '-0.220738',\n",
       " '0.193189',\n",
       " '-0.171447',\n",
       " '0.0398142',\n",
       " '-0.00306123',\n",
       " '0.0124712',\n",
       " '-0.0604954',\n",
       " '-0.0637569',\n",
       " '-0.192784',\n",
       " '0.0691775',\n",
       " '-0.235627',\n",
       " '-0.695412',\n",
       " '0.0393999',\n",
       " '0.00500533',\n",
       " '0.0142551',\n",
       " '-0.0899872',\n",
       " '-0.111971',\n",
       " '0.100664',\n",
       " '-0.184054',\n",
       " '-0.0590461',\n",
       " '-0.0465109',\n",
       " '-0.0150755',\n",
       " '-0.0513298',\n",
       " '-0.0987529',\n",
       " '-0.0366648',\n",
       " '-0.303673',\n",
       " '-0.017006',\n",
       " '0.080696',\n",
       " '-0.195126',\n",
       " '0.1504',\n",
       " '-0.149472',\n",
       " '-0.318116',\n",
       " '0.110871',\n",
       " '0.26067',\n",
       " '-0.0893003',\n",
       " '-0.085158',\n",
       " '-0.155758',\n",
       " '-0.0600761',\n",
       " '-0.0388501',\n",
       " '0.309034',\n",
       " '0.109652',\n",
       " '0.0357152',\n",
       " '-0.158324',\n",
       " '-0.189182',\n",
       " '0.0512705',\n",
       " '0.0812089',\n",
       " '-0.343977',\n",
       " '-0.205674',\n",
       " '-0.15306',\n",
       " '0.253454',\n",
       " '-0.0530577',\n",
       " '0.0589571',\n",
       " '0.0414807',\n",
       " '-0.198986',\n",
       " '-0.0430847',\n",
       " '0.367526',\n",
       " '0.0418675',\n",
       " '-0.159542',\n",
       " '0.176339',\n",
       " '0.356934',\n",
       " '-0.0974301',\n",
       " '-0.164426',\n",
       " '-0.077908',\n",
       " '0.268078',\n",
       " '0.183976',\n",
       " '-0.234933',\n",
       " '0.250391',\n",
       " '0.122084',\n",
       " '0.023921',\n",
       " '-0.293752',\n",
       " '-0.0107412',\n",
       " '-0.172625',\n",
       " '0.0896321',\n",
       " '-0.249243',\n",
       " '-0.178334',\n",
       " '-0.100114',\n",
       " '0.174536',\n",
       " '0.0815058',\n",
       " '-0.259272',\n",
       " '-0.0360751',\n",
       " '-0.183724',\n",
       " '0.123181',\n",
       " '0.181773',\n",
       " '-0.118333',\n",
       " '-0.275433',\n",
       " '0.00962016',\n",
       " '-0.0358025',\n",
       " '0.782868',\n",
       " '0.0813635',\n",
       " '-0.308954',\n",
       " '0.00448305',\n",
       " '0.172544',\n",
       " '0.0387627',\n",
       " '0.0373694',\n",
       " '0.0566374',\n",
       " '0.0239079',\n",
       " '-0.257542',\n",
       " '0.157507',\n",
       " '-0.282229',\n",
       " '-0.132506',\n",
       " '0.217548',\n",
       " '0.128146',\n",
       " '0.0975518',\n",
       " '-0.130981',\n",
       " '-0.142839',\n",
       " '-0.175458',\n",
       " '-0.168996',\n",
       " '-0.0225121',\n",
       " '0.28975',\n",
       " '0.32618',\n",
       " '-0.0590532']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_m #vector for unk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28127, 300)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this is an embedding matrix with embed dim of 300 with the words from our datasets vocab\n",
    "#embedded with glove vectors.\n",
    "#any word not in the glove embeddings is embedded with row_m\n",
    "#which is the glove 'unknown' vector\n",
    "new_w.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run GCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GLUblock(nn.Module):\n",
    "    def __init__(self, k, in_c, out_c, downbot):\n",
    "        super().__init__()\n",
    "        #only need to change shape of the residual if num_channels changes (i.e. in_c != out_c)\n",
    "        #[bs,in_c,seq_length]->conv(1,in_c,out_c)->[bs,out_c,seq_length]\n",
    "        if in_c == out_c:\n",
    "            self.use_proj=0\n",
    "        else:\n",
    "            self.use_proj=1\n",
    "        self.convresid=nn.utils.weight_norm(nn.Conv2d(in_c, out_c, kernel_size=(1,1)),name='weight',dim=0)\n",
    "        \n",
    "        self.leftpad = nn.ConstantPad2d((0,0,k-1,0),0)#(paddingLeft, paddingRight, paddingTop, paddingBottom)\n",
    "\n",
    "        #[bs,in_c,seq_length+(k-1)]->conv(1,in_c,in_c/downbot)->[bs,in_c/downbot,seq_length+(k-1)]\n",
    "        self.convx1a = nn.utils.weight_norm(nn.Conv2d(in_c, int(in_c/downbot), kernel_size=(1,1)),name='weight',dim=0)\n",
    "        self.convx2a = nn.utils.weight_norm(nn.Conv2d(in_c, int(in_c/downbot), kernel_size=(1,1)),name='weight',dim=0)\n",
    "        #[bs,in_c/downbot,seq_length+(k-1)]->conv(k,in_c/downbot,in_c/downbot)->[bs,in_c/downbot,seq_length]\n",
    "        self.convx1b = nn.utils.weight_norm(nn.Conv2d(int(in_c/downbot), int(in_c/downbot), kernel_size=(k,1)),name='weight',dim=0)\n",
    "        self.convx2b = nn.utils.weight_norm(nn.Conv2d(int(in_c/downbot), int(in_c/downbot), kernel_size=(k,1)),name='weight',dim=0)\n",
    "        #[bs,in_c/downbot,seq_length]->conv(1,in_c/downbot,out_c)->[bs,out_c,seq_length]\n",
    "        self.convx1c = nn.utils.weight_norm(nn.Conv2d(int(in_c/downbot), out_c, kernel_size=(1,1)),name='weight',dim=0)\n",
    "        self.convx2c = nn.utils.weight_norm(nn.Conv2d(int(in_c/downbot), out_c, kernel_size=(1,1)),name='weight',dim=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        if self.use_proj==1:# if in_c != out_c, need to change size of residual\n",
    "            residual=self.convresid(residual)\n",
    "        x=self.leftpad(x) # [bs,in_c,seq_length+(k-1),1]\n",
    "        x1 = self.convx1c(self.convx1b(self.convx1a(x))) # [bs,out_c,seq_length,1]\n",
    "        x2 = self.convx2c(self.convx2b(self.convx2a(x))) # [bs,out_c,seq_length,1]\n",
    "        x2 = torch.sigmoid(x2)\n",
    "        x=torch.mul(x1,x2) # [bs,out_c,seq_length,1]\n",
    "        return x+residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNNmodel(nn.Module):\n",
    "    def __init__(self, vs, emb_sz, k, nh, nl,downbot):\n",
    "    #def __init__(self, vs, emb_sz, k, nh, nl,dw,cutoffs):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embed = nn.Embedding(vs, emb_sz)\n",
    "        \n",
    "        self.inlayer=GLUblock(k,emb_sz,nh,downbot)\n",
    "        self.GLUlayers=self.make_GLU_layers(k,nh,nl,downbot)\n",
    "        self.out=nn.AdaptiveLogSoftmaxWithLoss(nh, vs, cutoffs=[round(vs/25),round(vs/5)],div_value=4)\n",
    "\n",
    "    def make_GLU_layers(self, k, nh, nl, downbot):\n",
    "        layers = [GLUblock(k, nh, nh, downbot) for i in range(nl)]\n",
    "        return nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        target=x[1:,:]\n",
    "        target=target.contiguous().view(target.size()[0]*target.size()[1])#[seq_length*bs,out_c]\n",
    "        x=x[:-1,:]\n",
    "        \n",
    "        #first block\n",
    "        x = self.embed(torch.t(x)) # x -> [seq_length,bs] -> [bs,seq_length] -> [bs,seq_length,emb_sz] ... i.e. transpose 1st\n",
    "        x=torch.transpose(x, 1, 2) #[bs,emb_sz,seq_length]    \n",
    "        x = x.unsqueeze(3)  # [bs,emb_sz,seq_length,1]\n",
    "        x=self.inlayer(x) #[bs,nh,seq_length,1]\n",
    "             \n",
    "        #residual GLU blocks\n",
    "        x=self.GLUlayers(x) # [bs,nh,seq_length,1]\n",
    "        \n",
    "        #out\n",
    "        x=torch.squeeze(x,3) #[bs,out_c,seq_length]\n",
    "        x=torch.transpose(x, 1, 2) #[bs,seq_length,out_c]\n",
    "        x=torch.transpose(x, 0, 1) #[seq_length,bs,out_c]\n",
    "        x=x.contiguous().view(-1,x.size()[2])#[seq_length*bs,out_c]\n",
    "        outta=self.out(x,target)\n",
    "        \n",
    "        return    outta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCNNmodel(\n",
      "  (embed): Embedding(28087, 300)\n",
      "  (inlayer): GLUblock(\n",
      "    (convresid): Conv2d(300, 600, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (leftpad): ConstantPad2d(padding=(0, 0, 3, 0), value=0)\n",
      "    (convx1a): Conv2d(300, 15, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (convx2a): Conv2d(300, 15, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (convx1b): Conv2d(15, 15, kernel_size=(4, 1), stride=(1, 1))\n",
      "    (convx2b): Conv2d(15, 15, kernel_size=(4, 1), stride=(1, 1))\n",
      "    (convx1c): Conv2d(15, 600, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (convx2c): Conv2d(15, 600, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (GLUlayers): Sequential(\n",
      "    (0): GLUblock(\n",
      "      (convresid): Conv2d(600, 600, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (leftpad): ConstantPad2d(padding=(0, 0, 3, 0), value=0)\n",
      "      (convx1a): Conv2d(600, 30, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (convx2a): Conv2d(600, 30, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (convx1b): Conv2d(30, 30, kernel_size=(4, 1), stride=(1, 1))\n",
      "      (convx2b): Conv2d(30, 30, kernel_size=(4, 1), stride=(1, 1))\n",
      "      (convx1c): Conv2d(30, 600, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (convx2c): Conv2d(30, 600, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (1): GLUblock(\n",
      "      (convresid): Conv2d(600, 600, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (leftpad): ConstantPad2d(padding=(0, 0, 3, 0), value=0)\n",
      "      (convx1a): Conv2d(600, 30, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (convx2a): Conv2d(600, 30, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (convx1b): Conv2d(30, 30, kernel_size=(4, 1), stride=(1, 1))\n",
      "      (convx2b): Conv2d(30, 30, kernel_size=(4, 1), stride=(1, 1))\n",
      "      (convx1c): Conv2d(30, 600, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (convx2c): Conv2d(30, 600, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (2): GLUblock(\n",
      "      (convresid): Conv2d(600, 600, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (leftpad): ConstantPad2d(padding=(0, 0, 3, 0), value=0)\n",
      "      (convx1a): Conv2d(600, 30, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (convx2a): Conv2d(600, 30, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (convx1b): Conv2d(30, 30, kernel_size=(4, 1), stride=(1, 1))\n",
      "      (convx2b): Conv2d(30, 30, kernel_size=(4, 1), stride=(1, 1))\n",
      "      (convx1c): Conv2d(30, 600, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (convx2c): Conv2d(30, 600, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (3): GLUblock(\n",
      "      (convresid): Conv2d(600, 600, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (leftpad): ConstantPad2d(padding=(0, 0, 3, 0), value=0)\n",
      "      (convx1a): Conv2d(600, 30, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (convx2a): Conv2d(600, 30, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (convx1b): Conv2d(30, 30, kernel_size=(4, 1), stride=(1, 1))\n",
      "      (convx2b): Conv2d(30, 30, kernel_size=(4, 1), stride=(1, 1))\n",
      "      (convx1c): Conv2d(30, 600, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (convx2c): Conv2d(30, 600, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (out): AdaptiveLogSoftmaxWithLoss(\n",
      "    (head): Linear(in_features=600, out_features=1125, bias=False)\n",
      "    (tail): ModuleList(\n",
      "      (0): Sequential(\n",
      "        (0): Linear(in_features=600, out_features=150, bias=False)\n",
      "        (1): Linear(in_features=150, out_features=4494, bias=False)\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): Linear(in_features=600, out_features=37, bias=False)\n",
      "        (1): Linear(in_features=37, out_features=22470, bias=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#create GCNN \n",
    "GCNNnet=modeler(train_loader,val_loader,\n",
    "                           GCNNmodel(vs, emb_sz, k, nh, nl, downbot),modelvals)\n",
    "print(GCNNnet.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the glove-vectors into the model\n",
    "new_w=np.load(DATAPATH/'emb_wgts300_proc_par2.npy') #load embedding weights\n",
    "GCNNnet.model.embed.weight.data=torch.FloatTensor(new_w).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0\tTotal_its: 0.00M [0.00M/0.01M]\tPercdone: 0.00\tLoss: 8.7997\tTime: 0.02\tLR: 1.0000\n",
      "Train Epoch: 0\tTotal_its: 0.01M [0.01M/0.01M]\tPercdone: 0.36\tLoss: 383.2048\tTime: 0.99\tLR: 1.0000\n",
      "Train Epoch: 0\tTotal_its: 0.01M [0.01M/0.01M]\tPercdone: 0.72\tLoss: 86.2456\tTime: 2.10\tLR: 1.0000\n",
      "Validation Loss: 42.7355\tPerp: 3629188107272724480.0000\n",
      "Train Epoch: 1\tTotal_its: 0.01M [0.00M/0.01M]\tPercdone: 0.00\tLoss: 38.6271\tTime: 3.20\tLR: 1.0000\n",
      "Train Epoch: 1\tTotal_its: 0.02M [0.01M/0.01M]\tPercdone: 0.36\tLoss: 17.6924\tTime: 4.28\tLR: 1.0000\n",
      "Train Epoch: 1\tTotal_its: 0.02M [0.01M/0.01M]\tPercdone: 0.72\tLoss: 11.3362\tTime: 5.37\tLR: 1.0000\n",
      "Validation Loss: 13.6693\tPerp: 863949.0223\n",
      "Train Epoch: 2\tTotal_its: 0.03M [0.00M/0.01M]\tPercdone: 0.00\tLoss: 12.3590\tTime: 6.49\tLR: 1.0000\n",
      "Train Epoch: 2\tTotal_its: 0.03M [0.01M/0.01M]\tPercdone: 0.36\tLoss: 8.1638\tTime: 7.70\tLR: 1.0000\n",
      "Train Epoch: 2\tTotal_its: 0.04M [0.01M/0.01M]\tPercdone: 0.72\tLoss: 5.9316\tTime: 9.06\tLR: 1.0000\n",
      "Validation Loss: 8.4559\tPerp: 4702.8136\n",
      "Train Epoch: 3\tTotal_its: 0.04M [0.00M/0.01M]\tPercdone: 0.00\tLoss: 7.5762\tTime: 10.13\tLR: 1.0000\n",
      "Train Epoch: 3\tTotal_its: 0.05M [0.01M/0.01M]\tPercdone: 0.36\tLoss: 7.8182\tTime: 11.30\tLR: 1.0000\n",
      "Train Epoch: 3\tTotal_its: 0.05M [0.01M/0.01M]\tPercdone: 0.72\tLoss: 4.2898\tTime: 12.25\tLR: 1.0000\n",
      "Validation Loss: 6.4925\tPerp: 660.1607\n",
      "Train Epoch: 4\tTotal_its: 0.06M [0.00M/0.01M]\tPercdone: 0.00\tLoss: 5.7798\tTime: 13.23\tLR: 1.0000\n",
      "Train Epoch: 4\tTotal_its: 0.06M [0.01M/0.01M]\tPercdone: 0.36\tLoss: 3.6217\tTime: 14.41\tLR: 1.0000\n",
      "Train Epoch: 4\tTotal_its: 0.07M [0.01M/0.01M]\tPercdone: 0.72\tLoss: 4.3325\tTime: 15.72\tLR: 1.0000\n",
      "Validation Loss: 5.5310\tPerp: 252.4047\n",
      "Train Epoch: 5\tTotal_its: 0.07M [0.00M/0.01M]\tPercdone: 0.00\tLoss: 4.7927\tTime: 16.85\tLR: 1.0000\n",
      "Train Epoch: 5\tTotal_its: 0.07M [0.01M/0.01M]\tPercdone: 0.36\tLoss: 5.3890\tTime: 17.96\tLR: 1.0000\n",
      "Train Epoch: 5\tTotal_its: 0.08M [0.01M/0.01M]\tPercdone: 0.72\tLoss: 5.2323\tTime: 19.14\tLR: 1.0000\n",
      "Validation Loss: 5.3815\tPerp: 217.3503\n",
      "Train Epoch: 6\tTotal_its: 0.08M [0.00M/0.01M]\tPercdone: 0.00\tLoss: 4.7480\tTime: 20.29\tLR: 1.0000\n",
      "Train Epoch: 6\tTotal_its: 0.09M [0.01M/0.01M]\tPercdone: 0.36\tLoss: 5.6668\tTime: 21.36\tLR: 1.0000\n",
      "Train Epoch: 6\tTotal_its: 0.09M [0.01M/0.01M]\tPercdone: 0.72\tLoss: 5.0046\tTime: 22.53\tLR: 1.0000\n",
      "Validation Loss: 5.4144\tPerp: 224.6101\n",
      "Train Epoch: 7\tTotal_its: 0.10M [0.00M/0.01M]\tPercdone: 0.00\tLoss: 4.7034\tTime: 23.62\tLR: 1.0000\n",
      "Train Epoch: 7\tTotal_its: 0.10M [0.01M/0.01M]\tPercdone: 0.36\tLoss: 3.6312\tTime: 24.99\tLR: 1.0000\n",
      "Train Epoch: 7\tTotal_its: 0.11M [0.01M/0.01M]\tPercdone: 0.72\tLoss: 2.8192\tTime: 26.35\tLR: 1.0000\n",
      "Validation Loss: 5.4895\tPerp: 242.1339\n",
      "Train Epoch: 8\tTotal_its: 0.11M [0.00M/0.01M]\tPercdone: 0.00\tLoss: 4.8863\tTime: 27.40\tLR: 1.0000\n",
      "Train Epoch: 8\tTotal_its: 0.12M [0.01M/0.01M]\tPercdone: 0.36\tLoss: 5.3218\tTime: 28.41\tLR: 1.0000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-8f9419c87638>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mGCNNnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-5acf2f4bbc56>\u001b[0m in \u001b[0;36mmodel_fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     29\u001b[0m                 \u001b[0;31m#CALCULATE AND BACKPROP THE LOSS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodelvals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'grad_clip'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#gradient clipping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_value_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodelvals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'grad_clip'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "GCNNnet.model_fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_list,loss_list,perp_list,time_list=zip(*GCNNnet.modelvals['val_loss_list'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(list(range(3,51)),perp_list[2:])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Perplexity')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
